{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manjitullal/foursquare/blob/master/RNN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srsPqj3OoFO-",
        "colab_type": "text"
      },
      "source": [
        "# **Temporal and Spatial analysis of events data using LSTM**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zt2Bq77oUEu",
        "colab_type": "text"
      },
      "source": [
        "**Dataset:** foursquare\n",
        "\n",
        "**Aim:** to predict future location and time of user given the historical sequences of location and time .\n",
        "\n",
        "An analogy for the aim is , predicting the next word in a sentence. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzINCAjZpryW",
        "colab_type": "text"
      },
      "source": [
        "**Contents:**\n",
        "***\n",
        "1. Data pre processing\n",
        "2. Encoding\n",
        "3. Modeling\n",
        "4. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce2cG-Z1p_UV",
        "colab_type": "text"
      },
      "source": [
        "# **1. Data pre processing**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GlupXKwn6GU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecb7781d-1709-4155-d9a7-473633e39167"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "\n",
        "\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f30fba4de30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "918U9XsGYpD-",
        "colab_type": "text"
      },
      "source": [
        "1. **Check for GPU**\n",
        "---\n",
        "This code presently does not use GPU. This will later be modified to use one.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKWnSgTB1mv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "5687e5e3-2995-4ce2-88e3-de6594870ba7"
      },
      "source": [
        "#check the devices available\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 13359404271917426863\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 3441581282584748557\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idzooZ_m200b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "35178e23-ca38-4644-b7ac-f037ab935870"
      },
      "source": [
        "#check if the gpu is available\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5DIAW674AA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5cd0b8d-5d44-4318-804a-72750bea768f"
      },
      "source": [
        "#the GPU may not be available at the moment\n",
        "\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU device not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqnyh90agc5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "b9c2fc59-1093-4131-87b9-c6ac4983f31d"
      },
      "source": [
        "#dataset is in the google drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjDgrlTdgmji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "95429a2f-62f4-421f-84c1-b56dc93aacd1"
      },
      "source": [
        "#my google drive path\n",
        "\n",
        "!ls \"/content/drive/My Drive/dataset/foursquare\"\n",
        "path = \"/content/drive/My Drive/dataset/foursquare\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkin.txt\t UserFriends.txt    VenueRating.txt\n",
            "Description.txt  VenueCategory.txt  Venue.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sduA9CxS_y_H",
        "colab_type": "text"
      },
      "source": [
        "2. **Load dataset.** \n",
        "---\n",
        "Dataset, consists of 5 tables. `Checkin` table has the event details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-_st6uAdyTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9aad61ae-3af3-4776-c03a-0ee52a341233"
      },
      "source": [
        "%%time\n",
        "Checkin_columns = ['UserID','VenueID','Year','Month','Date','Hour']\n",
        "Checkin = pd.read_csv(path+'/Checkin.txt', sep=',', skiprows=1, names=Checkin_columns)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 712 ms, sys: 143 ms, total: 856 ms\n",
            "Wall time: 1.21 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbzKjlyHh7a2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1a586914-37c3-4edc-ff0e-3d83477bff8c"
      },
      "source": [
        "%%time\n",
        "\n",
        "Venue_columns = ['VenueID','VenueName','Latitude','Longitude','CategoryID']\n",
        "Venue = pd.read_csv(path+'/Venue.txt', sep=',', error_bad_lines=False,skiprows=1,names=Venue_columns)\n",
        "\n",
        "VenueCategory_columns = ['CategoryID','CategoryName','ParentCategoryID']\n",
        "VenueCategory = pd.read_csv(path+'/VenueCategory.txt', sep=',',error_bad_lines=False,skiprows=1,names=VenueCategory_columns)\n",
        "\n",
        "VenueRating_columns = ['VenueID','Rating']\n",
        "VenueRating = pd.read_csv(path+'/VenueRating.txt', sep=',',error_bad_lines=False,skiprows=1,names=VenueRating_columns)\n",
        "\n",
        "UserFriends = pd.read_csv(path+'/UserFriends.txt', sep=',') \n",
        "\n",
        "all_tables = [Checkin,Venue,VenueCategory,VenueRating,UserFriends]\n",
        "all_tables_string = ['Checkin','Venue','VenueCategory','VenueRating','UserFriends']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 999 ms, sys: 92.4 ms, total: 1.09 s\n",
            "Wall time: 1.89 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyuAPADGhADL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "9e3a69df-52a8-47f8-8629-4b6a137ceebc"
      },
      "source": [
        "Checkin.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>VenueID</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Date</th>\n",
              "      <th>Hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u1302</td>\n",
              "      <td>v47</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u45</td>\n",
              "      <td>v132</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u24844</td>\n",
              "      <td>v86</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u896</td>\n",
              "      <td>v248</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>u5020</td>\n",
              "      <td>v29</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserID VenueID  Year  Month  Date  Hour\n",
              "0   u1302     v47  2012      2    24    11\n",
              "1     u45    v132  2012      2    24    11\n",
              "2  u24844     v86  2012      2    24    11\n",
              "3    u896    v248  2012      2    24    11\n",
              "4   u5020     v29  2012      2    24    11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofoqannHheKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "aad355b4-9963-4109-e9df-d548d1f73254"
      },
      "source": [
        "#stats of the data \n",
        "\n",
        "def _describe(data):\n",
        "    print(f\" Number of rows: {data.shape[0]}\")\n",
        "    print(f\" Number of columns: {data.shape[1]}\")\n",
        "    print(f\" Number of null values: {np.sum(data.isnull().sum())}\")\n",
        "    print(\"The columns that have null values\")\n",
        "    print(pd.DataFrame(data.isnull().sum()).T)\n",
        "    \n",
        "for index,table in enumerate(all_tables):\n",
        "    print(f\"Details of table {all_tables_string[index]}\")\n",
        "    print(\"\")\n",
        "    _describe(table)\n",
        "    print(\"\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Details of table Checkin\n",
            "\n",
            " Number of rows: 1276988\n",
            " Number of columns: 6\n",
            " Number of null values: 0\n",
            "The columns that have null values\n",
            "   UserID  VenueID  Year  Month  Date  Hour\n",
            "0       0        0     0      0     0     0\n",
            "\n",
            "Details of table Venue\n",
            "\n",
            " Number of rows: 85928\n",
            " Number of columns: 5\n",
            " Number of null values: 14\n",
            "The columns that have null values\n",
            "   VenueID  VenueName  Latitude  Longitude  CategoryID\n",
            "0        0         12         2          0           0\n",
            "\n",
            "Details of table VenueCategory\n",
            "\n",
            " Number of rows: 394\n",
            " Number of columns: 3\n",
            " Number of null values: 0\n",
            "The columns that have null values\n",
            "   CategoryID  CategoryName  ParentCategoryID\n",
            "0           0             0                 0\n",
            "\n",
            "Details of table VenueRating\n",
            "\n",
            " Number of rows: 68178\n",
            " Number of columns: 2\n",
            " Number of null values: 96\n",
            "The columns that have null values\n",
            "   VenueID  Rating\n",
            "0       96       0\n",
            "\n",
            "Details of table UserFriends\n",
            "\n",
            " Number of rows: 1366388\n",
            " Number of columns: 2\n",
            " Number of null values: 0\n",
            "The columns that have null values\n",
            "   userID  friendID\n",
            "0       0         0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQP07W6eqXqN",
        "colab_type": "text"
      },
      "source": [
        "3. **Model for one user** (for testing), hence we will filter the data for one user, eventually this will be extended for all users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07eFFxUde_7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "2ee3cdb0-9602-452a-9750-d17405a78733"
      },
      "source": [
        "#filter data for one user \n",
        "\n",
        "Checkin_u1205 = Checkin[Checkin.UserID == 'u1205']\n",
        "Checkin_u1205.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>VenueID</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Date</th>\n",
              "      <th>Hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2723</th>\n",
              "      <td>u1205</td>\n",
              "      <td>v73805</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3817</th>\n",
              "      <td>u1205</td>\n",
              "      <td>v9884</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4739</th>\n",
              "      <td>u1205</td>\n",
              "      <td>v3906</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5904</th>\n",
              "      <td>u1205</td>\n",
              "      <td>v10373</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6840</th>\n",
              "      <td>u1205</td>\n",
              "      <td>v9884</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     UserID VenueID  Year  Month  Date  Hour\n",
              "2723  u1205  v73805  2012      2    25     9\n",
              "3817  u1205   v9884  2012      2    25    11\n",
              "4739  u1205   v3906  2012      2    25    13\n",
              "5904  u1205  v10373  2012      2    25    15\n",
              "6840  u1205   v9884  2012      2    25    17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wjalbEBit8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "a09825b8-0699-4516-847c-5de69b6d9ff2"
      },
      "source": [
        "# drop userid as that is not useful now, since there is only one user \n",
        "\n",
        "Checkin_u1205.drop(['UserID'], axis=1, inplace=True)\n",
        "\n",
        "#renaming column Date to Day\n",
        "Checkin_u1205.rename(columns={\"Date\":\"Day\"}, inplace=True)\n",
        "Checkin_u1205.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VenueID</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2723</th>\n",
              "      <td>v73805</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3817</th>\n",
              "      <td>v9884</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4739</th>\n",
              "      <td>v3906</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5904</th>\n",
              "      <td>v10373</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6840</th>\n",
              "      <td>v9884</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     VenueID  Year  Month  Day  Hour\n",
              "2723  v73805  2012      2   25     9\n",
              "3817   v9884  2012      2   25    11\n",
              "4739   v3906  2012      2   25    13\n",
              "5904  v10373  2012      2   25    15\n",
              "6840   v9884  2012      2   25    17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRc5b7_mjOA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "04cb5e32-d414-4d37-c9aa-fec876646a49"
      },
      "source": [
        "# create a new column, datetime to sort the events \n",
        "\n",
        "%%time\n",
        "Checkin_u1205['Datetime'] = pd.to_datetime(Checkin_u1205[['Year', 'Month', 'Day', 'Hour']])\n",
        "Checkin_u1205['Hour_mins'] = Checkin_u1205.Hour.values*60\n",
        "\n",
        "Checkin_u1205.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 22.7 ms, sys: 4.3 ms, total: 27 ms\n",
            "Wall time: 92.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR2arrZk1qF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "78b0570a-1b12-4ec1-a58e-22044d24b318"
      },
      "source": [
        "# sort based on datetime\n",
        "Checkin_u1205.sort_values(by='Datetime',inplace=True)\n",
        "\n",
        "Checkin_u1205.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VenueID</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>Hour_mins</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2723</th>\n",
              "      <td>v73805</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>9</td>\n",
              "      <td>2012-02-25 09:00:00</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9154</th>\n",
              "      <td>v40561</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>9</td>\n",
              "      <td>2012-02-25 09:00:00</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3817</th>\n",
              "      <td>v9884</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "      <td>2012-02-25 11:00:00</td>\n",
              "      <td>660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10664</th>\n",
              "      <td>v1743</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "      <td>2012-02-25 11:00:00</td>\n",
              "      <td>660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4739</th>\n",
              "      <td>v3906</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "      <td>2012-02-25 13:00:00</td>\n",
              "      <td>780</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      VenueID  Year  Month  Day  Hour            Datetime  Hour_mins\n",
              "2723   v73805  2012      2   25     9 2012-02-25 09:00:00        540\n",
              "9154   v40561  2012      2   25     9 2012-02-25 09:00:00        540\n",
              "3817    v9884  2012      2   25    11 2012-02-25 11:00:00        660\n",
              "10664   v1743  2012      2   25    11 2012-02-25 11:00:00        660\n",
              "4739    v3906  2012      2   25    13 2012-02-25 13:00:00        780"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uElqQ4Jo2NLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from the above, we can see that for some reason there are 2 duplicate timestamps with different venues\n",
        "# it is not possible for a person to be at different location at the same time, so removing the rows with duplicate time stamps\n",
        "# the category of the venues is hierarchical, however for there appears no link between the venues\n",
        "\n",
        "Checkin_u1205_nodup = Checkin_u1205.drop_duplicates('Datetime')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2IOLvasZ1Qv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "992ec4ed-0623-4830-b3a0-a4248bf7e569"
      },
      "source": [
        "print(\"Rows in Checkin_u1205: \", Checkin_u1205.shape[0])\n",
        "print(\"Rows in Checkin_u1205_nodup: \", Checkin_u1205_nodup.shape[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rows in Checkin_u1205:  1303\n",
            "Rows in Checkin_u1205_nodup:  1227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzagi8fMgvjB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "outputId": "681935eb-f326-4a77-cad7-ede74f918853"
      },
      "source": [
        "Checkin_u1205_nodup.iloc[:20]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VenueID</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>Hour_mins</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2723</th>\n",
              "      <td>v73805</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>9</td>\n",
              "      <td>2012-02-25 09:00:00</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3817</th>\n",
              "      <td>v9884</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "      <td>2012-02-25 11:00:00</td>\n",
              "      <td>660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4739</th>\n",
              "      <td>v3906</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "      <td>2012-02-25 13:00:00</td>\n",
              "      <td>780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5904</th>\n",
              "      <td>v10373</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "      <td>2012-02-25 15:00:00</td>\n",
              "      <td>900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6840</th>\n",
              "      <td>v9884</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>17</td>\n",
              "      <td>2012-02-25 17:00:00</td>\n",
              "      <td>1020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18507</th>\n",
              "      <td>v9885</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>9</td>\n",
              "      <td>2012-02-26 09:00:00</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12801</th>\n",
              "      <td>v10373</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>11</td>\n",
              "      <td>2012-02-26 11:00:00</td>\n",
              "      <td>660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11674</th>\n",
              "      <td>v9885</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>13</td>\n",
              "      <td>2012-02-26 13:00:00</td>\n",
              "      <td>780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15263</th>\n",
              "      <td>v2927</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>15</td>\n",
              "      <td>2012-02-26 15:00:00</td>\n",
              "      <td>900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20745</th>\n",
              "      <td>v6013</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>9</td>\n",
              "      <td>2012-02-27 09:00:00</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22076</th>\n",
              "      <td>v67648</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>11</td>\n",
              "      <td>2012-02-27 11:00:00</td>\n",
              "      <td>660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23077</th>\n",
              "      <td>v37724</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>13</td>\n",
              "      <td>2012-02-27 13:00:00</td>\n",
              "      <td>780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23727</th>\n",
              "      <td>v13235</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>14</td>\n",
              "      <td>2012-02-27 14:00:00</td>\n",
              "      <td>840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24467</th>\n",
              "      <td>v85343</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>15</td>\n",
              "      <td>2012-02-27 15:00:00</td>\n",
              "      <td>900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25731</th>\n",
              "      <td>v9884</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>17</td>\n",
              "      <td>2012-02-27 17:00:00</td>\n",
              "      <td>1020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20334</th>\n",
              "      <td>v55736</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>19</td>\n",
              "      <td>2012-02-27 19:00:00</td>\n",
              "      <td>1140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27796</th>\n",
              "      <td>v18477</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>20</td>\n",
              "      <td>2012-02-27 20:00:00</td>\n",
              "      <td>1200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27898</th>\n",
              "      <td>v9885</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>21</td>\n",
              "      <td>2012-02-27 21:00:00</td>\n",
              "      <td>1260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30493</th>\n",
              "      <td>v6013</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "      <td>8</td>\n",
              "      <td>2012-02-28 08:00:00</td>\n",
              "      <td>480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31455</th>\n",
              "      <td>v342</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "      <td>10</td>\n",
              "      <td>2012-02-28 10:00:00</td>\n",
              "      <td>600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      VenueID  Year  Month  Day  Hour            Datetime  Hour_mins\n",
              "2723   v73805  2012      2   25     9 2012-02-25 09:00:00        540\n",
              "3817    v9884  2012      2   25    11 2012-02-25 11:00:00        660\n",
              "4739    v3906  2012      2   25    13 2012-02-25 13:00:00        780\n",
              "5904   v10373  2012      2   25    15 2012-02-25 15:00:00        900\n",
              "6840    v9884  2012      2   25    17 2012-02-25 17:00:00       1020\n",
              "18507   v9885  2012      2   26     9 2012-02-26 09:00:00        540\n",
              "12801  v10373  2012      2   26    11 2012-02-26 11:00:00        660\n",
              "11674   v9885  2012      2   26    13 2012-02-26 13:00:00        780\n",
              "15263   v2927  2012      2   26    15 2012-02-26 15:00:00        900\n",
              "20745   v6013  2012      2   27     9 2012-02-27 09:00:00        540\n",
              "22076  v67648  2012      2   27    11 2012-02-27 11:00:00        660\n",
              "23077  v37724  2012      2   27    13 2012-02-27 13:00:00        780\n",
              "23727  v13235  2012      2   27    14 2012-02-27 14:00:00        840\n",
              "24467  v85343  2012      2   27    15 2012-02-27 15:00:00        900\n",
              "25731   v9884  2012      2   27    17 2012-02-27 17:00:00       1020\n",
              "20334  v55736  2012      2   27    19 2012-02-27 19:00:00       1140\n",
              "27796  v18477  2012      2   27    20 2012-02-27 20:00:00       1200\n",
              "27898   v9885  2012      2   27    21 2012-02-27 21:00:00       1260\n",
              "30493   v6013  2012      2   28     8 2012-02-28 08:00:00        480\n",
              "31455    v342  2012      2   28    10 2012-02-28 10:00:00        600"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1JdSv3NrBxs",
        "colab_type": "text"
      },
      "source": [
        "For time being we are not using the heirarchical informations about the venue, to keep the baseline model simple."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVmSazxGrSwh",
        "colab_type": "text"
      },
      "source": [
        "Now, we need to create a time-series of events. \n",
        "\n",
        "`Example:`\n",
        "\n",
        "User goes to gym, grocery and home in that order or shopping, movies, restaurant and home in that order. \n",
        "\n",
        "Here, we need to create the longest time-series.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1Xx9Tyi64Y6",
        "colab_type": "text"
      },
      "source": [
        "create dataset as tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy_SlcJeiRkR",
        "colab_type": "text"
      },
      "source": [
        "4. **Create longest sequences.** \n",
        "---\n",
        "`Idea`: gather longest time-series by viewing the events of the user, events less than the duration of 8hrs between them will be added to the same series. A gap of 8 hrs or more indicates the day has ended for the user, hence no more travel.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRUGUaF-UkKD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cb66487b-31d0-4bcf-b8d2-6ea754fce919"
      },
      "source": [
        "\n",
        "%%time\n",
        "\n",
        "import datetime\n",
        "\n",
        "def _generate_events(data):\n",
        "  previous_time = datetime.datetime(2020, 12, 31)\n",
        "  all_events = []\n",
        "  current_events = []\n",
        "  for index, row in data.iterrows():\n",
        "    current_time = row['Datetime']  \n",
        "    current_hour = row['Hour_mins']\n",
        "    venue = row['VenueID']\n",
        "    if( (current_time - previous_time).total_seconds()/60/60 < 8):\n",
        "      current_events.append([venue, current_hour])\n",
        "      previous_time = current_time\n",
        "    else:\n",
        "      all_events.append(current_events)\n",
        "      current_events = []\n",
        "      current_events.append([venue, current_hour])\n",
        "      previous_time = current_time\n",
        "  if len(current_events)>0:\n",
        "    all_events.append(current_events)\n",
        "  return all_events\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7 µs, sys: 1 µs, total: 8 µs\n",
            "Wall time: 11.2 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGbPUprJjT6C",
        "colab_type": "text"
      },
      "source": [
        "5. **Subsequences:** A Sequence cannot be directly fed into a model, hence one possibility is to break into sequence of two.\n",
        "\n",
        "---\n",
        "\n",
        "Example:\n",
        "\n",
        "for a sequence (v1,t1) (v2,t2) (v3,t3) (v4,t4)\n",
        "\n",
        "(v1,t1) (v2,t2)\n",
        "\n",
        "(v2,t2) (v3,t3)\n",
        "\n",
        "(v3,t3) (v4,t4)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onphkt15fffb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ed9cffd0-d22f-49ce-f423-0a2601e28954"
      },
      "source": [
        "# create all possible subsequences from the above sequence (maintaining the order)\n",
        "# we need a length of atleast 2 for feature and the label, ignore all sequence of events less than length 2\n",
        "\n",
        "\n",
        "# LSTM will remember that v2 comes after v1 and that v3 comes after v2 and if it sees v3 then next would be v4\n",
        "\n",
        "%%time\n",
        "\n",
        "def _generate_subsequence(data):\n",
        "  all_sequences = []\n",
        "  for sequence in data:  \n",
        "    if len(sequence) >= 2:\n",
        "      sequences = []\n",
        "      for i in range(0,len(sequence)-1):\n",
        "          sequences.append(sequence[i:i+2])          \n",
        "      all_sequences.append(sequences)\n",
        "  return all_sequences\n",
        "\n",
        "\n",
        "#old way of creating sub sequences \n",
        "# (v1,t1) (v2,t2)\n",
        "# (v1,t1) (v2,t2) (v3,t3)\n",
        "# (v1,t1) (v2,t2) (v3,t3) (v4,t4)\n",
        "\n",
        "'''\n",
        "def _generate_subsequence(data):\n",
        "  all_sequences = []\n",
        "  for sequence in data:  \n",
        "    if len(sequence) > 2:\n",
        "      for i in range(0,1):\n",
        "        sequences = []\n",
        "        for j in range(i+2,len(sequence)+1):      \n",
        "          sequences.append(sequence[i:j])          \n",
        "        all_sequences.append(sequences)\n",
        "  return all_sequences\n",
        "'''\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 7.15 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad3Oc0gJANKK",
        "colab_type": "text"
      },
      "source": [
        "# **2. Encoding**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIk1Mp7aARtr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "a9013c26-0686-498e-ffd0-1febd09b7eac"
      },
      "source": [
        "%time\n",
        "\n",
        "events = _generate_events(Checkin_u1205_nodup)\n",
        "print(\"Events\")\n",
        "print(events)\n",
        "\n",
        "#sequences = _generate_subsequence(events)\n",
        "#print(\"Subsequences\")\n",
        "#print(sequences)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.01 µs\n",
            "Events\n",
            "[[['v73805', 540], ['v9884', 660], ['v3906', 780], ['v10373', 900], ['v9884', 1020]], [['v9885', 540], ['v10373', 660], ['v9885', 780], ['v2927', 900]], [['v6013', 540], ['v67648', 660], ['v37724', 780], ['v13235', 840], ['v85343', 900], ['v9884', 1020], ['v55736', 1140], ['v18477', 1200], ['v9885', 1260]], [['v6013', 480], ['v342', 600], ['v69205', 660], ['v128', 720], ['v52425', 780], ['v17926', 840], ['v67615', 900], ['v19062', 960], ['v9884', 1080], ['v18477', 1200], ['v9885', 1260]], [['v6013', 480], ['v9820', 600], ['v19062', 660], ['v67615', 780], ['v37724', 840], ['v16610', 900], ['v5488', 1020], ['v73805', 1080], ['v10373', 1140], ['v9885', 1200]], [['v6013', 480], ['v342', 600], ['v69205', 660], ['v81833', 720], ['v37724', 780], ['v67615', 840], ['v72562', 900], ['v580', 1020], ['v9884', 1080], ['v9885', 1200]], [['v7598', 480], ['v36222', 600], ['v9884', 780], ['v272', 900], ['v10373', 1140], ['v9885', 1260]], [['v10373', 480], ['v9884', 720], ['v10373', 780]], [['v18477', 540], ['v73805', 600], ['v36222', 780], ['v9884', 960], ['v9885', 1260]], [['v55736', 420], ['v6013', 480], ['v81833', 720], ['v37724', 780], ['v67615', 840], ['v72336', 900], ['v68631', 960], ['v7467', 1020], ['v36222', 1140], ['v73805', 1200], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v81833', 720], ['v37724', 780], ['v72336', 900], ['v68631', 960], ['v74832', 1020], ['v9884', 1080], ['v73805', 1140], ['v18477', 1260], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v342', 600], ['v68631', 660], ['v81833', 720], ['v72336', 900], ['v16061', 960], ['v9885', 1080], ['v9885', 1200]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v81833', 720], ['v69205', 840], ['v72562', 960], ['v580', 1020], ['v9884', 1080], ['v36222', 1200], ['v9885', 1260]], [['v55736', 420], ['v6013', 480], ['v342', 660], ['v9106', 720], ['v37724', 780], ['v67615', 840], ['v72562', 960], ['v5488', 1020], ['v73805', 1080], ['v36222', 1200], ['v9885', 1260]], [['v10373', 660], ['v18477', 840], ['v36222', 960], ['v9884', 1020], ['v74015', 1080], ['v36075', 1140], ['v9885', 1200]], [['v18477', 840], ['v9884', 900], ['v10373', 960], ['v9885', 1200]], [['v6013', 480], ['v342', 660], ['v81833', 720], ['v37724', 840], ['v67615', 900], ['v27571', 1020], ['v9884', 1140], ['v36222', 1200], ['v9885', 1260]], [['v55736', 420], ['v6013', 480], ['v342', 600], ['v83549', 660], ['v81833', 720], ['v72336', 840], ['v580', 1020], ['v9884', 1080], ['v73805', 1200], ['v9885', 1260]], [['v342', 660], ['v81833', 720], ['v37724', 840], ['v68631', 900], ['v16061', 960], ['v9884', 1080], ['v10373', 1140], ['v9885', 1260]], [['v73117', 420], ['v6013', 480], ['v342', 660], ['v52425', 840], ['v67615', 900], ['v72562', 960], ['v5488', 1020], ['v18470', 1080], ['v73805', 1200], ['v9885', 1260]], [['v9688', 420], ['v10937', 480], ['v6013', 540], ['v342', 660], ['v41', 720], ['v37724', 840], ['v68631', 960], ['v9884', 1080], ['v10373', 1140], ['v18477', 1200], ['v9885', 1260]], [['v7598', 600], ['v18477', 660], ['v18470', 720], ['v36222', 840], ['v9884', 960], ['v25103', 1080], ['v9885', 1200]], [['v73805', 540]], [['v18477', 1020], ['v73805', 1080], ['v10373', 1140], ['v36222', 1200], ['v9885', 1260]], [['v74378', 480], ['v36222', 720], ['v10373', 840], ['v73117', 900], ['v18477', 1020], ['v9884', 1140], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v85343', 720], ['v57806', 780], ['v68631', 840], ['v68287', 1020], ['v9884', 1080], ['v10373', 1140], ['v18477', 1200], ['v9885', 1260]], [['v342', 720], ['v85523', 780], ['v37724', 840], ['v68631', 900], ['v31855', 960], ['v42094', 1020], ['v36222', 1140], ['v10373', 1200], ['v9885', 1260]], [['v10937', 480], ['v6013', 540], ['v342', 600], ['v68631', 780], ['v72336', 840], ['v37724', 900], ['v52425', 960], ['v42094', 1020], ['v9884', 1080], ['v36222', 1200], ['v73805', 1260], ['v9885', 1320]], [['v18477', 840], ['v9884', 960], ['v10373', 1140], ['v73805', 1200], ['v9885', 1260]], [['v36222', 540], ['v9884', 960], ['v18477', 1080], ['v73805', 1140], ['v9885', 1200]], [['v9688', 420], ['v6013', 480], ['v31855', 720], ['v19062', 780], ['v37724', 840], ['v68631', 960], ['v9884', 1080], ['v10373', 1140], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v81833', 720], ['v37724', 900], ['v72336', 960], ['v580', 1020], ['v9884', 1080], ['v10373', 1140], ['v18477', 1200], ['v73805', 1260], ['v9885', 1320]], [['v55736', 420], ['v6013', 480], ['v342', 600], ['v16061', 660], ['v9106', 720], ['v37724', 780], ['v67615', 840], ['v72336', 900], ['v580', 1020], ['v10373', 1080], ['v73805', 1140], ['v36222', 1200], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v81833', 720], ['v37724', 840], ['v72336', 900], ['v67615', 960], ['v580', 1020], ['v9884', 1080], ['v10373', 1140], ['v73805', 1200], ['v9885', 1260]], [['v9688', 420], ['v10937', 480], ['v6013', 540], ['v57806', 600], ['v342', 660], ['v4134', 780], ['v83549', 840], ['v84331', 900], ['v9884', 1080], ['v10373', 1200], ['v9885', 1260]], [['v7598', 540], ['v77608', 660], ['v73805', 840], ['v36222', 960], ['v9884', 1140], ['v10373', 1200], ['v9885', 1260]], [['v10373', 660], ['v18477', 840], ['v36222', 900], ['v2235', 1020], ['v1800', 1080], ['v73805', 1140], ['v9885', 1200]], [['v55736', 420], ['v6013', 480], ['v342', 600], ['v16061', 660], ['v37724', 780], ['v68631', 840], ['v72336', 960], ['v9884', 1080], ['v10373', 1140], ['v18477', 1200], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v342', 600], ['v81833', 720], ['v37724', 780], ['v67615', 840], ['v72336', 960], ['v580', 1020], ['v9884', 1080], ['v18477', 1140], ['v73805', 1200], ['v9885', 1260]], [['v55736', 420], ['v6013', 480], ['v342', 660], ['v9106', 720], ['v37724', 780], ['v68631', 840], ['v69205', 900], ['v9885', 1080], ['v18477', 1140], ['v36222', 1200], ['v9885', 1260]], [['v73117', 420], ['v6013', 480], ['v342', 660], ['v31855', 720], ['v16061', 1020], ['v5488', 1080], ['v10373', 1140], ['v9885', 1200]], [['v9688', 420], ['v6013', 480], ['v1038', 720], ['v37724', 780], ['v67615', 840], ['v1989', 960], ['v45158', 1080], ['v9884', 1140], ['v18477', 1200], ['v9885', 1260]], [['v33102', 600], ['v9884', 660], ['v10373', 1080], ['v18477', 1140], ['v9885', 1260]], [['v9884', 780]], [['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v37724', 780], ['v69205', 840], ['v68631', 900], ['v72336', 960], ['v45158', 1020], ['v9884', 1080], ['v10373', 1140], ['v18477', 1260], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v57806', 600], ['v342', 660], ['v9820', 720], ['v37724', 780], ['v68631', 840], ['v4647', 1140], ['v10373', 1200], ['v9885', 1260]], [['v4647', 960], ['v68287', 1020], ['v9884', 1080], ['v10373', 1140], ['v18477', 1200], ['v73805', 1260], ['v9885', 1320]], [['v6013', 480], ['v342', 660], ['v37724', 840], ['v68631', 900], ['v72336', 960], ['v580', 1020], ['v5488', 1080], ['v18477', 1140], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v37724', 780], ['v68631', 840], ['v16061', 900], ['v72336', 960], ['v1989', 1020], ['v18477', 1260], ['v9885', 1320]], [['v10373', 900], ['v18477', 960], ['v58116', 1140], ['v36222', 1200], ['v73805', 1260], ['v9885', 1380]], [['v7598', 540], ['v36222', 660], ['v9884', 960], ['v18470', 1140], ['v73805', 1200], ['v18477', 1260], ['v9885', 1320]], [['v73117', 420], ['v6013', 480], ['v342', 660], ['v81833', 720], ['v37724', 780], ['v68631', 900], ['v67615', 960], ['v4647', 1020], ['v10373', 1080], ['v18477', 1200], ['v73805', 1260], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v81', 720], ['v455', 780], ['v68631', 840], ['v72336', 900], ['v16061', 960], ['v9884', 1020], ['v73805', 1140], ['v10373', 1200], ['v9885', 1260]], [['v18477', 720], ['v25361', 960], ['v33102', 1080], ['v73805', 1200], ['v9885', 1260]], [['v10937', 480], ['v57806', 600], ['v6013', 660], ['v9106', 720], ['v68631', 840], ['v342', 960], ['v42094', 1020], ['v9884', 1080], ['v10373', 1140], ['v18477', 1200], ['v9885', 1260]], [['v73117', 420], ['v84331', 540], ['v6013', 600], ['v342', 660], ['v81', 720], ['v52425', 840], ['v72336', 900], ['v68631', 960], ['v9884', 1080], ['v18477', 1260], ['v9885', 1320]], [['v77608', 600], ['v8286', 840], ['v4972', 1080], ['v9885', 1320]], [['v10373', 720], ['v36222', 780], ['v10373', 1080], ['v18477', 1140], ['v73805', 1200], ['v9885', 1260]], [['v6013', 480], ['v342', 600], ['v16061', 660], ['v68631', 780], ['v37724', 840], ['v67615', 960], ['v4647', 1020], ['v9884', 1080], ['v18477', 1200], ['v73805', 1260], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v57806', 660], ['v81833', 720], ['v13235', 840], ['v45158', 960], ['v580', 1020], ['v9884', 1080], ['v10373', 1140], ['v18477', 1200], ['v73805', 1260], ['v9885', 1320]], [['v6013', 480], ['v81833', 660], ['v19062', 720], ['v37724', 780], ['v68631', 840], ['v67615', 900], ['v69205', 960], ['v33102', 1080], ['v73056', 1200], ['v10373', 1260], ['v9885', 1320]], [['v6013', 480], ['v342', 660], ['v68631', 840], ['v37724', 900], ['v580', 1020], ['v73805', 1080], ['v18477', 1140], ['v9885', 1200]], [['v9688', 420], ['v6013', 480], ['v81', 720], ['v37724', 780], ['v68631', 900], ['v16061', 960], ['v580', 1020], ['v9885', 1080], ['v9884', 1140], ['v10373', 1200], ['v73805', 1320]], [['v10373', 660], ['v33102', 840], ['v9884', 900], ['v18477', 1080], ['v9885', 1320]], [['v7598', 600], ['v10373', 660], ['v73805', 960], ['v9884', 1020], ['v18477', 1140], ['v9885', 1380]], [['v73117', 420], ['v6013', 480], ['v342', 660], ['v37724', 840], ['v68631', 900], ['v16061', 960], ['v45158', 1020], ['v9884', 1080], ['v10373', 1140], ['v18477', 1200], ['v73805', 1260], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v81833', 720], ['v37724', 780], ['v68631', 840], ['v16061', 960], ['v580', 1020], ['v9884', 1080], ['v10373', 1140], ['v36222', 1200], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v342', 600], ['v68631', 900], ['v37724', 960], ['v5488', 1080], ['v10373', 1140], ['v36222', 1200], ['v18477', 1260], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v57806', 660], ['v37724', 720], ['v68631', 780], ['v16061', 900], ['v52425', 960], ['v580', 1020], ['v8286', 1080], ['v22696', 1200], ['v18477', 1260], ['v9885', 0], ['v73117', 420], ['v6013', 480], ['v342', 660], ['v52425', 780], ['v72336', 840], ['v69205', 960], ['v580', 1020], ['v9884', 1080], ['v18477', 1200], ['v9885', 1260]], [['v7598', 480], ['v761', 600], ['v36222', 720], ['v10373', 1020], ['v73805', 1260], ['v9885', 1320]], [['v7598', 540], ['v18477', 600], ['v10373', 840], ['v25361', 960], ['v73805', 1020], ['v10373', 1140], ['v9885', 1260]], [['v18608', 600], ['v73117', 660], ['v36222', 900], ['v3862', 1080], ['v73805', 1140], ['v18477', 1200], ['v10373', 1260], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v544', 720], ['v37724', 780], ['v68631', 840], ['v72336', 900], ['v69205', 960], ['v45158', 1020], ['v9884', 1080], ['v10373', 1140], ['v18477', 1200], ['v73805', 1260], ['v9885', 1320]], [['v342', 720], ['v16061', 840], ['v68631', 960], ['v10509', 1080], ['v18608', 1140], ['v73805', 1200], ['v18477', 1260], ['v9885', 1320]], [['v74015', 420], ['v73805', 540], ['v8286', 720], ['v10373', 840], ['v9884', 1020], ['v7733', 1080], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v81', 720], ['v2901', 780], ['v37724', 840], ['v16061', 960], ['v9884', 1140], ['v18477', 1200], ['v73805', 1260], ['v9885', 1320]], [['v7598', 600], ['v9884', 780], ['v1181', 1020], ['v2514', 1140], ['v10373', 1200], ['v10373', 1260], ['v9885', 1320]], [['v9884', 540], ['v73805', 960], ['v18477', 1140], ['v9885', 1200]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v37724', 720], ['v52425', 840], ['v67615', 900], ['v23178', 1020], ['v73805', 1080], ['v18477', 1140], ['v10373', 1200], ['v9885', 1320]], [['v6013', 480], ['v342', 600], ['v68631', 840], ['v4647', 1020], ['v9884', 1080], ['v73805', 1140], ['v18477', 1200], ['v9885', 1260]], [['v55736', 420], ['v6013', 480], ['v342', 600], ['v52425', 720], ['v37724', 840], ['v67615', 900], ['v72336', 960], ['v5488', 1020], ['v9884', 1080], ['v18477', 1140], ['v73805', 1200], ['v9885', 1320]], [['v73117', 480], ['v74015', 540], ['v8286', 780], ['v10373', 900], ['v73805', 1200], ['v9885', 1260]], [['v6013', 480], ['v342', 660], ['v739', 720], ['v37724', 900], ['v68631', 960], ['v7467', 1020], ['v9884', 1080], ['v73056', 1200], ['v9885', 1260]], [['v73805', 540]], [['v9884', 1080], ['v10373', 1140], ['v18477', 1260], ['v9885', 1320]], [['v57437', 480], ['v14537', 780], ['v22801', 840], ['v18608', 900], ['v10373', 960], ['v9884', 1020], ['v73805', 1080], ['v18477', 1200], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v342', 600], ['v16061', 660], ['v37724', 780], ['v68631', 840], ['v69205', 1020], ['v73782', 1080], ['v9884', 1140], ['v73805', 1200], ['v18477', 1260], ['v9885', 1320]], [['v6013', 480], ['v55', 540], ['v342', 600], ['v37724', 780], ['v68631', 840], ['v72336', 900], ['v52425', 1020], ['v17295', 1200], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v37724', 780], ['v52425', 960], ['v580', 1080], ['v10373', 1140], ['v9885', 1320]], [['v6013', 480], ['v342', 600], ['v37724', 840], ['v68631', 900], ['v52425', 960], ['v580', 1020], ['v33102', 1080], ['v17295', 1200], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v342', 600], ['v37724', 660], ['v10937', 780], ['v9884', 900], ['v73056', 1080], ['v18477', 1200], ['v9885', 1320]], [['v63824', 780], ['v9884', 900], ['v18477', 1080], ['v10373', 1200], ['v9885', 1320]], [['v9885', 540]], [['v73805', 1320], ['v9885', 1380]], [['v73056', 720], ['v9884', 780]], [['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v68631', 840], ['v72336', 960], ['v7467', 1020], ['v9884', 1080], ['v73056', 1140], ['v18477', 1200], ['v9885', 1260]], [['v73117', 540], ['v10373', 600], ['v36222', 720], ['v73805', 840], ['v9884', 1140], ['v9885', 1200]], [['v9688', 420], ['v6013', 540], ['v342', 600], ['v37724', 780], ['v68631', 840], ['v5488', 1020], ['v33102', 1080], ['v9885', 1320]], [['v9688', 420], ['v6013', 540], ['v16061', 660], ['v1038', 780], ['v37724', 840], ['v72336', 900], ['v7467', 1020], ['v9884', 1080], ['v10373', 1140], ['v73805', 1200], ['v9885', 1320]], [['v7598', 540], ['v18608', 660], ['v9884', 720], ['v10373', 900], ['v10509', 960], ['v73805', 1020], ['v36222', 1200], ['v9885', 1380]], [['v7598', 540]], [['v10373', 1020], ['v549', 1200], ['v9885', 1320]], [['v60129', 480], ['v6013', 540], ['v342', 660], ['v72336', 720], ['v68631', 840], ['v69205', 960], ['v48253', 1080], ['v9884', 1140], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v342', 600], ['v16061', 660], ['v37724', 840], ['v67615', 960], ['v5488', 1080], ['v33102', 1140], ['v17295', 1200], ['v9884', 1260], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v342', 600], ['v9106', 720], ['v37724', 840], ['v16061', 900], ['v72336', 960], ['v7467', 1080], ['v10373', 1200], ['v18477', 1260], ['v9885', 1320]], [['v9688', 420], ['v60129', 480], ['v342', 600], ['v128', 720], ['v37724', 780], ['v81', 1020], ['v9884', 1140], ['v10373', 1200], ['v9885', 1260]], [['v6013', 480], ['v342', 660], ['v73056', 840], ['v7598', 900], ['v9884', 960], ['v22696', 1140], ['v9885', 1260]], [['v7598', 540], ['v33102', 840], ['v18608', 960], ['v18477', 1200], ['v9884', 1260], ['v9885', 1380]], [['v22696', 540], ['v18477', 900], ['v10373', 1020], ['v9884', 1080], ['v73056', 1200], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v3455', 720], ['v37724', 780], ['v68631', 840], ['v10373', 1080], ['v18477', 1140], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v55', 540], ['v342', 660], ['v1648', 720], ['v37724', 900], ['v69205', 960], ['v9884', 1080], ['v10373', 1140], ['v18477', 1200], ['v9885', 1320]], [['v342', 660], ['v37724', 780], ['v68631', 960], ['v580', 1020], ['v9884', 1080], ['v73805', 1140], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v342', 600], ['v995', 720], ['v2901', 780], ['v1892', 840], ['v74832', 1020], ['v9884', 1080], ['v10373', 1260], ['v9885', 1320]], [['v10373', 480]], [['v580', 960], ['v47095', 1020], ['v5664', 1260], ['v11935', 1380], ['v9885', 240]], [['v18477', 960], ['v1743', 1080], ['v9885', 1260]], [['v73117', 420], ['v7598', 600], ['v36222', 720], ['v18477', 900], ['v10373', 960], ['v9884', 1080], ['v33102', 1140], ['v17492', 1200], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v72336', 960], ['v68631', 1020], ['v7467', 1080], ['v18477', 1200], ['v9885', 1260]], [['v60129', 480], ['v6013', 600], ['v342', 660], ['v544', 720], ['v24553', 780], ['v9884', 1140], ['v22696', 1200], ['v9885', 1320]], [['v60129', 480], ['v6013', 540], ['v81', 720], ['v342', 780], ['v37724', 840], ['v7467', 1080], ['v9884', 1140], ['v18477', 1200], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v342', 540], ['v68631', 600], ['v72336', 660], ['v1236', 780], ['v18608', 1020], ['v3197', 1080], ['v73047', 1140], ['v7587', 1260], ['v9885', 1320]], [['v7598', 480], ['v324', 660], ['v9884', 720], ['v74015', 780], ['v73056', 840], ['v16563', 960], ['v1842', 1080], ['v59516', 1200], ['v2173', 120], ['v9885', 180]], [['v9884', 660], ['v33102', 900], ['v10373', 1020], ['v999', 1140], ['v132', 1260], ['v80414', 1320], ['v9885', 0], ['v9688', 420], ['v6013', 480], ['v342', 720], ['v41', 780], ['v72336', 900], ['v68631', 960], ['v9884', 1080], ['v10373', 1140], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v342', 600], ['v82238', 660], ['v2496', 720], ['v37724', 780], ['v68631', 840], ['v67615', 960], ['v10373', 1140], ['v66545', 1260], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v71717', 900], ['v580', 1020], ['v475', 1080], ['v9884', 1140]], [['v9688', 420], ['v6013', 480], ['v3455', 780], ['v67615', 960], ['v1989', 1020], ['v41', 1200], ['v9885', 60], ['v9688', 420], ['v6013', 480], ['v37724', 840], ['v9884', 1080], ['v18608', 1140], ['v10373', 1200], ['v9885', 1260]], [['v53362', 600], ['v9884', 660], ['v36222', 720], ['v18470', 840], ['v67869', 1140], ['v2100', 1320], ['v1075', 0]], [['v10373', 540]], [['v54459', 1140], ['v1236', 1200], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v342', 600], ['v128', 720], ['v68631', 840], ['v72336', 900], ['v9884', 1140], ['v18477', 1200], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v81833', 720], ['v37724', 780], ['v1989', 960], ['v63', 1080], ['v7467', 1200], ['v9884', 1260], ['v18477', 1320], ['v9885', 1380]], [['v2927', 540], ['v10373', 600], ['v82822', 660], ['v2487', 720], ['v195', 780], ['v18477', 840], ['v85781', 900], ['v10224', 960], ['v43126', 1140], ['v9885', 1380]], [['v1120', 720], ['v9884', 960], ['v36222', 1080], ['v9885', 1200]], [['v7598', 540], ['v73056', 600], ['v46400', 720], ['v18477', 1020], ['v9885', 1320]], [['v1743', 600]], [['v9884', 1080], ['v10373', 1200], ['v66545', 1260], ['v9885', 1320]], [['v7598', 540], ['v10373', 900], ['v9884', 960], ['v18477', 1200], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v41', 780], ['v37724', 840], ['v342', 900], ['v9884', 1080], ['v18477', 1200], ['v73805', 1260], ['v9885', 1380]], [['v9688', 420], ['v6013', 480], ['v342', 600], ['v46400', 720], ['v37724', 780], ['v68631', 840], ['v69205', 900], ['v72336', 960], ['v580', 1020], ['v9884', 1080], ['v10373', 1140], ['v66545', 1260], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v342', 600], ['v68631', 840], ['v43531', 1020], ['v9884', 1080], ['v18608', 1140], ['v10373', 1260], ['v9885', 60], ['v9688', 420], ['v6013', 480], ['v342', 600], ['v41', 720], ['v24553', 780], ['v69205', 960], ['v42094', 1020], ['v9884', 1080], ['v18477', 1200]], [['v9688', 420], ['v60129', 480], ['v6013', 540], ['v342', 600], ['v68631', 660], ['v2496', 780], ['v37724', 840], ['v61652', 900], ['v580', 1020], ['v9885', 1320]], [['v7598', 540], ['v18477', 720], ['v3197', 840], ['v9885', 1260]], [['v21054', 480], ['v10373', 540], ['v18477', 960], ['v9884', 1020], ['v9885', 1200]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v128', 720], ['v37724', 780], ['v68631', 960], ['v9884', 1140], ['v10373', 1200], ['v9885', 1260]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v81833', 720], ['v37724', 780], ['v72336', 900], ['v53585', 1020], ['v5488', 1080], ['v9885', 1140], ['v18477', 1200], ['v9885', 1320]], [['v9688', 420], ['v6013', 480], ['v342', 660], ['v37724', 780], ['v32892', 900], ['v580', 1080], ['v10373', 1140]], [['v6013', 480], ['v342', 540], ['v81', 720], ['v68631', 780], ['v37724', 900], ['v55', 960], ['v84346', 1020], ['v10373', 1260], ['v9885', 1320]], [['v6013', 540], ['v342', 600], ['v37724', 660], ['v9885', 780], ['v9884', 960], ['v10373', 1080], ['v549', 1200]], [['v18477', 480], ['v18477', 600], ['v5574', 720], ['v73047', 900], ['v9885', 1200]], [['v73047', 480], ['v18477', 720], ['v59516', 960]], [['v9885', 0], ['v9688', 420], ['v6013', 480], ['v41', 720], ['v37724', 780], ['v16061', 900], ['v67615', 960]], [['v45783', 840]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh95Fvpn9eE8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "0ebeb143-ebfc-44e7-887b-4c21ecc620d5"
      },
      "source": [
        "%time\n",
        "\n",
        "def _venue_only(data):\n",
        "  all_sequences = []\n",
        "  for sequence in data:\n",
        "    events = []\n",
        "    for event in sequence:      \n",
        "      events.append(event[0])\n",
        "    all_sequences.append(events)\n",
        "  return all_sequences\n",
        "\n",
        "v_events = _venue_only(events)\n",
        "print(v_events)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 7.63 µs\n",
            "[['v73805', 'v9884', 'v3906', 'v10373', 'v9884'], ['v9885', 'v10373', 'v9885', 'v2927'], ['v6013', 'v67648', 'v37724', 'v13235', 'v85343', 'v9884', 'v55736', 'v18477', 'v9885'], ['v6013', 'v342', 'v69205', 'v128', 'v52425', 'v17926', 'v67615', 'v19062', 'v9884', 'v18477', 'v9885'], ['v6013', 'v9820', 'v19062', 'v67615', 'v37724', 'v16610', 'v5488', 'v73805', 'v10373', 'v9885'], ['v6013', 'v342', 'v69205', 'v81833', 'v37724', 'v67615', 'v72562', 'v580', 'v9884', 'v9885'], ['v7598', 'v36222', 'v9884', 'v272', 'v10373', 'v9885'], ['v10373', 'v9884', 'v10373'], ['v18477', 'v73805', 'v36222', 'v9884', 'v9885'], ['v55736', 'v6013', 'v81833', 'v37724', 'v67615', 'v72336', 'v68631', 'v7467', 'v36222', 'v73805', 'v9885'], ['v9688', 'v6013', 'v81833', 'v37724', 'v72336', 'v68631', 'v74832', 'v9884', 'v73805', 'v18477', 'v9885'], ['v9688', 'v6013', 'v342', 'v68631', 'v81833', 'v72336', 'v16061', 'v9885', 'v9885'], ['v9688', 'v6013', 'v342', 'v81833', 'v69205', 'v72562', 'v580', 'v9884', 'v36222', 'v9885'], ['v55736', 'v6013', 'v342', 'v9106', 'v37724', 'v67615', 'v72562', 'v5488', 'v73805', 'v36222', 'v9885'], ['v10373', 'v18477', 'v36222', 'v9884', 'v74015', 'v36075', 'v9885'], ['v18477', 'v9884', 'v10373', 'v9885'], ['v6013', 'v342', 'v81833', 'v37724', 'v67615', 'v27571', 'v9884', 'v36222', 'v9885'], ['v55736', 'v6013', 'v342', 'v83549', 'v81833', 'v72336', 'v580', 'v9884', 'v73805', 'v9885'], ['v342', 'v81833', 'v37724', 'v68631', 'v16061', 'v9884', 'v10373', 'v9885'], ['v73117', 'v6013', 'v342', 'v52425', 'v67615', 'v72562', 'v5488', 'v18470', 'v73805', 'v9885'], ['v9688', 'v10937', 'v6013', 'v342', 'v41', 'v37724', 'v68631', 'v9884', 'v10373', 'v18477', 'v9885'], ['v7598', 'v18477', 'v18470', 'v36222', 'v9884', 'v25103', 'v9885'], ['v73805'], ['v18477', 'v73805', 'v10373', 'v36222', 'v9885'], ['v74378', 'v36222', 'v10373', 'v73117', 'v18477', 'v9884', 'v9885'], ['v9688', 'v6013', 'v342', 'v85343', 'v57806', 'v68631', 'v68287', 'v9884', 'v10373', 'v18477', 'v9885'], ['v342', 'v85523', 'v37724', 'v68631', 'v31855', 'v42094', 'v36222', 'v10373', 'v9885'], ['v10937', 'v6013', 'v342', 'v68631', 'v72336', 'v37724', 'v52425', 'v42094', 'v9884', 'v36222', 'v73805', 'v9885'], ['v18477', 'v9884', 'v10373', 'v73805', 'v9885'], ['v36222', 'v9884', 'v18477', 'v73805', 'v9885'], ['v9688', 'v6013', 'v31855', 'v19062', 'v37724', 'v68631', 'v9884', 'v10373', 'v9885'], ['v9688', 'v6013', 'v81833', 'v37724', 'v72336', 'v580', 'v9884', 'v10373', 'v18477', 'v73805', 'v9885'], ['v55736', 'v6013', 'v342', 'v16061', 'v9106', 'v37724', 'v67615', 'v72336', 'v580', 'v10373', 'v73805', 'v36222', 'v9885'], ['v9688', 'v6013', 'v342', 'v81833', 'v37724', 'v72336', 'v67615', 'v580', 'v9884', 'v10373', 'v73805', 'v9885'], ['v9688', 'v10937', 'v6013', 'v57806', 'v342', 'v4134', 'v83549', 'v84331', 'v9884', 'v10373', 'v9885'], ['v7598', 'v77608', 'v73805', 'v36222', 'v9884', 'v10373', 'v9885'], ['v10373', 'v18477', 'v36222', 'v2235', 'v1800', 'v73805', 'v9885'], ['v55736', 'v6013', 'v342', 'v16061', 'v37724', 'v68631', 'v72336', 'v9884', 'v10373', 'v18477', 'v9885'], ['v9688', 'v6013', 'v342', 'v81833', 'v37724', 'v67615', 'v72336', 'v580', 'v9884', 'v18477', 'v73805', 'v9885'], ['v55736', 'v6013', 'v342', 'v9106', 'v37724', 'v68631', 'v69205', 'v9885', 'v18477', 'v36222', 'v9885'], ['v73117', 'v6013', 'v342', 'v31855', 'v16061', 'v5488', 'v10373', 'v9885'], ['v9688', 'v6013', 'v1038', 'v37724', 'v67615', 'v1989', 'v45158', 'v9884', 'v18477', 'v9885'], ['v33102', 'v9884', 'v10373', 'v18477', 'v9885'], ['v9884'], ['v9885'], ['v9688', 'v6013', 'v37724', 'v69205', 'v68631', 'v72336', 'v45158', 'v9884', 'v10373', 'v18477', 'v9885'], ['v9688', 'v6013', 'v57806', 'v342', 'v9820', 'v37724', 'v68631', 'v4647', 'v10373', 'v9885'], ['v4647', 'v68287', 'v9884', 'v10373', 'v18477', 'v73805', 'v9885'], ['v6013', 'v342', 'v37724', 'v68631', 'v72336', 'v580', 'v5488', 'v18477', 'v9885'], ['v9688', 'v6013', 'v342', 'v37724', 'v68631', 'v16061', 'v72336', 'v1989', 'v18477', 'v9885'], ['v10373', 'v18477', 'v58116', 'v36222', 'v73805', 'v9885'], ['v7598', 'v36222', 'v9884', 'v18470', 'v73805', 'v18477', 'v9885'], ['v73117', 'v6013', 'v342', 'v81833', 'v37724', 'v68631', 'v67615', 'v4647', 'v10373', 'v18477', 'v73805', 'v9885'], ['v9688', 'v6013', 'v342', 'v81', 'v455', 'v68631', 'v72336', 'v16061', 'v9884', 'v73805', 'v10373', 'v9885'], ['v18477', 'v25361', 'v33102', 'v73805', 'v9885'], ['v10937', 'v57806', 'v6013', 'v9106', 'v68631', 'v342', 'v42094', 'v9884', 'v10373', 'v18477', 'v9885'], ['v73117', 'v84331', 'v6013', 'v342', 'v81', 'v52425', 'v72336', 'v68631', 'v9884', 'v18477', 'v9885'], ['v77608', 'v8286', 'v4972', 'v9885'], ['v10373', 'v36222', 'v10373', 'v18477', 'v73805', 'v9885'], ['v6013', 'v342', 'v16061', 'v68631', 'v37724', 'v67615', 'v4647', 'v9884', 'v18477', 'v73805', 'v9885'], ['v9688', 'v6013', 'v57806', 'v81833', 'v13235', 'v45158', 'v580', 'v9884', 'v10373', 'v18477', 'v73805', 'v9885'], ['v6013', 'v81833', 'v19062', 'v37724', 'v68631', 'v67615', 'v69205', 'v33102', 'v73056', 'v10373', 'v9885'], ['v6013', 'v342', 'v68631', 'v37724', 'v580', 'v73805', 'v18477', 'v9885'], ['v9688', 'v6013', 'v81', 'v37724', 'v68631', 'v16061', 'v580', 'v9885', 'v9884', 'v10373', 'v73805'], ['v10373', 'v33102', 'v9884', 'v18477', 'v9885'], ['v7598', 'v10373', 'v73805', 'v9884', 'v18477', 'v9885'], ['v73117', 'v6013', 'v342', 'v37724', 'v68631', 'v16061', 'v45158', 'v9884', 'v10373', 'v18477', 'v73805', 'v9885'], ['v9688', 'v6013', 'v81833', 'v37724', 'v68631', 'v16061', 'v580', 'v9884', 'v10373', 'v36222', 'v9885'], ['v9688', 'v6013', 'v342', 'v68631', 'v37724', 'v5488', 'v10373', 'v36222', 'v18477', 'v9885'], ['v9688', 'v6013', 'v57806', 'v37724', 'v68631', 'v16061', 'v52425', 'v580', 'v8286', 'v22696', 'v18477', 'v9885', 'v73117', 'v6013', 'v342', 'v52425', 'v72336', 'v69205', 'v580', 'v9884', 'v18477', 'v9885'], ['v7598', 'v761', 'v36222', 'v10373', 'v73805', 'v9885'], ['v7598', 'v18477', 'v10373', 'v25361', 'v73805', 'v10373', 'v9885'], ['v18608', 'v73117', 'v36222', 'v3862', 'v73805', 'v18477', 'v10373', 'v9885'], ['v9688', 'v6013', 'v342', 'v544', 'v37724', 'v68631', 'v72336', 'v69205', 'v45158', 'v9884', 'v10373', 'v18477', 'v73805', 'v9885'], ['v342', 'v16061', 'v68631', 'v10509', 'v18608', 'v73805', 'v18477', 'v9885'], ['v74015', 'v73805', 'v8286', 'v10373', 'v9884', 'v7733', 'v9885'], ['v9688', 'v6013', 'v342', 'v81', 'v2901', 'v37724', 'v16061', 'v9884', 'v18477', 'v73805', 'v9885'], ['v7598', 'v9884', 'v1181', 'v2514', 'v10373', 'v10373', 'v9885'], ['v9884', 'v73805', 'v18477', 'v9885'], ['v9688', 'v6013', 'v342', 'v37724', 'v52425', 'v67615', 'v23178', 'v73805', 'v18477', 'v10373', 'v9885'], ['v6013', 'v342', 'v68631', 'v4647', 'v9884', 'v73805', 'v18477', 'v9885'], ['v55736', 'v6013', 'v342', 'v52425', 'v37724', 'v67615', 'v72336', 'v5488', 'v9884', 'v18477', 'v73805', 'v9885'], ['v73117', 'v74015', 'v8286', 'v10373', 'v73805', 'v9885'], ['v6013', 'v342', 'v739', 'v37724', 'v68631', 'v7467', 'v9884', 'v73056', 'v9885'], ['v73805'], ['v9884', 'v10373', 'v18477', 'v9885'], ['v57437', 'v14537', 'v22801', 'v18608', 'v10373', 'v9884', 'v73805', 'v18477', 'v9885'], ['v9688', 'v6013', 'v342', 'v16061', 'v37724', 'v68631', 'v69205', 'v73782', 'v9884', 'v73805', 'v18477', 'v9885'], ['v6013', 'v55', 'v342', 'v37724', 'v68631', 'v72336', 'v52425', 'v17295', 'v9885'], ['v9688', 'v6013', 'v342', 'v37724', 'v52425', 'v580', 'v10373', 'v9885'], ['v6013', 'v342', 'v37724', 'v68631', 'v52425', 'v580', 'v33102', 'v17295', 'v9885'], ['v9688', 'v6013', 'v342', 'v37724', 'v10937', 'v9884', 'v73056', 'v18477', 'v9885'], ['v63824', 'v9884', 'v18477', 'v10373', 'v9885'], ['v9885'], ['v73805', 'v9885'], ['v73056', 'v9884'], ['v9885'], ['v9688', 'v6013', 'v342', 'v68631', 'v72336', 'v7467', 'v9884', 'v73056', 'v18477', 'v9885'], ['v73117', 'v10373', 'v36222', 'v73805', 'v9884', 'v9885'], ['v9688', 'v6013', 'v342', 'v37724', 'v68631', 'v5488', 'v33102', 'v9885'], ['v9688', 'v6013', 'v16061', 'v1038', 'v37724', 'v72336', 'v7467', 'v9884', 'v10373', 'v73805', 'v9885'], ['v7598', 'v18608', 'v9884', 'v10373', 'v10509', 'v73805', 'v36222', 'v9885'], ['v7598'], ['v10373', 'v549', 'v9885'], ['v60129', 'v6013', 'v342', 'v72336', 'v68631', 'v69205', 'v48253', 'v9884', 'v9885'], ['v9688', 'v6013', 'v342', 'v16061', 'v37724', 'v67615', 'v5488', 'v33102', 'v17295', 'v9884', 'v9885'], ['v9688', 'v6013', 'v342', 'v9106', 'v37724', 'v16061', 'v72336', 'v7467', 'v10373', 'v18477', 'v9885'], ['v9688', 'v60129', 'v342', 'v128', 'v37724', 'v81', 'v9884', 'v10373', 'v9885'], ['v6013', 'v342', 'v73056', 'v7598', 'v9884', 'v22696', 'v9885'], ['v7598', 'v33102', 'v18608', 'v18477', 'v9884', 'v9885'], ['v22696', 'v18477', 'v10373', 'v9884', 'v73056', 'v9885'], ['v9688', 'v6013', 'v342', 'v3455', 'v37724', 'v68631', 'v10373', 'v18477', 'v9885'], ['v9688', 'v6013', 'v55', 'v342', 'v1648', 'v37724', 'v69205', 'v9884', 'v10373', 'v18477', 'v9885'], ['v342', 'v37724', 'v68631', 'v580', 'v9884', 'v73805', 'v9885'], ['v9688', 'v6013', 'v342', 'v995', 'v2901', 'v1892', 'v74832', 'v9884', 'v10373', 'v9885'], ['v10373'], ['v580', 'v47095', 'v5664', 'v11935', 'v9885'], ['v18477', 'v1743', 'v9885'], ['v73117', 'v7598', 'v36222', 'v18477', 'v10373', 'v9884', 'v33102', 'v17492', 'v9885'], ['v9688', 'v6013', 'v342', 'v72336', 'v68631', 'v7467', 'v18477', 'v9885'], ['v60129', 'v6013', 'v342', 'v544', 'v24553', 'v9884', 'v22696', 'v9885'], ['v60129', 'v6013', 'v81', 'v342', 'v37724', 'v7467', 'v9884', 'v18477', 'v9885'], ['v9688', 'v6013', 'v342', 'v68631', 'v72336', 'v1236', 'v18608', 'v3197', 'v73047', 'v7587', 'v9885'], ['v7598', 'v324', 'v9884', 'v74015', 'v73056', 'v16563', 'v1842', 'v59516', 'v2173', 'v9885'], ['v9884', 'v33102', 'v10373', 'v999', 'v132', 'v80414', 'v9885', 'v9688', 'v6013', 'v342', 'v41', 'v72336', 'v68631', 'v9884', 'v10373', 'v9885'], ['v9688', 'v6013', 'v342', 'v82238', 'v2496', 'v37724', 'v68631', 'v67615', 'v10373', 'v66545', 'v9885'], ['v9688', 'v6013', 'v71717', 'v580', 'v475', 'v9884'], ['v9688', 'v6013', 'v3455', 'v67615', 'v1989', 'v41', 'v9885', 'v9688', 'v6013', 'v37724', 'v9884', 'v18608', 'v10373', 'v9885'], ['v53362', 'v9884', 'v36222', 'v18470', 'v67869', 'v2100', 'v1075'], ['v10373'], ['v54459', 'v1236', 'v9885'], ['v9688', 'v6013', 'v342', 'v128', 'v68631', 'v72336', 'v9884', 'v18477', 'v9885'], ['v9688', 'v6013', 'v342', 'v81833', 'v37724', 'v1989', 'v63', 'v7467', 'v9884', 'v18477', 'v9885'], ['v2927', 'v10373', 'v82822', 'v2487', 'v195', 'v18477', 'v85781', 'v10224', 'v43126', 'v9885'], ['v1120', 'v9884', 'v36222', 'v9885'], ['v7598', 'v73056', 'v46400', 'v18477', 'v9885'], ['v1743'], ['v9884', 'v10373', 'v66545', 'v9885'], ['v7598', 'v10373', 'v9884', 'v18477', 'v9885'], ['v9688', 'v6013', 'v41', 'v37724', 'v342', 'v9884', 'v18477', 'v73805', 'v9885'], ['v9688', 'v6013', 'v342', 'v46400', 'v37724', 'v68631', 'v69205', 'v72336', 'v580', 'v9884', 'v10373', 'v66545', 'v9885'], ['v9688', 'v6013', 'v342', 'v68631', 'v43531', 'v9884', 'v18608', 'v10373', 'v9885', 'v9688', 'v6013', 'v342', 'v41', 'v24553', 'v69205', 'v42094', 'v9884', 'v18477'], ['v9688', 'v60129', 'v6013', 'v342', 'v68631', 'v2496', 'v37724', 'v61652', 'v580', 'v9885'], ['v7598', 'v18477', 'v3197', 'v9885'], ['v21054', 'v10373', 'v18477', 'v9884', 'v9885'], ['v9688', 'v6013', 'v342', 'v128', 'v37724', 'v68631', 'v9884', 'v10373', 'v9885'], ['v9688', 'v6013', 'v342', 'v81833', 'v37724', 'v72336', 'v53585', 'v5488', 'v9885', 'v18477', 'v9885'], ['v9688', 'v6013', 'v342', 'v37724', 'v32892', 'v580', 'v10373'], ['v6013', 'v342', 'v81', 'v68631', 'v37724', 'v55', 'v84346', 'v10373', 'v9885'], ['v6013', 'v342', 'v37724', 'v9885', 'v9884', 'v10373', 'v549'], ['v18477', 'v18477', 'v5574', 'v73047', 'v9885'], ['v73047', 'v18477', 'v59516'], ['v9885', 'v9688', 'v6013', 'v41', 'v37724', 'v16061', 'v67615'], ['v45783']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmF8wTtylB47",
        "colab_type": "text"
      },
      "source": [
        "1. **Split the data:** \n",
        "\n",
        "---\n",
        "Before, encoding, split the data to train, validation and test set and then perform the encoding and padding. We do this to maintain integrity and structure of the data.\n",
        "\n",
        "Since we have inputs of the different length, we will have to pad each input with zeros , so that all inputs are of the same length in a mini-batch\n",
        "\n",
        "60, 20, 20 split (train, validation and test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHPoIaUzLhaR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "b072efca-8436-4afc-8c0e-896de24f0634"
      },
      "source": [
        "n = len(v_events)  \n",
        "\n",
        "n_test = int( n * .2 ) \n",
        "n_val = int( n * .2 ) \n",
        "n_train = n - (n_test+n_val)\n",
        "\n",
        "print(f\"Dataset set terms: {n}\")\n",
        "print(f\"Train set terms: {n_train}\") \n",
        "print(f\"Test set terms: {n_test}\")\n",
        "print( f\"Validation set terms: {n_val}\")\n",
        "\n",
        "train_set, val_set, test_set = data.random_split(v_events, (n_train, n_val, n_test))\n",
        "\n",
        "#the train, val and the test indices has to be whole numbers adding upto to the n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset set terms: 154\n",
            "Train set terms: 94\n",
            "Test set terms: 30\n",
            "Validation set terms: 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGKjRWeWlvzs",
        "colab_type": "text"
      },
      "source": [
        "2. **Get Max length of each set.**\n",
        "\n",
        "---\n",
        "we need this info for padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwVuB5LgeQAv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "00018f84-3e08-4bfb-9b51-b2393b68550b"
      },
      "source": [
        "#find max length of sequence for each set\n",
        "\n",
        "def _get_maxlength_seq(data):\n",
        "  t = []\n",
        "  for i in data:\n",
        "    t.append([i,len(i)])\n",
        "  temp_df = pd.DataFrame(t)\n",
        "  temp_df.sort_values(by=1, ascending=False,inplace=True)\n",
        "  return np.max(temp_df[1])\n",
        "\n",
        "max_length_train= _get_maxlength_seq(train_set)\n",
        "max_length_val= _get_maxlength_seq(val_set)\n",
        "max_length_test= _get_maxlength_seq(test_set)\n",
        "\n",
        "print(f\"max_length_train: {max_length_train}\")\n",
        "print(f\"max_length_val: {max_length_val}\")\n",
        "print(f\"max_length_test: {max_length_test}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_length_train: 14\n",
            "max_length_val: 18\n",
            "max_length_test: 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpfeL-uE8_KX",
        "colab_type": "text"
      },
      "source": [
        "3. **Padding all the inputs to have same size**\n",
        "---\n",
        "pad empty string for each sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIDFQonb85hI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30bb7a2a-60dd-4347-bd37-b1aff17b9c3d"
      },
      "source": [
        "def _padding(data, maxlength):\n",
        "  changed_data = []\n",
        "  for sequence in data:\n",
        "    c_sequence = sequence.copy()\n",
        "    if (len(c_sequence) <= maxlength and len(c_sequence) >= 2):\n",
        "      zero_length = len(c_sequence[0])\n",
        "      for i in range(maxlength-len(sequence)):\n",
        "        c_sequence.insert(0,[0*i for i in range(zero_length)])\n",
        "\n",
        "      changed_data.append(c_sequence)\n",
        "    else:\n",
        "      pass\n",
        "    \n",
        "  return np.array(changed_data)\n",
        "\n",
        "'''\n",
        "p_train_set = _padding(train_set, max_length_train)\n",
        "p_val_set = _padding(val_set, max_length_val)\n",
        "p_test_set = _padding(test_set, max_length_test)\n",
        "'''"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\np_train_set = _padding(train_set, max_length_train)\\np_val_set = _padding(val_set, max_length_val)\\np_test_set = _padding(test_set, max_length_test)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsiIJ97zbXIC",
        "colab_type": "text"
      },
      "source": [
        "4. **One hot ecoding** of the the venues.\n",
        "\n",
        "----\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8-T1nChONp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class one_hot_char_coding(object):\n",
        "  def __init__(self):\n",
        "    self.word2idx = {}\n",
        "    self.idx2word = []\n",
        "    self.length = 0\n",
        "\n",
        "  def add_word(self, word):\n",
        "    if word not in self.idx2word:\n",
        "      self.idx2word.append(word)\n",
        "      self.word2idx[word] = self.length + 1\n",
        "      self.length += 1\n",
        "    return self.word2idx[word]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.idx2word)\n",
        "\n",
        "  def onehot_encoded(self, word):\n",
        "    vec = [i*0 for i in range(self.length)]\n",
        "    vec[self.word2idx[word]-1] = 1\n",
        "    return vec\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9SAVfWaOPM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b47b4041-b6a9-4dc8-fa39-e15700ac4cf5"
      },
      "source": [
        "#%time\n",
        "#get codes for all the words \n",
        "\n",
        "coded_obj = one_hot_char_coding()\n",
        "\n",
        "for word in Checkin_u1205_nodup.VenueID.values:\n",
        "    coded_obj.add_word(word)\n",
        "\n",
        "#print(coded_obj.word2idx)\n",
        "#'v73805': 1, 'v9884': 2, 'v3906': 3, 'v10373\n",
        "#print(len(coded_obj.onehot_encoded(\"v3906\")))\n",
        "\n",
        "#here we have 139 unique values, so the one hot encoded vector is 139 length long\n",
        "\n",
        "'''def _one_hot_code(data):\n",
        "  all_seq = []\n",
        "  for sequence in data:    \n",
        "    eve = []\n",
        "    if(len(sequence)>1):\n",
        "      for index, event in enumerate(sequence):\n",
        "        eve.append(coded_obj.onehot_encoded(event))\n",
        "      all_seq.append(eve)\n",
        "  return all_seq\n",
        "\n",
        "'''\n",
        "#test3 = _one_hot_code(train_set)\n",
        "#test3 = _padding(test3,9)\n",
        "#test3\n",
        "#temp2 = torch.from_numpy(test3)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def _one_hot_code(data):\\n  all_seq = []\\n  for sequence in data:    \\n    eve = []\\n    if(len(sequence)>1):\\n      for index, event in enumerate(sequence):\\n        eve.append(coded_obj.onehot_encoded(event))\\n      all_seq.append(eve)\\n  return all_seq\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhtMDtpqMVOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _one_hot_code_target(data):\n",
        "  all_seq = []\n",
        "  for event in data:    \n",
        "    all_seq.append(coded_obj.onehot_encoded(event))\n",
        "  return np.array(all_seq)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDrBqglln8cH",
        "colab_type": "text"
      },
      "source": [
        "4. **Tensor implementation of one hot encoding**\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWWym6paoCgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "all_venues = {}\n",
        "n_venues = len(Checkin_u1205_nodup.VenueID.unique())\n",
        "all_venues_list = Checkin_u1205_nodup.VenueID.unique()\n",
        "\n",
        "#create a overall index for all the venues\n",
        "def _all_venue_index():\n",
        "  count = 1\n",
        "  for venue in Checkin_u1205_nodup.VenueID.unique():\n",
        "    all_venues[venue] = count\n",
        "    count+=1\n",
        "  return all_venues\n",
        "\n",
        "_all_venue_index()\n",
        "\n",
        "def venueToIndex(venue):\n",
        "    return all_venues.get(venue)\n",
        "\n",
        "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
        "def venueToTensor(venue):\n",
        "    tensor = torch.zeros(1, n_venues)\n",
        "    tensor[0][venueToIndex(venue)] = 1\n",
        "    return tensor\n",
        "\n",
        "def venuesToTensor(venues):\n",
        "    tensor = torch.zeros(len(venues), 1, n_venues)\n",
        "    for index, venue in enumerate(venues):\n",
        "        tensor[index][0][venueToIndex(venue)] = 1\n",
        "    return tensor\n",
        "\n",
        "def venuesequenceToTensor(venues, max_length):\n",
        "    tensor = torch.zeros(max_length, len(venues), n_venues)\n",
        "    for i, sequence in enumerate(venues):\n",
        "      for j, venue in enumerate(sequence) :\n",
        "        tensor[j][i][venueToIndex(venue)] = 1\n",
        "    return tensor\n",
        "\n",
        "#print(venuesToTensor(targets).size())\n",
        "#print(venuesequenceToTensor(features, max_length_train-1).size())\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcdRb49nZyix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#max_length_train\n",
        "#X_train_features_categorical\n",
        "#X_train_features_categorical"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOld9ao6mjOL",
        "colab_type": "text"
      },
      "source": [
        "5. **Encoding time:**\n",
        "---\n",
        "Time is cyclical feature so it will be encoded as Time Column = Sin(Time) + Cosine(Time). This will maintain the cyclic nature of the data.\n",
        "\n",
        "sequence with less than 2 will be descarded as they cannot be used to predict\n",
        "\n",
        "`note: this part is currently not in use`\n",
        "\n",
        "Including time with location for modeling will be included later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ_nlVVBr7jX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ecb3efd0-1193-4d72-d798-95a6c16beaa2"
      },
      "source": [
        "%time\n",
        "\n",
        "def _assign_code(data):\n",
        "  temp_row=[]\n",
        "  for row in data:    \n",
        "    temp_event = []\n",
        "    for event in row:   \n",
        "      venue_id = coded_obj.onehot_encoded(event[0])\n",
        "      time_sine = np.sin(2 * np.pi * event[1]/23.0)\n",
        "      time_cos = np.cos(2 * np.pi * event[1]/23.0)\n",
        "      temp_event.append([venue_id, time_sine, time_cos])\n",
        "    if(len(temp_event) >= 2):\n",
        "      temp_row.append(temp_event)\n",
        "  return temp_row\n",
        " \n",
        "#train_set_e = _assign_code(train_set)\n",
        "#print(f\"Number of inputs less than 2 is: {len(train_set) - len(train_set_e)}\") \n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.25 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Memj7VEnC6V",
        "colab_type": "text"
      },
      "source": [
        "6. **Features and Labels**\n",
        "\n",
        "---\n",
        "Last event will be the target, so split the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE0U1Hw6M8VV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _separate_x_y(data):\n",
        "  x = data[:-1]\n",
        "  y = data[-1]\n",
        "  return [x,y]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMOAaduqAIY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _feature_label(data):\n",
        "  X_data, Y_data = [], []\n",
        "  for row in data:\n",
        "    if(len(row) >= 2):\n",
        "      temp = _separate_x_y(row)\n",
        "      x,y = temp[0], temp[1]\n",
        "      X_data.append(x)\n",
        "      Y_data.append(y)\n",
        "  return [X_data, Y_data]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyh02zMcUkI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#no splitting for Keras Model\n",
        "def _feature_label2(data):\n",
        "  X_data = []\n",
        "  for row in data:\n",
        "    if(len(row) >= 2):\n",
        "      X_data.append(row)      \n",
        "  return X_data"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFul_m9edNbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06a6c932-9d41-4728-98a8-1528847980fc"
      },
      "source": [
        "#temp = _feature_label(train_set)\n",
        "#X_train, Y_train = temp[0], temp[1]\n",
        "\n",
        "'''\n",
        "X_train_m = _one_hot_code(X_train)\n",
        "X_train_m = _padding(X_train_m, max_length_train-1) #minus one due to label\n",
        "X_train_m = torch.from_numpy(X_train_m)\n",
        "X_train_m = X_train_m.float()'''\n",
        "\n",
        "#cross entropy loss expects indices of the labels and not the one hot encodings\n",
        "'''\n",
        "Y_train_m = [coded_obj.word2idx[venue] for venue in Y_train]\n",
        "Y_train_m = torch.Tensor(Y_train_m)\n",
        "'''\n",
        "\n",
        "'''\n",
        "Y_train_m = _one_hot_code_target(Y_train) #no padding required for target\n",
        "Y_train_m = torch.from_numpy(Y_train_m)'''\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nY_train_m = _one_hot_code_target(Y_train) #no padding required for target\\nY_train_m = torch.from_numpy(Y_train_m)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAs7bXaKOgjn",
        "colab_type": "text"
      },
      "source": [
        "6. **Features and labels**\n",
        "\n",
        "---\n",
        "The input for model has to be Pytorch tensor for a pytorch model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQK0HuNpOeSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_sequences = _feature_label2(train_set)\n",
        "#train_sequences_x_y = _generate_subsequence(train_sequences)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuSOK-ThO1wY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_sequences_x_y"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFyuMR5GO-W3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _ksplit_x_y(data):\n",
        "  features, targets = [], []\n",
        "  for sequence in data:\n",
        "    tempf = []\n",
        "    tempt = []\n",
        "    for event in sequence:\n",
        "      tempf.append(event[0])\n",
        "      tempt.append(event[1])\n",
        "    features.append(tempf)\n",
        "    targets.append(tempt)\n",
        "  return [features, targets]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "079Zdp2iPJPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# given a sequence, mark the last one as target and the first few as features \n",
        "\n",
        "def _new_split(data):\n",
        "  features = []\n",
        "  targets = []\n",
        "  for sequences in data:\n",
        "    if(len(sequences)) >= 2:\n",
        "      features.append(sequences[:-1])\n",
        "      targets.append(sequences[-1])\n",
        "  return features, targets\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s89PdxwYRTN",
        "colab_type": "text"
      },
      "source": [
        "# 3. **Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYq3X4qhbdyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhoDYI7W4g0u",
        "colab_type": "text"
      },
      "source": [
        "1. **Pytorch Model with both venues and time in minutes**\n",
        "---\n",
        "Simple RNN using Pytorch.\n",
        "We cannot have tensor with multiple dimensions, so this approach using Pytorch needs to be modified to make it work. Move onto to the Second model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAo-cFogQzEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.num_classes = 139\n",
        "        self.num_layers = n_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.sequence_length = 8\n",
        "\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Initializing hidden state\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        # Model\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out = out.contiguous().view(-1, self.hidden_dim)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
        "        return hidden"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdu76DFd6cix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input_size, is the number of unique ids, 139 in our case\n",
        "\n",
        "model = Model(input_size=139, output_size=1, hidden_dim=8, n_layers=2)\n",
        "# set the model to the device (default is CPU)\n",
        "#model.to(device)\n",
        "\n",
        "# hyperparameters\n",
        "n_epochs = 100\n",
        "lr=0.01\n",
        "\n",
        "# Optimizer\n",
        "#since present model is about classification Cross entropy loss is used, for prediction this has to be MSE\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eohYSfFQ-dgR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "03afc118-e9ee-4d91-b325-c0892492e7a6"
      },
      "source": [
        "# Training Run\n",
        "'''\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    optimizer.zero_grad() \n",
        "    #input_seq.to(device)\n",
        "    output, hidden = model(X_train_m)\n",
        "    loss = criterion(output, Y_train_m.view(-1).long()\n",
        "    loss.backward() # backpropagation and gradients\n",
        "    optimizer.step() # Updates the weights\n",
        "    \n",
        "    if epoch%10 == 0:\n",
        "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
        "        print(\"Loss: {:.4f}\".format(loss.item()))\n",
        "'''"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor epoch in range(1, n_epochs + 1):\\n    optimizer.zero_grad() \\n    #input_seq.to(device)\\n    output, hidden = model(X_train_m)\\n    loss = criterion(output, Y_train_m.view(-1).long()\\n    loss.backward() # backpropagation and gradients\\n    optimizer.step() # Updates the weights\\n    \\n    if epoch%10 == 0:\\n        print(\\'Epoch: {}/{}.............\\'.format(epoch, n_epochs), end=\\' \\')\\n        print(\"Loss: {:.4f}\".format(loss.item()))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcWnRj7PUFtm",
        "colab_type": "text"
      },
      "source": [
        "2. **Pytorch RNN Model with only venues**\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPsh9WIs7A5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features, targets = _new_split(train_set)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL8rmpKE5bSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8d83cb8a-f8b2-419f-c10b-b4d27bcc9a17"
      },
      "source": [
        "print(\"Size of Targets: \", venuesToTensor(targets).size())\n",
        "print(\"Size of Features\", venuesequenceToTensor(features, max_length_train-1).size())\n",
        "\n",
        "X_features_tensor = venuesequenceToTensor(features, max_length_train-1)\n",
        "Y_target_tensor = venuesToTensor(targets)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Targets:  torch.Size([86, 1, 139])\n",
            "Size of Features torch.Size([13, 86, 139])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5IG7JKo5bn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4720ce00-a477-4275-de45-403686da18f5"
      },
      "source": [
        "#training set sequences\n",
        "for i in train_set:\n",
        "  print(i)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['v7598', 'v9884', 'v1181', 'v2514', 'v10373', 'v10373', 'v9885']\n",
            "['v9884', 'v73805', 'v18477', 'v9885']\n",
            "['v9688', 'v6013', 'v71717', 'v580', 'v475', 'v9884']\n",
            "['v1120', 'v9884', 'v36222', 'v9885']\n",
            "['v55736', 'v6013', 'v342', 'v83549', 'v81833', 'v72336', 'v580', 'v9884', 'v73805', 'v9885']\n",
            "['v9688', 'v6013', 'v342', 'v37724', 'v10937', 'v9884', 'v73056', 'v18477', 'v9885']\n",
            "['v55736', 'v6013', 'v81833', 'v37724', 'v67615', 'v72336', 'v68631', 'v7467', 'v36222', 'v73805', 'v9885']\n",
            "['v7598', 'v10373', 'v9884', 'v18477', 'v9885']\n",
            "['v10373']\n",
            "['v6013', 'v342', 'v81833', 'v37724', 'v67615', 'v27571', 'v9884', 'v36222', 'v9885']\n",
            "['v10373', 'v9884', 'v10373']\n",
            "['v9688', 'v6013', 'v342', 'v37724', 'v52425', 'v580', 'v10373', 'v9885']\n",
            "['v60129', 'v6013', 'v342', 'v72336', 'v68631', 'v69205', 'v48253', 'v9884', 'v9885']\n",
            "['v9688', 'v6013', 'v57806', 'v81833', 'v13235', 'v45158', 'v580', 'v9884', 'v10373', 'v18477', 'v73805', 'v9885']\n",
            "['v9688', 'v60129', 'v342', 'v128', 'v37724', 'v81', 'v9884', 'v10373', 'v9885']\n",
            "['v6013', 'v342', 'v37724', 'v68631', 'v72336', 'v580', 'v5488', 'v18477', 'v9885']\n",
            "['v9688', 'v6013', 'v342', 'v9106', 'v37724', 'v16061', 'v72336', 'v7467', 'v10373', 'v18477', 'v9885']\n",
            "['v73805']\n",
            "['v73117', 'v6013', 'v342', 'v81833', 'v37724', 'v68631', 'v67615', 'v4647', 'v10373', 'v18477', 'v73805', 'v9885']\n",
            "['v7598', 'v77608', 'v73805', 'v36222', 'v9884', 'v10373', 'v9885']\n",
            "['v6013', 'v342', 'v37724', 'v68631', 'v52425', 'v580', 'v33102', 'v17295', 'v9885']\n",
            "['v9885']\n",
            "['v55736', 'v6013', 'v342', 'v9106', 'v37724', 'v67615', 'v72562', 'v5488', 'v73805', 'v36222', 'v9885']\n",
            "['v73117', 'v84331', 'v6013', 'v342', 'v81', 'v52425', 'v72336', 'v68631', 'v9884', 'v18477', 'v9885']\n",
            "['v9688', 'v6013', 'v81833', 'v37724', 'v68631', 'v16061', 'v580', 'v9884', 'v10373', 'v36222', 'v9885']\n",
            "['v10373', 'v549', 'v9885']\n",
            "['v9688', 'v6013', 'v342', 'v81833', 'v37724', 'v1989', 'v63', 'v7467', 'v9884', 'v18477', 'v9885']\n",
            "['v9688', 'v6013', 'v342', 'v81', 'v2901', 'v37724', 'v16061', 'v9884', 'v18477', 'v73805', 'v9885']\n",
            "['v9688', 'v6013', 'v37724', 'v69205', 'v68631', 'v72336', 'v45158', 'v9884', 'v10373', 'v18477', 'v9885']\n",
            "['v9688', 'v6013', 'v342', 'v81833', 'v37724', 'v72336', 'v67615', 'v580', 'v9884', 'v10373', 'v73805', 'v9885']\n",
            "['v9885']\n",
            "['v21054', 'v10373', 'v18477', 'v9884', 'v9885']\n",
            "['v7598', 'v18608', 'v9884', 'v10373', 'v10509', 'v73805', 'v36222', 'v9885']\n",
            "['v9688', 'v6013', 'v41', 'v37724', 'v342', 'v9884', 'v18477', 'v73805', 'v9885']\n",
            "['v9688', 'v6013', 'v342', 'v128', 'v68631', 'v72336', 'v9884', 'v18477', 'v9885']\n",
            "['v22696', 'v18477', 'v10373', 'v9884', 'v73056', 'v9885']\n",
            "['v342', 'v37724', 'v68631', 'v580', 'v9884', 'v73805', 'v9885']\n",
            "['v73047', 'v18477', 'v59516']\n",
            "['v9885', 'v10373', 'v9885', 'v2927']\n",
            "['v9688', 'v6013', 'v342', 'v68631', 'v81833', 'v72336', 'v16061', 'v9885', 'v9885']\n",
            "['v9884']\n",
            "['v73117', 'v6013', 'v342', 'v37724', 'v68631', 'v16061', 'v45158', 'v9884', 'v10373', 'v18477', 'v73805', 'v9885']\n",
            "['v9688', 'v6013', 'v342', 'v37724', 'v68631', 'v5488', 'v33102', 'v9885']\n",
            "['v9688', 'v10937', 'v6013', 'v342', 'v41', 'v37724', 'v68631', 'v9884', 'v10373', 'v18477', 'v9885']\n",
            "['v10373', 'v18477', 'v36222', 'v9884', 'v74015', 'v36075', 'v9885']\n",
            "['v9688', 'v6013', 'v342', 'v995', 'v2901', 'v1892', 'v74832', 'v9884', 'v10373', 'v9885']\n",
            "['v10373', 'v33102', 'v9884', 'v18477', 'v9885']\n",
            "['v18477', 'v73805', 'v36222', 'v9884', 'v9885']\n",
            "['v9688', 'v6013', 'v342', 'v72336', 'v68631', 'v7467', 'v18477', 'v9885']\n",
            "['v53362', 'v9884', 'v36222', 'v18470', 'v67869', 'v2100', 'v1075']\n",
            "['v7598']\n",
            "['v9688', 'v6013', 'v342', 'v128', 'v37724', 'v68631', 'v9884', 'v10373', 'v9885']\n",
            "['v9688', 'v6013', 'v342', 'v46400', 'v37724', 'v68631', 'v69205', 'v72336', 'v580', 'v9884', 'v10373', 'v66545', 'v9885']\n",
            "['v9688', 'v6013', 'v57806', 'v342', 'v9820', 'v37724', 'v68631', 'v4647', 'v10373', 'v9885']\n",
            "['v74015', 'v73805', 'v8286', 'v10373', 'v9884', 'v7733', 'v9885']\n",
            "['v7598', 'v18477', 'v3197', 'v9885']\n",
            "['v7598', 'v33102', 'v18608', 'v18477', 'v9884', 'v9885']\n",
            "['v9688', 'v6013', 'v342', 'v81', 'v455', 'v68631', 'v72336', 'v16061', 'v9884', 'v73805', 'v10373', 'v9885']\n",
            "['v10373']\n",
            "['v9884', 'v10373', 'v66545', 'v9885']\n",
            "['v6013', 'v342', 'v68631', 'v4647', 'v9884', 'v73805', 'v18477', 'v9885']\n",
            "['v7598', 'v10373', 'v73805', 'v9884', 'v18477', 'v9885']\n",
            "['v6013', 'v81833', 'v19062', 'v37724', 'v68631', 'v67615', 'v69205', 'v33102', 'v73056', 'v10373', 'v9885']\n",
            "['v580', 'v47095', 'v5664', 'v11935', 'v9885']\n",
            "['v74378', 'v36222', 'v10373', 'v73117', 'v18477', 'v9884', 'v9885']\n",
            "['v55736', 'v6013', 'v342', 'v16061', 'v37724', 'v68631', 'v72336', 'v9884', 'v10373', 'v18477', 'v9885']\n",
            "['v6013', 'v342', 'v739', 'v37724', 'v68631', 'v7467', 'v9884', 'v73056', 'v9885']\n",
            "['v9688', 'v6013', 'v342', 'v37724', 'v32892', 'v580', 'v10373']\n",
            "['v9688', 'v6013', 'v342', 'v81833', 'v37724', 'v67615', 'v72336', 'v580', 'v9884', 'v18477', 'v73805', 'v9885']\n",
            "['v73805', 'v9884', 'v3906', 'v10373', 'v9884']\n",
            "['v7598', 'v18477', 'v10373', 'v25361', 'v73805', 'v10373', 'v9885']\n",
            "['v9688', 'v6013', 'v81833', 'v37724', 'v72336', 'v68631', 'v74832', 'v9884', 'v73805', 'v18477', 'v9885']\n",
            "['v73117', 'v74015', 'v8286', 'v10373', 'v73805', 'v9885']\n",
            "['v9688', 'v6013', 'v81833', 'v37724', 'v72336', 'v580', 'v9884', 'v10373', 'v18477', 'v73805', 'v9885']\n",
            "['v6013', 'v67648', 'v37724', 'v13235', 'v85343', 'v9884', 'v55736', 'v18477', 'v9885']\n",
            "['v6013', 'v55', 'v342', 'v37724', 'v68631', 'v72336', 'v52425', 'v17295', 'v9885']\n",
            "['v55736', 'v6013', 'v342', 'v52425', 'v37724', 'v67615', 'v72336', 'v5488', 'v9884', 'v18477', 'v73805', 'v9885']\n",
            "['v73117', 'v7598', 'v36222', 'v18477', 'v10373', 'v9884', 'v33102', 'v17492', 'v9885']\n",
            "['v6013', 'v342', 'v69205', 'v81833', 'v37724', 'v67615', 'v72562', 'v580', 'v9884', 'v9885']\n",
            "['v6013', 'v342', 'v37724', 'v9885', 'v9884', 'v10373', 'v549']\n",
            "['v10937', 'v6013', 'v342', 'v68631', 'v72336', 'v37724', 'v52425', 'v42094', 'v9884', 'v36222', 'v73805', 'v9885']\n",
            "['v9688', 'v6013', 'v342', 'v68631', 'v37724', 'v5488', 'v10373', 'v36222', 'v18477', 'v9885']\n",
            "['v342', 'v16061', 'v68631', 'v10509', 'v18608', 'v73805', 'v18477', 'v9885']\n",
            "['v45783']\n",
            "['v55736', 'v6013', 'v342', 'v9106', 'v37724', 'v68631', 'v69205', 'v9885', 'v18477', 'v36222', 'v9885']\n",
            "['v36222', 'v9884', 'v18477', 'v73805', 'v9885']\n",
            "['v7598', 'v36222', 'v9884', 'v18470', 'v73805', 'v18477', 'v9885']\n",
            "['v7598', 'v73056', 'v46400', 'v18477', 'v9885']\n",
            "['v342', 'v81833', 'v37724', 'v68631', 'v16061', 'v9884', 'v10373', 'v9885']\n",
            "['v9688', 'v6013', 'v1038', 'v37724', 'v67615', 'v1989', 'v45158', 'v9884', 'v18477', 'v9885']\n",
            "['v54459', 'v1236', 'v9885']\n",
            "['v9688', 'v10937', 'v6013', 'v57806', 'v342', 'v4134', 'v83549', 'v84331', 'v9884', 'v10373', 'v9885']\n",
            "['v9688', 'v6013', 'v3455', 'v67615', 'v1989', 'v41', 'v9885', 'v9688', 'v6013', 'v37724', 'v9884', 'v18608', 'v10373', 'v9885']\n",
            "['v18477', 'v9884', 'v10373', 'v9885']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rebOddS95cAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "120dfb3b-bb2c-4195-b53d-9dda97975194"
      },
      "source": [
        "#features are the sequences and the targets are the destination\n",
        "features, targets = _new_split(train_set)\n",
        "print(features[0])\n",
        "print(targets[0])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['v7598', 'v9884', 'v1181', 'v2514', 'v10373', 'v10373']\n",
            "v9885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg0Gzl9GUQ8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "#simple model to predict the probability of next venue given a sequence of venues\n",
        "#Network\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "n_hidden = 128\n",
        "input_size = 139 #size of each input\n",
        "rnn = RNN(input_size, n_hidden, n_venues)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO100lEQqMc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1e19f43-516a-4616-c59c-b51a13bdef37"
      },
      "source": [
        "#slice the tensor to a row \n",
        "#input2[:,0]\n",
        "#X_features_tensor.size()\n",
        "#max_length_train\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99vjDjkSU7Rr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "21ea6888-4771-49f2-9887-0d3ab7c37aa3"
      },
      "source": [
        "n_hidden = 128\n",
        "#input = venueToTensor('v6013')\n",
        "input = X_features_tensor[:,0]\n",
        "\n",
        "hidden =torch.zeros(max_length_train-1, n_hidden)\n",
        "#hidden =torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input, hidden)\n",
        "print(output)\n",
        "#first parameter in hidden must be the length of venues in the input\n",
        "#number of hidden values do not matter"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-5.0176, -4.9091, -4.9454,  ..., -4.9048, -5.0261, -4.8869],\n",
            "        [-4.9541, -4.9012, -4.9439,  ..., -5.0063, -5.0019, -4.8789],\n",
            "        [-4.9651, -4.9259, -4.8820,  ..., -4.9783, -4.9686, -4.8889],\n",
            "        ...,\n",
            "        [-4.9650, -4.9251, -4.9206,  ..., -4.9687, -4.9759, -4.8920],\n",
            "        [-4.9650, -4.9251, -4.9206,  ..., -4.9687, -4.9759, -4.8920],\n",
            "        [-4.9650, -4.9251, -4.9206,  ..., -4.9687, -4.9759, -4.8920]],\n",
            "       grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_NIU_vmk076",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "78401633-b926-4e21-ab54-9ff60959d986"
      },
      "source": [
        "#get the result venue from the probabilites\n",
        "\n",
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item() -1 #since python is zero indexed\n",
        "    return all_venues_list[category_i], category_i\n",
        "\n",
        "print(categoryFromOutput(output))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('v9885', 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zPMIndxkf6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b019434-cf58-4d7a-e17a-eb94a06deb7c"
      },
      "source": [
        "all_venues_list[5-1]"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'v9885'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzLd_UCUM3vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5eSiDu7G8zT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.005\n",
        "\n",
        "def train(target, feature):\n",
        "    hidden = rnn.initHidden()\n",
        "\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    for i in range(feature.size()[0]):\n",
        "        output, hidden = rnn(feature[i], hidden)\n",
        "\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "\n",
        "    # update the weights using gradient\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
        "\n",
        "    return output, loss.item()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pm-rZ4D7txw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "33e89d7b-7a47-4670-d223-cbb9eca723fe"
      },
      "source": [
        "#target_venue_index = randomChoice(targets)\n",
        "'''\n",
        "target_venue_index = 9\n",
        "print(target_venue_index)\n",
        "print(targets[target_venue_index])\n",
        "print(all_venues[targets[target_venue_index]])\n",
        "print(features[target_venue_index])'''"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntarget_venue_index = 9\\nprint(target_venue_index)\\nprint(targets[target_venue_index])\\nprint(all_venues[targets[target_venue_index]])\\nprint(features[target_venue_index])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P2-wCds3sdr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "8456f6dc-33df-4bf2-e151-f2186679f497"
      },
      "source": [
        "import random\n",
        "\n",
        "def randomChoice(l):\n",
        "    return random.randint(0, len(l) - 1)\n",
        "\n",
        "def randomTrainingExample():\n",
        "    target_venue_index = randomChoice(targets)\n",
        "    feature_venues = features[target_venue_index]\n",
        "    target_tensor = torch.tensor([all_venues[targets[target_venue_index]]], dtype=torch.long)\n",
        "    feature_tensor = venuesToTensor(feature_venues)\n",
        "    return feature_venues, targets[target_venue_index], feature_tensor, target_tensor, target_venue_index\n",
        "\n",
        "for i in range(10):\n",
        "    feature_venues, target_s, feature_tensor, target_tensor, target_venue_index = randomTrainingExample()\n",
        "    print('feature_venues =', feature_venues, ' targets =', target_s, all_venues[targets[target_venue_index]])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature_venues = ['v10373', 'v18477', 'v36222', 'v9884', 'v74015', 'v36075']  targets = v9885 5\n",
            "feature_venues = ['v6013', 'v342', 'v37724', 'v9885', 'v9884', 'v10373']  targets = v549 88\n",
            "feature_venues = ['v6013', 'v67648', 'v37724', 'v13235', 'v85343', 'v9884', 'v55736', 'v18477']  targets = v9885 5\n",
            "feature_venues = ['v36222', 'v9884', 'v18477', 'v73805']  targets = v9885 5\n",
            "feature_venues = ['v73117', 'v6013', 'v342', 'v37724', 'v68631', 'v16061', 'v45158', 'v9884', 'v10373', 'v18477', 'v73805']  targets = v9885 5\n",
            "feature_venues = ['v6013', 'v342', 'v81833', 'v37724', 'v67615', 'v27571', 'v9884', 'v36222']  targets = v9885 5\n",
            "feature_venues = ['v9688', 'v6013', 'v71717', 'v580', 'v475']  targets = v9884 2\n",
            "feature_venues = ['v9688', 'v6013', 'v342', 'v128', 'v68631', 'v72336', 'v9884', 'v18477']  targets = v9885 5\n",
            "feature_venues = ['v55736', 'v6013', 'v342', 'v9106', 'v37724', 'v67615', 'v72562', 'v5488', 'v73805', 'v36222']  targets = v9885 5\n",
            "feature_venues = ['v9688', 'v6013', 'v342', 'v46400', 'v37724', 'v68631', 'v69205', 'v72336', 'v580', 'v9884', 'v10373', 'v66545']  targets = v9885 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMcOE3aTMsYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "700e7c35-6cac-421c-c784-6dec3bce57e7"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "n_iters = 100000\n",
        "print_every = 5000\n",
        "plot_every = 100\n",
        "\n",
        "\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for iter in range(1, n_iters + 1):\n",
        "    feature_venues, target_s, feature_tensor, target_tensor, target_venue_index = randomTrainingExample()\n",
        "    output, loss = train(target_tensor, feature_tensor)\n",
        "    current_loss += loss\n",
        "\n",
        "    # Print iter number, loss, name and guess\n",
        "    if iter % print_every == 0:\n",
        "        guess, guess_i = categoryFromOutput(output)\n",
        "        correct = '✓' if guess == target_s else '✗ (%s)' % target_s\n",
        "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, feature_venues, guess, correct))\n",
        "\n",
        "    # Add current loss avg to list of losses\n",
        "    if iter % plot_every == 0:\n",
        "        all_losses.append(current_loss / plot_every)\n",
        "        current_loss = 0"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000 5% (0m 8s) 0.0000 ['v9688', 'v6013', 'v342', 'v72336', 'v68631', 'v7467', 'v18477'] / v9885 ✓\n",
            "10000 10% (0m 16s) 0.0000 ['v9688', 'v6013', 'v342', 'v81', 'v2901', 'v37724', 'v16061', 'v9884', 'v18477', 'v73805'] / v9885 ✓\n",
            "15000 15% (0m 24s) 0.0000 ['v73117', 'v6013', 'v342', 'v37724', 'v68631', 'v16061', 'v45158', 'v9884', 'v10373', 'v18477', 'v73805'] / v9885 ✓\n",
            "20000 20% (0m 33s) 0.0000 ['v9688', 'v6013', 'v81833', 'v37724', 'v68631', 'v16061', 'v580', 'v9884', 'v10373', 'v36222'] / v9885 ✓\n",
            "25000 25% (0m 41s) 0.0001 ['v7598', 'v18477', 'v3197'] / v9885 ✓\n",
            "30000 30% (0m 50s) 0.0002 ['v36222', 'v9884', 'v18477', 'v73805'] / v9885 ✓\n",
            "35000 35% (0m 58s) 0.0000 ['v9688', 'v6013', 'v81833', 'v37724', 'v72336', 'v68631', 'v74832', 'v9884', 'v73805', 'v18477'] / v9885 ✓\n",
            "40000 40% (1m 6s) 0.0000 ['v22696', 'v18477', 'v10373', 'v9884', 'v73056'] / v9885 ✓\n",
            "45000 45% (1m 14s) 0.0000 ['v74015', 'v73805', 'v8286', 'v10373', 'v9884', 'v7733'] / v9885 ✓\n",
            "50000 50% (1m 23s) 0.0000 ['v9688', 'v60129', 'v342', 'v128', 'v37724', 'v81', 'v9884', 'v10373'] / v9885 ✓\n",
            "55000 55% (1m 31s) 0.0000 ['v6013', 'v342', 'v37724', 'v68631', 'v52425', 'v580', 'v33102', 'v17295'] / v9885 ✓\n",
            "60000 60% (1m 40s) 0.0000 ['v55736', 'v6013', 'v342', 'v83549', 'v81833', 'v72336', 'v580', 'v9884', 'v73805'] / v9885 ✓\n",
            "65000 65% (1m 48s) 0.0000 ['v9688', 'v6013', 'v3455', 'v67615', 'v1989', 'v41', 'v9885', 'v9688', 'v6013', 'v37724', 'v9884', 'v18608', 'v10373'] / v9885 ✓\n",
            "70000 70% (1m 56s) 0.0000 ['v342', 'v37724', 'v68631', 'v580', 'v9884', 'v73805'] / v9885 ✓\n",
            "75000 75% (2m 5s) 0.0000 ['v6013', 'v81833', 'v19062', 'v37724', 'v68631', 'v67615', 'v69205', 'v33102', 'v73056', 'v10373'] / v9885 ✓\n",
            "80000 80% (2m 13s) 0.0002 ['v53362', 'v9884', 'v36222', 'v18470', 'v67869', 'v2100'] / v1075 ✓\n",
            "85000 85% (2m 21s) 0.0000 ['v10373', 'v33102', 'v9884', 'v18477'] / v9885 ✓\n",
            "90000 90% (2m 30s) 0.0000 ['v7598', 'v9884', 'v1181', 'v2514', 'v10373', 'v10373'] / v9885 ✓\n",
            "95000 95% (2m 38s) 0.0495 ['v10373', 'v549'] / v9885 ✓\n",
            "100000 100% (2m 46s) 0.0000 ['v55736', 'v6013', 'v342', 'v9106', 'v37724', 'v68631', 'v69205', 'v9885', 'v18477', 'v36222'] / v9885 ✓\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB7HGCi7ilPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "99d57c2e-c5bb-40de-ccf4-c110567e6cea"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f30ee039518>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJQNQ1b3jCok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ee1804d-d84e-4a1a-df88-107542ab3c02"
      },
      "source": [
        "#output.topk(1)\n",
        "all_venues.get()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(values=tensor([[0.]], grad_fn=<TopkBackward>), indices=tensor([[5]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_B85p9ADyg3",
        "colab_type": "text"
      },
      "source": [
        "3. **Keras RNN Model with venues and time in minutes**\n",
        "---\n",
        "Model using Keras.\n",
        "In Keras we can combine categorical and numeric features.\n",
        "\n",
        "Idea:\n",
        "\n",
        "we have a sequence of events (v1,t1) (v2,t2) (v3,t3) and (v4,t4)\n",
        "We create two inputs v1 (categorical) and t1(numeric) pass it to a multi-input and multi-output keras model.\n",
        "\n",
        "For each sequence we create a set of features and targets and train the model for that sequence, and then continue the same process for all sequences.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9mL_wylGSG1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "256c9c22-efda-4c8e-d788-5aec150b56b5"
      },
      "source": [
        "train_sequences_x_y"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-4cd3c4fe5687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_sequences_x_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_sequences_x_y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np3FDjpOvEAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#events are of the form (v,t), where v is categorical and t is hour in mins, seperate the two\n",
        "#same function used for ksplit() will work\n",
        "\n",
        "temp1 = _ksplit_x_y(X_train_features)\n",
        "\n",
        "X_train_features_categorical = temp1[0]\n",
        "X_train_features_numerical = temp1[1]\n",
        "\n",
        "temp2 = _ksplit_x_y(Y_train_targets)\n",
        "\n",
        "Y_train_targets_categorical = temp2[0]\n",
        "Y_train_targets_numerical = temp2[1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1gdEkBZvueG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert categorical to one hot encoding\n",
        "\n",
        "def _one_hot_k(data):\n",
        "  changed_data = []\n",
        "  for sequence in data:\n",
        "    temp = []\n",
        "    for venue in sequence:\n",
        "      temp.append(coded_obj.onehot_encoded(venue))\n",
        "    changed_data.append(temp)\n",
        "  return changed_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtsgljzOvxAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#replace\n",
        "\n",
        "#X_train_features_categorical = _one_hot_k(X_train_features_categorical)\n",
        "#Y_train_targets_categorical = _one_hot_k(Y_train_targets_categorical)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfM5Igq92Jf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test2 = tf.ragged.constant(X_train_features_categorical)\n",
        "#test22 = tf.ragged.constant(X_train_features_numerical)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbyefQFPw9Xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "float_input = tf.keras.Input(shape=(2, ))\n",
        "one_hot_input = tf.keras.Input(shape=(137,) )\n",
        "\n",
        "first_dense = tf.keras.layers.Dense(3)(float_input)\n",
        "second_dense = tf.keras.layers.Dense(50)(one_hot_input)\n",
        "\n",
        "merge_one = tf.keras.layers.concatenate([first_dense, second_dense])\n",
        "dense_inner = tf.keras.layers.Dense(10)(merge_one)\n",
        "\n",
        "dense_output1 = tf.keras.layers.Dense(1)(dense_inner)\n",
        "dense_output2 = tf.keras.layers.Dense(1)(dense_inner)\n",
        "\n",
        "model = tf.keras.Model(inputs=[float_input, one_hot_input], outputs=[dense_output1,dense_output2])\n",
        "\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "#model.fit([X1,X2], Y, epochs=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JxKUlZZe5PE",
        "colab_type": "text"
      },
      "source": [
        "Resources used\n",
        "***\n",
        "https://discuss.pytorch.org/t/mini-batch-training-for-inputs-of-variable-sizes/13662\n",
        "\n",
        "https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed\n",
        "\n",
        "https://stackoverflow.com/questions/53532352/how-do-i-split-the-training-dataset-into-training-validation-and-test-datasets\n",
        "\n",
        "https://learning.oreilly.com/library/view/deep-learning-with/9781788624336/e397c9a2-28a2-41fd-bcc2-a6bb49adfc44.xhtml\n",
        "\n",
        "https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning\n",
        "\n",
        "\n",
        "https://jdhao.github.io/2017/11/15/pytorch-datatype-note/\n",
        "\n",
        "https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
        "\n",
        "https://ai.stackexchange.com/questions/3156/how-to-select-number-of-hidden-layers-and-number-of-memory-cells-in-an-lstm\n",
        "\n",
        "https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/\n",
        "\n",
        "https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
        "\n"
      ]
    }
  ]
}