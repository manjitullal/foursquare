{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxTU+5iLoZFAhBlQKxXrhY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manjitullal/foursquare/blob/master/LSTM_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPIN8iVkCIKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JkNUfStCRFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "aec662e6-d561-4cff-9bf1-8331d08168f0"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive/dataset/foursquare\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQbgAz2nCgSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "301149b2-0d19-4ce8-c4b8-7794a9cf9302"
      },
      "source": [
        "%%time\n",
        "Checkin_columns = ['UserID','VenueID','Year','Month','Date','Hour']\n",
        "Checkin = pd.read_csv(path+'/Checkin.txt', sep=',', skiprows=1, names=Checkin_columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 638 ms, sys: 160 ms, total: 798 ms\n",
            "Wall time: 2.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g0DY_5rCkcb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ed3958f2-a6cc-4c59-b0a6-004bf1b96e8f"
      },
      "source": [
        "Checkin.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>VenueID</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Date</th>\n",
              "      <th>Hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u1302</td>\n",
              "      <td>v47</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u45</td>\n",
              "      <td>v132</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u24844</td>\n",
              "      <td>v86</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>u896</td>\n",
              "      <td>v248</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>u5020</td>\n",
              "      <td>v29</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserID VenueID  Year  Month  Date  Hour\n",
              "0   u1302     v47  2012      2    24    11\n",
              "1     u45    v132  2012      2    24    11\n",
              "2  u24844     v86  2012      2    24    11\n",
              "3    u896    v248  2012      2    24    11\n",
              "4   u5020     v29  2012      2    24    11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXecrhCrCovX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7f00aad1-de66-49d3-9f2c-3d342d9be788"
      },
      "source": [
        "#find the users with most events \n",
        "\n",
        "Checkin.groupby(by='UserID')['UserID'].count().sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UserID\n",
              "u1205     1303\n",
              "u2651     1100\n",
              "u32917    1039\n",
              "u4324      990\n",
              "u45        976\n",
              "          ... \n",
              "u23634       1\n",
              "u23633       1\n",
              "u23631       1\n",
              "u23630       1\n",
              "u9999        1\n",
              "Name: UserID, Length: 45289, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NPTanuyCsZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "742af294-10b7-4d64-c433-c522812f2520"
      },
      "source": [
        "#create another user \n",
        "Checkin_u2651 = Checkin[Checkin.UserID == 'u2651']\n",
        "Checkin_u2651.drop(['UserID'], axis=1, inplace=True)\n",
        "Checkin_u2651.rename(columns={\"Date\":\"Day\"}, inplace=True)\n",
        "Checkin_u2651.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VenueID</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>v68771</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>v68771</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2520</th>\n",
              "      <td>v68812</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3626</th>\n",
              "      <td>v68771</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4445</th>\n",
              "      <td>v69912</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     VenueID  Year  Month  Day  Hour\n",
              "890   v68771  2012      2   24    11\n",
              "2496  v68771  2012      2   25    17\n",
              "2520  v68812  2012      2   25    19\n",
              "3626  v68771  2012      2   25    11\n",
              "4445  v69912  2012      2   25    13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFKVxS2cC3dZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a58be9d2-4e4d-4dc4-e43b-8a7d7c33f4b7"
      },
      "source": [
        "%%time\n",
        "Checkin_u2651['Datetime'] = pd.to_datetime(Checkin_u2651[['Year', 'Month', 'Day', 'Hour']])\n",
        "Checkin_u2651['Hour_mins'] = Checkin_u2651.Hour.values*60"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 16.9 ms, sys: 4.02 ms, total: 21 ms\n",
            "Wall time: 46.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MjLJRddDDE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9a7c618d-5ed8-4df9-d1c1-4e3dbc68e302"
      },
      "source": [
        "Checkin_u2651.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VenueID</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>Hour_mins</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>v68771</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "      <td>2012-02-24 11:00:00</td>\n",
              "      <td>660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>v68771</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>17</td>\n",
              "      <td>2012-02-25 17:00:00</td>\n",
              "      <td>1020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2520</th>\n",
              "      <td>v68812</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>19</td>\n",
              "      <td>2012-02-25 19:00:00</td>\n",
              "      <td>1140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3626</th>\n",
              "      <td>v68771</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "      <td>2012-02-25 11:00:00</td>\n",
              "      <td>660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4445</th>\n",
              "      <td>v69912</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "      <td>2012-02-25 13:00:00</td>\n",
              "      <td>780</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     VenueID  Year  Month  Day  Hour            Datetime  Hour_mins\n",
              "890   v68771  2012      2   24    11 2012-02-24 11:00:00        660\n",
              "2496  v68771  2012      2   25    17 2012-02-25 17:00:00       1020\n",
              "2520  v68812  2012      2   25    19 2012-02-25 19:00:00       1140\n",
              "3626  v68771  2012      2   25    11 2012-02-25 11:00:00        660\n",
              "4445  v69912  2012      2   25    13 2012-02-25 13:00:00        780"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFdkflGRDINd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "9a9da7d5-b942-4d40-db37-26fa10eaaeba"
      },
      "source": [
        "Checkin_u2651_nodup = Checkin_u2651.drop_duplicates('Datetime')\n",
        "Checkin_u2651_nodup.sort_values(by='Datetime',inplace=True)\n",
        "Checkin_u2651_nodup.iloc[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VenueID</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>Hour_mins</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>v68771</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "      <td>2012-02-24 11:00:00</td>\n",
              "      <td>660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3626</th>\n",
              "      <td>v68771</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "      <td>2012-02-25 11:00:00</td>\n",
              "      <td>660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4445</th>\n",
              "      <td>v69912</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "      <td>2012-02-25 13:00:00</td>\n",
              "      <td>780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>v68771</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>17</td>\n",
              "      <td>2012-02-25 17:00:00</td>\n",
              "      <td>1020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2520</th>\n",
              "      <td>v68812</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>19</td>\n",
              "      <td>2012-02-25 19:00:00</td>\n",
              "      <td>1140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18581</th>\n",
              "      <td>v74594</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>9</td>\n",
              "      <td>2012-02-26 09:00:00</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19234</th>\n",
              "      <td>v69912</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>11</td>\n",
              "      <td>2012-02-26 11:00:00</td>\n",
              "      <td>660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11835</th>\n",
              "      <td>v68771</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>13</td>\n",
              "      <td>2012-02-26 13:00:00</td>\n",
              "      <td>780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15523</th>\n",
              "      <td>v61065</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>15</td>\n",
              "      <td>2012-02-26 15:00:00</td>\n",
              "      <td>900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12367</th>\n",
              "      <td>v68775</td>\n",
              "      <td>2012</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>2012-02-26 19:00:00</td>\n",
              "      <td>1140</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      VenueID  Year  Month  Day  Hour            Datetime  Hour_mins\n",
              "890    v68771  2012      2   24    11 2012-02-24 11:00:00        660\n",
              "3626   v68771  2012      2   25    11 2012-02-25 11:00:00        660\n",
              "4445   v69912  2012      2   25    13 2012-02-25 13:00:00        780\n",
              "2496   v68771  2012      2   25    17 2012-02-25 17:00:00       1020\n",
              "2520   v68812  2012      2   25    19 2012-02-25 19:00:00       1140\n",
              "18581  v74594  2012      2   26     9 2012-02-26 09:00:00        540\n",
              "19234  v69912  2012      2   26    11 2012-02-26 11:00:00        660\n",
              "11835  v68771  2012      2   26    13 2012-02-26 13:00:00        780\n",
              "15523  v61065  2012      2   26    15 2012-02-26 15:00:00        900\n",
              "12367  v68775  2012      2   26    19 2012-02-26 19:00:00       1140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRWyA2FSDWVX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ed3b0d1e-4d06-4860-a05d-79471cf6a06b"
      },
      "source": [
        "\n",
        "%%time\n",
        "\n",
        "import datetime\n",
        "\n",
        "def _generate_events(data):\n",
        "  previous_time = datetime.datetime(2020, 12, 31)\n",
        "  all_events = []\n",
        "  current_events = []\n",
        "  for index, row in data.iterrows():\n",
        "    current_time = row['Datetime']  \n",
        "    current_hour = row['Hour']\n",
        "    venue = row['VenueID']\n",
        "    if( abs((current_time - previous_time).total_seconds())/60/60 < 8):\n",
        "      current_events.append([venue, current_hour])\n",
        "      previous_time = current_time\n",
        "    else:\n",
        "      all_events.append(current_events)\n",
        "      current_events = []\n",
        "      current_events.append([venue, current_hour])\n",
        "      previous_time = current_time\n",
        "  if len(current_events)>0:\n",
        "    all_events.append(current_events)\n",
        "  return all_events"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 7 µs, total: 7 µs\n",
            "Wall time: 9.78 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7ZoynByEJ1L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "742bf01a-d8eb-455a-99b4-465f391b9db7"
      },
      "source": [
        "%%time\n",
        "def _generate_subsequence(data):\n",
        "  all_sequences = []\n",
        "  for sequence in data:  \n",
        "    if len(sequence) >= 2:\n",
        "      sequences = []\n",
        "      for i in range(0,len(sequence)-1):\n",
        "          sequences.append(sequence[i:i+2])          \n",
        "      all_sequences.append(sequences)\n",
        "  return all_sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 7.63 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DCujPYFENAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "cf9d438c-4508-477f-d5a2-03713a208c38"
      },
      "source": [
        "%time\n",
        "o_events = _generate_events(Checkin_u2651_nodup)\n",
        "print(\"Events\")\n",
        "print(o_events)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.68 µs\n",
            "Events\n",
            "[[], [['v68771', 11]], [['v68771', 11], ['v69912', 13], ['v68771', 17], ['v68812', 19]], [['v74594', 9], ['v69912', 11], ['v68771', 13], ['v61065', 15], ['v68775', 19]], [['v23056', 9], ['v68812', 16], ['v74594', 17], ['v68775', 19], ['v68771', 22]], [['v68771', 8], ['v69912', 11], ['v68768', 17], ['v68771', 18], ['v83111', 19], ['v68771', 21]], [['v68771', 6], ['v69912', 8], ['v64246', 9], ['v29805', 10], ['v18503', 12], ['v25312', 13], ['v27753', 16], ['v74594', 22], ['v68771', 23], ['v68775', 0], ['v68775', 7], ['v68812', 11], ['v18503', 12], ['v24143', 13], ['v82320', 19], ['v74594', 21], ['v9901', 23]], [['v68812', 9], ['v33365', 10]], [['v18503', 21], ['v69912', 22], ['v68771', 23]], [['v68771', 8], ['v68812', 9], ['v18503', 12], ['v7256', 17], ['v2641', 18]], [['v57948', 9], ['v29805', 10], ['v18503', 12], ['v1195', 14]], [['v68812', 22], ['v68775', 23], ['v69912', 0]], [['v68768', 8], ['v68812', 9], ['v44187', 14], ['v13815', 20], ['v2060', 22], ['v69912', 23], ['v68771', 0]], [['v68812', 9], ['v41716', 11], ['v18503', 12], ['v39550', 14], ['v81598', 15], ['v63209', 21], ['v2060', 22], ['v9901', 23], ['v68771', 1], ['v69912', 2], ['v68771', 9], ['v68812', 12], ['v11563', 14], ['v83111', 18], ['v74594', 19], ['v68771', 21]], [['v68812', 8], ['v83111', 9], ['v68775', 10], ['v68812', 11], ['v18503', 12], ['v6111', 14]], [['v61065', 22], ['v9901', 23], ['v68775', 6], ['v68771', 9], ['v68771', 10], ['v18503', 12], ['v24143', 15], ['v8915', 19], ['v2060', 21], ['v68775', 23]], [['v68771', 7], ['v83111', 8], ['v18503', 12], ['v2133', 19], ['v61065', 21], ['v69912', 22]], [['v68775', 8], ['v83111', 9], ['v18503', 12]], [['v3240', 20], ['v53888', 21], ['v61065', 23], ['v69912', 0]], [['v68775', 8], ['v68771', 9], ['v18503', 14], ['v11625', 15], ['v9257', 17], ['v69912', 0]], [['v41716', 9], ['v68812', 11], ['v11563', 13], ['v2060', 14], ['v59700', 18], ['v24511', 21], ['v3240', 22], ['v18315', 23], ['v9901', 0]], [['v68812', 11], ['v11563', 14], ['v4446', 16], ['v74594', 20], ['v68771', 21], ['v69912', 23]], [['v68775', 8], ['v83111', 10], ['v8056', 16], ['v1195', 20], ['v73617', 21], ['v9901', 0], ['v68771', 4], ['v74594', 8], ['v64246', 9], ['v68812', 10], ['v18503', 14], ['v3897', 17], ['v44187', 19], ['v2641', 21], ['v68812', 23]], [['v68775', 7], ['v55121', 9], ['v68812', 11], ['v18503', 14], ['v44187', 15], ['v5757', 16], ['v81623', 17], ['v44187', 19], ['v69912', 0]], [['v68768', 9], ['v68812', 11], ['v2060', 12]], [['v39147', 21], ['v68812', 22], ['v68771', 23], ['v69912', 0]], [['v68812', 9], ['v18503', 14], ['v18610', 15], ['v8738', 22], ['v69912', 0], ['v68775', 7], ['v41716', 9], ['v68812', 10], ['v18503', 14], ['v65878', 15]], [['v18315', 23], ['v9901', 0]], [['v68771', 11], ['v11563', 13], ['v18503', 14], ['v8089', 15]], [['v18315', 23], ['v9901', 0], ['v68775', 3], ['v68771', 10], ['v68812', 12], ['v18503', 14], ['v8089', 15], ['v1156', 16], ['v20285', 20], ['v3305', 22], ['v39147', 23], ['v9901', 0], ['v69912', 1], ['v68771', 2], ['v57948', 9], ['v83111', 10], ['v18503', 14], ['v28851', 15]], [['v68812', 0], ['v68771', 1]], [['v68812', 9], ['v55121', 11], ['v18503', 12], ['v1195', 14], ['v1457', 17], ['v13233', 19], ['v53888', 21], ['v61065', 23]], [['v68771', 9], ['v68812', 12], ['v18503', 14], ['v44187', 15], ['v1156', 18], ['v74594', 0], ['v68771', 1], ['v41716', 8], ['v83111', 9], ['v68812', 12], ['v18503', 14], ['v1195', 15], ['v28851', 17], ['v39147', 23], ['v68775', 0], ['v68771', 1], ['v39147', 6], ['v228', 9], ['v230', 10], ['v68812', 17], ['v74594', 22]], [['v83111', 8], ['v68771', 10], ['v68812', 12], ['v18503', 14], ['v28851', 16], ['v80976', 17], ['v11841', 20], ['v3305', 21], ['v9901', 0], ['v40893', 2], ['v83111', 9], ['v68771', 10], ['v68812', 13], ['v18503', 14], ['v1195', 15], ['v18693', 18], ['v12251', 19], ['v74594', 23], ['v68812', 0], ['v68771', 1], ['v83111', 8], ['v6634', 10], ['v18503', 14], ['v1195', 16], ['v14785', 21], ['v74594', 0], ['v68775', 1], ['v68771', 2], ['v29805', 8], ['v83111', 9], ['v68812', 11], ['v19502', 14], ['v9498', 17], ['v6890', 20], ['v68812', 22], ['v74594', 23], ['v68771', 0]], [['v41716', 9], ['v83111', 10], ['v68812', 11], ['v18503', 14], ['v9257', 15], ['v1303', 16], ['v19502', 17], ['v44187', 18], ['v38600', 19], ['v74594', 23], ['v68771', 0], ['v68775', 5], ['v57948', 8], ['v64246', 9], ['v83111', 10], ['v68812', 11], ['v18503', 14], ['v6890', 15], ['v3305', 20], ['v18315', 23], ['v9901', 0], ['v68771', 2], ['v68775', 3], ['v41716', 8], ['v68812', 11], ['v11563', 13], ['v18315', 14], ['v68812', 17]], [['v68775', 4], ['v41716', 8], ['v83111', 10], ['v68812', 12], ['v18503', 14]], [['v9901', 23], ['v40893', 3], ['v41716', 10], ['v68812', 11], ['v18503', 14], ['v3305', 21], ['v1195', 22], ['v18315', 23], ['v68775', 0]], [['v68771', 10], ['v68812', 11], ['v2060', 13], ['v18503', 14], ['v3305', 15]], [['v68775', 0], ['v68771', 1], ['v83111', 8], ['v68771', 9], ['v18503', 12], ['v9498', 17], ['v39147', 21], ['v68771', 22]], [['v41716', 8], ['v83111', 9], ['v68771', 10], ['v18503', 14], ['v9257', 17], ['v9498', 19], ['v3305', 21], ['v68812', 0], ['v68771', 1], ['v41716', 8], ['v11563', 10], ['v68771', 11], ['v68812', 12], ['v18503', 14], ['v9498', 19], ['v3305', 21], ['v9901', 0], ['v68775', 2], ['v69912', 3]], [['v61065', 16], ['v74594', 17], ['v68771', 20], ['v68775', 23]], [['v41716', 8], ['v83111', 9], ['v18503', 14], ['v3305', 20], ['v18315', 23], ['v9901', 0], ['v68771', 3], ['v41716', 10], ['v83111', 12], ['v18503', 14]], [['v2721', 22], ['v74594', 23], ['v68775', 0]], [['v83111', 8], ['v68771', 10], ['v68812', 12], ['v18503', 14]], [['v9901', 1]], [['v56693', 15], ['v68812', 18], ['v69912', 22]], [['v68775', 6], ['v41716', 11], ['v68812', 12], ['v12197', 13], ['v12489', 20], ['v68771', 22]], [['v41716', 8], ['v68771', 9], ['v68812', 12], ['v18503', 14], ['v3305', 20], ['v9901', 0], ['v68775', 4], ['v41716', 10], ['v83111', 11], ['v68812', 12], ['v2042', 13], ['v56693', 14], ['v61065', 17], ['v74594', 18], ['v68812', 21]], [['v41716', 8], ['v83111', 9], ['v68771', 10], ['v18503', 14], ['v14124', 17], ['v6890', 19], ['v9901', 0], ['v68775', 5], ['v83111', 10], ['v68771', 12], ['v18503', 14]], [['v39147', 23], ['v68812', 0], ['v68771', 1], ['v41716', 8], ['v68771', 12], ['v13268', 13]], [['v74594', 0], ['v68771', 1], ['v64246', 8], ['v68812', 11], ['v6890', 16], ['v3305', 19], ['v18315', 21], ['v68768', 22], ['v68775', 5], ['v64246', 8], ['v55121', 9], ['v68812', 12]], [['v3305', 21], ['v39147', 23], ['v68771', 0]], [['v57948', 8], ['v83111', 9], ['v68771', 10], ['v68812', 12], ['v2060', 13], ['v85431', 16], ['v3305', 22], ['v61065', 23], ['v9901', 0]], [['v68812', 14], ['v83111', 21], ['v68812', 22]], [['v41716', 8], ['v68771', 9], ['v68812', 13], ['v18503', 14], ['v9498', 16], ['v6890', 18], ['v3305', 20], ['v74594', 23]], [['v41716', 10], ['v68771', 11], ['v68812', 13], ['v18503', 14], ['v9498', 15], ['v40168', 17], ['v6890', 20], ['v14785', 21], ['v18315', 23], ['v9901', 0]], [['v69912', 10], ['v36986', 11], ['v83111', 12], ['v2060', 13], ['v53888', 14], ['v3305', 21], ['v39147', 23], ['v74594', 0]], [['v29805', 11]], [['v18315', 21], ['v69912', 22]], [['v68775', 6], ['v64246', 8], ['v41716', 9], ['v83111', 10], ['v68771', 11], ['v68812', 12], ['v2060', 13], ['v18503', 14], ['v3305', 21], ['v61065', 23], ['v68771', 0], ['v29805', 7], ['v68771', 8], ['v68812', 12], ['v14124', 19], ['v3305', 22], ['v39147', 23], ['v9901', 0], ['v68775', 2], ['v68771', 3], ['v41716', 7], ['v83111', 8], ['v68771', 9]], [['v74594', 18], ['v12489', 20]], [['v83111', 9], ['v68771', 10], ['v68812', 13], ['v18503', 14], ['v9498', 16], ['v74594', 23], ['v9901', 0], ['v69912', 4], ['v29805', 9], ['v55121', 10], ['v68771', 11], ['v18503', 14], ['v8090', 21], ['v25457', 22], ['v18315', 23], ['v2603', 0], ['v68775', 1], ['v83111', 8], ['v6634', 9], ['v11563', 10], ['v68812', 11], ['v55121', 13], ['v18503', 14], ['v6890', 18], ['v14124', 19], ['v3305', 21], ['v9901', 0], ['v68775', 2], ['v83111', 9], ['v68771', 10], ['v18503', 13], ['v75121', 17], ['v9498', 19]], [['v57948', 8], ['v68771', 10], ['v83111', 11], ['v68812', 12], ['v11563', 13]], [['v18315', 23], ['v68812', 0], ['v68775', 1], ['v57948', 8], ['v83111', 9], ['v68771', 10], ['v68812', 12], ['v18503', 14], ['v1195', 19], ['v3305', 21], ['v61065', 23], ['v9901', 0], ['v68775', 2]], [['v83111', 13], ['v68771', 14], ['v2534', 16], ['v25647', 17], ['v68812', 18], ['v74594', 22], ['v68775', 3], ['v41716', 8], ['v68771', 9], ['v68812', 12], ['v18503', 14], ['v6890', 17], ['v39147', 23], ['v9901', 0]], [['v68771', 10], ['v68812', 12], ['v18503', 14]], [['v24511', 22], ['v3859', 23], ['v53888', 0]], [['v64246', 8], ['v41716', 10], ['v83111', 11], ['v68812', 12], ['v36986', 13], ['v18503', 14]], [['v74594', 23], ['v68775', 1], ['v41716', 6], ['v18503', 8], ['v14124', 9], ['v21315', 16], ['v12682', 18], ['v8389', 20]], [['v41716', 8], ['v68771', 9], ['v18503', 14], ['v6890', 15], ['v3305', 21], ['v39147', 23], ['v9901', 0]], [['v41716', 9], ['v4297', 11], ['v4692', 12]], [['v68812', 22], ['v68775', 5], ['v69912', 9], ['v68812', 10], ['v50483', 13], ['v53888', 16], ['v6127', 18], ['v74594', 22], ['v68775', 2], ['v68771', 9], ['v68812', 12], ['v18503', 14], ['v1195', 20], ['v3236', 22], ['v39147', 23], ['v9901', 0], ['v68771', 3], ['v41716', 8], ['v83111', 9], ['v68771', 10], ['v68812', 12], ['v18503', 14], ['v1303', 16], ['v39147', 23], ['v74594', 0], ['v29805', 7], ['v64246', 8], ['v6634', 9], ['v68812', 12], ['v18503', 13]], [['v3305', 22], ['v25647', 23], ['v68775', 0], ['v64246', 6], ['v6890', 13], ['v18503', 16], ['v25647', 17], ['v61065', 19], ['v69912', 21]], [['v68775', 5], ['v64246', 7], ['v68771', 8], ['v68812', 10], ['v18503', 14], ['v9498', 17], ['v9242', 18], ['v6890', 20], ['v395', 21], ['v3305', 22], ['v18315', 23], ['v68775', 5], ['v55121', 8], ['v68771', 9], ['v18503', 14], ['v1195', 17], ['v6890', 20], ['v3305', 22], ['v18315', 23], ['v9901', 0], ['v69912', 2], ['v55121', 9], ['v68768', 10], ['v881', 14], ['v68812', 16], ['v61065', 19], ['v74594', 22], ['v68771', 23], ['v68775', 4], ['v64246', 8], ['v11563', 9], ['v68768', 10], ['v68812', 12], ['v18503', 14], ['v9498', 15], ['v14124', 18], ['v25647', 23], ['v9901', 0]], [['v83111', 10], ['v68812', 11], ['v6890', 17], ['v18610', 20], ['v68775', 0]], [['v83111', 8], ['v68768', 9], ['v68771', 10], ['v18503', 14]], [['v74594', 23], ['v29805', 6]], [['v18503', 16], ['v68768', 17], ['v68812', 20], ['v74594', 21], ['v68771', 22]], [['v18503', 6], ['v58085', 12], ['v14124', 13], ['v6890', 14], ['v18315', 16], ['v68768', 17], ['v2240', 20]], [['v57948', 8], ['v83111', 9], ['v68771', 10], ['v68812', 12], ['v36986', 13], ['v18503', 14], ['v14124', 16], ['v13567', 19], ['v39147', 23]], [['v41716', 7], ['v68812', 8], ['v68768', 9], ['v68812', 11], ['v17690', 12], ['v64246', 15], ['v68768', 16], ['v74594', 18], ['v68771', 22], ['v68775', 0]], [['v68771', 8], ['v68812', 12], ['v18503', 14], ['v395', 15], ['v9498', 16], ['v18315', 23], ['v74594', 0], ['v9901', 1], ['v68775', 3]], [['v68771', 11], ['v710', 16], ['v14124', 20], ['v68775', 0], ['v41716', 7], ['v64246', 8], ['v11563', 10], ['v83111', 11], ['v68771', 12], ['v18503', 14], ['v14124', 19], ['v395', 22], ['v18315', 23], ['v29805', 6], ['v18503', 8], ['v14124', 9]], [['v53888', 17], ['v74594', 22], ['v69912', 23], ['v68775', 0]], [['v83111', 8], ['v68812', 11], ['v68768', 12], ['v18503', 14], ['v14124', 18], ['v18610', 20], ['v68775', 0]], [['v55121', 8], ['v68812', 12], ['v18503', 14], ['v47162', 16], ['v13567', 20], ['v6890', 21], ['v61065', 0]], [['v69912', 8], ['v6127', 9], ['v55121', 12], ['v68812', 16], ['v7382', 19], ['v61065', 22], ['v74594', 23], ['v68775', 0]], [['v83111', 9], ['v68771', 10], ['v68812', 12], ['v2060', 14]], [['v395', 22], ['v68768', 23], ['v9901', 0], ['v68775', 6], ['v41716', 11], ['v68812', 12], ['v18503', 14], ['v1155', 19], ['v395', 20], ['v40805', 21], ['v39147', 0], ['v68775', 1]], [['v6634', 9], ['v5310', 10], ['v68812', 11], ['v18503', 14], ['v14124', 16], ['v710', 17], ['v6890', 21], ['v53888', 23], ['v68775', 1], ['v68812', 6], ['v14124', 9], ['v9498', 13], ['v18503', 17], ['v68812', 18], ['v69912', 22], ['v68775', 23]], [['v83111', 7], ['v68771', 9], ['v68812', 10], ['v18503', 14], ['v77584', 17], ['v3305', 18], ['v395', 19], ['v74594', 23], ['v68775', 0]], [['v83111', 9], ['v68812', 11], ['v11563', 13], ['v18503', 14]], [['v15240', 2], ['v51500', 3]], [['v59530', 13], ['v68768', 17], ['v68812', 20], ['v61065', 22], ['v51500', 23], ['v9901', 0]], [['v68771', 11], ['v68812', 12], ['v18503', 14]], [['v3305', 22], ['v68775', 0]], [['v68812', 12], ['v18503', 14], ['v13567', 16], ['v395', 19], ['v890', 23], ['v68775', 0], ['v64246', 7], ['v14124', 9], ['v18315', 16], ['v68812', 20]], [['v68771', 5], ['v68812', 12], ['v18503', 14], ['v14124', 17], ['v395', 21], ['v77584', 22], ['v39147', 0]], [['v68812', 12], ['v18503', 14], ['v14225', 16], ['v33028', 17], ['v9775', 18], ['v61065', 0], ['v68775', 1], ['v68812', 8], ['v68768', 13], ['v74594', 19], ['v68775', 1], ['v41716', 8], ['v83111', 9], ['v68768', 10], ['v68812', 12], ['v42978', 14], ['v77584', 18], ['v81623', 19], ['v395', 21], ['v18315', 23], ['v575', 0], ['v9901', 1], ['v68775', 5], ['v64246', 10], ['v68812', 11], ['v18503', 14], ['v9498', 17], ['v39147', 0], ['v68775', 1]], [['v68768', 10], ['v2603', 14], ['v14124', 18]], [['v68812', 10], ['v68768', 14]], [['v74594', 22], ['v68771', 23]], [['v83111', 10], ['v68771', 11], ['v68812', 12], ['v64246', 13], ['v9498', 18], ['v18315', 1]], [['v41716', 9], ['v11563', 11], ['v3649', 12], ['v68812', 13], ['v68768', 15], ['v74594', 19], ['v68775', 2], ['v68812', 9], ['v83111', 15], ['v68771', 18], ['v61441', 19], ['v74594', 20], ['v68768', 22], ['v68775', 0]], [['v64246', 9], ['v68812', 11], ['v18503', 14], ['v40167', 17], ['v3305', 22], ['v9901', 0]], [['v68812', 13], ['v18503', 14], ['v6890', 18], ['v3305', 19], ['v2060', 23], ['v9901', 0], ['v68812', 3], ['v68771', 5], ['v64246', 12], ['v83111', 13], ['v68768', 14], ['v68812', 18], ['v74594', 19], ['v61065', 23], ['v68775', 1]], [['v14124', 9], ['v4628', 11], ['v43749', 13], ['v28851', 14], ['v68768', 17], ['v68812', 18], ['v68771', 21], ['v68775', 23]], [['v55121', 16], ['v68771', 17], ['v74594', 18], ['v68771', 20], ['v68812', 21], ['v68775', 22]], [['v2060', 6], ['v18503', 7], ['v14124', 12], ['v48715', 15], ['v55121', 16], ['v68771', 17], ['v74594', 18], ['v68812', 20], ['v68775', 22]], [['v18503', 7], ['v14124', 8], ['v43749', 12], ['v395', 14], ['v2603', 15], ['v83111', 16], ['v68812', 17], ['v25370', 19], ['v50977', 20], ['v9901', 23], ['v30302', 4]], [['v18503', 14], ['v43749', 17], ['v13567', 19], ['v71093', 22], ['v68775', 0], ['v64246', 5], ['v2060', 6], ['v18503', 7], ['v14124', 8], ['v6890', 14], ['v68768', 16], ['v61065', 20], ['v68812', 21], ['v68771', 23]], [['v18503', 7], ['v14124', 8], ['v4825', 11], ['v2603', 15], ['v68768', 16], ['v9901', 18], ['v68812', 20], ['v68775', 2], ['v68771', 3], ['v18503', 8], ['v19734', 9], ['v14124', 12], ['v28031', 14], ['v48715', 15], ['v68768', 16], ['v74594', 18], ['v68812', 20], ['v68775', 2], ['v69912', 6], ['v68771', 12], ['v18503', 14], ['v9498', 16], ['v48715', 22], ['v18315', 23], ['v68775', 1]], [['v41716', 10], ['v5310', 11], ['v68771', 12], ['v2060', 14]], [['v68812', 22], ['v9901', 23], ['v64246', 2], ['v68775', 4], ['v68768', 11]], [['v68812', 11], ['v64246', 12], ['v18503', 14], ['v78553', 16], ['v6676', 17], ['v2060', 23], ['v68775', 0]], [['v41716', 9], ['v83111', 10], ['v64246', 11], ['v18503', 14], ['v14124', 17], ['v48715', 22], ['v68775', 1], ['v83111', 6], ['v14124', 9], ['v17865', 15], ['v2603', 16], ['v74594', 18]], [['v41716', 8], ['v68812', 9], ['v69912', 10], ['v68812', 11], ['v64246', 12], ['v18315', 13], ['v18503', 14], ['v14124', 16], ['v395', 17], ['v14785', 20], ['v70663', 22]], [['v83111', 10], ['v68771', 11], ['v68812', 12], ['v2060', 14], ['v18503', 15], ['v9498', 17], ['v14785', 18], ['v14124', 19], ['v395', 20], ['v48715', 22], ['v18315', 3], ['v41716', 8], ['v64246', 11], ['v68768', 13], ['v68812', 14], ['v74594', 19], ['v68771', 21], ['v68775', 2]], [['v68768', 11], ['v68812', 14], ['v74594', 18], ['v64246', 21], ['v9901', 22]], [['v83111', 11], ['v68812', 12], ['v18503', 14], ['v14610', 15], ['v43749', 21], ['v18315', 0], ['v68775', 1]], [['v41716', 9], ['v83111', 10], ['v68771', 11], ['v18503', 14], ['v40167', 15], ['v43749', 16], ['v39584', 17], ['v14124', 19], ['v3305', 20], ['v74594', 23]], [['v18503', 8], ['v14124', 9], ['v6890', 10], ['v43749', 14], ['v74594', 18], ['v68771', 19], ['v68812', 20]], [['v68775', 7], ['v41716', 9], ['v83111', 10], ['v68812', 11], ['v64246', 12], ['v70663', 14]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvCIU6FhEg3c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b0234374-f8b5-4db5-d55b-5146ea5c17aa"
      },
      "source": [
        "def _set_earliest_event_time(data):\n",
        "  all_sequences = []\n",
        "  changed_data = data.copy()\n",
        "  for sequence in changed_data:      \n",
        "    if(len(sequence)>=2):\n",
        "      sequence[0][1] = 0\n",
        "      all_sequences.append(sequence)\n",
        "  return all_sequences\n",
        "    \n",
        "m_events = _set_earliest_event_time(o_events)\n",
        "print(\"Changed Events\")\n",
        "print(m_events)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Changed Events\n",
            "[[['v68771', 0], ['v69912', 13], ['v68771', 17], ['v68812', 19]], [['v74594', 0], ['v69912', 11], ['v68771', 13], ['v61065', 15], ['v68775', 19]], [['v23056', 0], ['v68812', 16], ['v74594', 17], ['v68775', 19], ['v68771', 22]], [['v68771', 0], ['v69912', 11], ['v68768', 17], ['v68771', 18], ['v83111', 19], ['v68771', 21]], [['v68771', 0], ['v69912', 8], ['v64246', 9], ['v29805', 10], ['v18503', 12], ['v25312', 13], ['v27753', 16], ['v74594', 22], ['v68771', 23], ['v68775', 0], ['v68775', 7], ['v68812', 11], ['v18503', 12], ['v24143', 13], ['v82320', 19], ['v74594', 21], ['v9901', 23]], [['v68812', 0], ['v33365', 10]], [['v18503', 0], ['v69912', 22], ['v68771', 23]], [['v68771', 0], ['v68812', 9], ['v18503', 12], ['v7256', 17], ['v2641', 18]], [['v57948', 0], ['v29805', 10], ['v18503', 12], ['v1195', 14]], [['v68812', 0], ['v68775', 23], ['v69912', 0]], [['v68768', 0], ['v68812', 9], ['v44187', 14], ['v13815', 20], ['v2060', 22], ['v69912', 23], ['v68771', 0]], [['v68812', 0], ['v41716', 11], ['v18503', 12], ['v39550', 14], ['v81598', 15], ['v63209', 21], ['v2060', 22], ['v9901', 23], ['v68771', 1], ['v69912', 2], ['v68771', 9], ['v68812', 12], ['v11563', 14], ['v83111', 18], ['v74594', 19], ['v68771', 21]], [['v68812', 0], ['v83111', 9], ['v68775', 10], ['v68812', 11], ['v18503', 12], ['v6111', 14]], [['v61065', 0], ['v9901', 23], ['v68775', 6], ['v68771', 9], ['v68771', 10], ['v18503', 12], ['v24143', 15], ['v8915', 19], ['v2060', 21], ['v68775', 23]], [['v68771', 0], ['v83111', 8], ['v18503', 12], ['v2133', 19], ['v61065', 21], ['v69912', 22]], [['v68775', 0], ['v83111', 9], ['v18503', 12]], [['v3240', 0], ['v53888', 21], ['v61065', 23], ['v69912', 0]], [['v68775', 0], ['v68771', 9], ['v18503', 14], ['v11625', 15], ['v9257', 17], ['v69912', 0]], [['v41716', 0], ['v68812', 11], ['v11563', 13], ['v2060', 14], ['v59700', 18], ['v24511', 21], ['v3240', 22], ['v18315', 23], ['v9901', 0]], [['v68812', 0], ['v11563', 14], ['v4446', 16], ['v74594', 20], ['v68771', 21], ['v69912', 23]], [['v68775', 0], ['v83111', 10], ['v8056', 16], ['v1195', 20], ['v73617', 21], ['v9901', 0], ['v68771', 4], ['v74594', 8], ['v64246', 9], ['v68812', 10], ['v18503', 14], ['v3897', 17], ['v44187', 19], ['v2641', 21], ['v68812', 23]], [['v68775', 0], ['v55121', 9], ['v68812', 11], ['v18503', 14], ['v44187', 15], ['v5757', 16], ['v81623', 17], ['v44187', 19], ['v69912', 0]], [['v68768', 0], ['v68812', 11], ['v2060', 12]], [['v39147', 0], ['v68812', 22], ['v68771', 23], ['v69912', 0]], [['v68812', 0], ['v18503', 14], ['v18610', 15], ['v8738', 22], ['v69912', 0], ['v68775', 7], ['v41716', 9], ['v68812', 10], ['v18503', 14], ['v65878', 15]], [['v18315', 0], ['v9901', 0]], [['v68771', 0], ['v11563', 13], ['v18503', 14], ['v8089', 15]], [['v18315', 0], ['v9901', 0], ['v68775', 3], ['v68771', 10], ['v68812', 12], ['v18503', 14], ['v8089', 15], ['v1156', 16], ['v20285', 20], ['v3305', 22], ['v39147', 23], ['v9901', 0], ['v69912', 1], ['v68771', 2], ['v57948', 9], ['v83111', 10], ['v18503', 14], ['v28851', 15]], [['v68812', 0], ['v68771', 1]], [['v68812', 0], ['v55121', 11], ['v18503', 12], ['v1195', 14], ['v1457', 17], ['v13233', 19], ['v53888', 21], ['v61065', 23]], [['v68771', 0], ['v68812', 12], ['v18503', 14], ['v44187', 15], ['v1156', 18], ['v74594', 0], ['v68771', 1], ['v41716', 8], ['v83111', 9], ['v68812', 12], ['v18503', 14], ['v1195', 15], ['v28851', 17], ['v39147', 23], ['v68775', 0], ['v68771', 1], ['v39147', 6], ['v228', 9], ['v230', 10], ['v68812', 17], ['v74594', 22]], [['v83111', 0], ['v68771', 10], ['v68812', 12], ['v18503', 14], ['v28851', 16], ['v80976', 17], ['v11841', 20], ['v3305', 21], ['v9901', 0], ['v40893', 2], ['v83111', 9], ['v68771', 10], ['v68812', 13], ['v18503', 14], ['v1195', 15], ['v18693', 18], ['v12251', 19], ['v74594', 23], ['v68812', 0], ['v68771', 1], ['v83111', 8], ['v6634', 10], ['v18503', 14], ['v1195', 16], ['v14785', 21], ['v74594', 0], ['v68775', 1], ['v68771', 2], ['v29805', 8], ['v83111', 9], ['v68812', 11], ['v19502', 14], ['v9498', 17], ['v6890', 20], ['v68812', 22], ['v74594', 23], ['v68771', 0]], [['v41716', 0], ['v83111', 10], ['v68812', 11], ['v18503', 14], ['v9257', 15], ['v1303', 16], ['v19502', 17], ['v44187', 18], ['v38600', 19], ['v74594', 23], ['v68771', 0], ['v68775', 5], ['v57948', 8], ['v64246', 9], ['v83111', 10], ['v68812', 11], ['v18503', 14], ['v6890', 15], ['v3305', 20], ['v18315', 23], ['v9901', 0], ['v68771', 2], ['v68775', 3], ['v41716', 8], ['v68812', 11], ['v11563', 13], ['v18315', 14], ['v68812', 17]], [['v68775', 0], ['v41716', 8], ['v83111', 10], ['v68812', 12], ['v18503', 14]], [['v9901', 0], ['v40893', 3], ['v41716', 10], ['v68812', 11], ['v18503', 14], ['v3305', 21], ['v1195', 22], ['v18315', 23], ['v68775', 0]], [['v68771', 0], ['v68812', 11], ['v2060', 13], ['v18503', 14], ['v3305', 15]], [['v68775', 0], ['v68771', 1], ['v83111', 8], ['v68771', 9], ['v18503', 12], ['v9498', 17], ['v39147', 21], ['v68771', 22]], [['v41716', 0], ['v83111', 9], ['v68771', 10], ['v18503', 14], ['v9257', 17], ['v9498', 19], ['v3305', 21], ['v68812', 0], ['v68771', 1], ['v41716', 8], ['v11563', 10], ['v68771', 11], ['v68812', 12], ['v18503', 14], ['v9498', 19], ['v3305', 21], ['v9901', 0], ['v68775', 2], ['v69912', 3]], [['v61065', 0], ['v74594', 17], ['v68771', 20], ['v68775', 23]], [['v41716', 0], ['v83111', 9], ['v18503', 14], ['v3305', 20], ['v18315', 23], ['v9901', 0], ['v68771', 3], ['v41716', 10], ['v83111', 12], ['v18503', 14]], [['v2721', 0], ['v74594', 23], ['v68775', 0]], [['v83111', 0], ['v68771', 10], ['v68812', 12], ['v18503', 14]], [['v56693', 0], ['v68812', 18], ['v69912', 22]], [['v68775', 0], ['v41716', 11], ['v68812', 12], ['v12197', 13], ['v12489', 20], ['v68771', 22]], [['v41716', 0], ['v68771', 9], ['v68812', 12], ['v18503', 14], ['v3305', 20], ['v9901', 0], ['v68775', 4], ['v41716', 10], ['v83111', 11], ['v68812', 12], ['v2042', 13], ['v56693', 14], ['v61065', 17], ['v74594', 18], ['v68812', 21]], [['v41716', 0], ['v83111', 9], ['v68771', 10], ['v18503', 14], ['v14124', 17], ['v6890', 19], ['v9901', 0], ['v68775', 5], ['v83111', 10], ['v68771', 12], ['v18503', 14]], [['v39147', 0], ['v68812', 0], ['v68771', 1], ['v41716', 8], ['v68771', 12], ['v13268', 13]], [['v74594', 0], ['v68771', 1], ['v64246', 8], ['v68812', 11], ['v6890', 16], ['v3305', 19], ['v18315', 21], ['v68768', 22], ['v68775', 5], ['v64246', 8], ['v55121', 9], ['v68812', 12]], [['v3305', 0], ['v39147', 23], ['v68771', 0]], [['v57948', 0], ['v83111', 9], ['v68771', 10], ['v68812', 12], ['v2060', 13], ['v85431', 16], ['v3305', 22], ['v61065', 23], ['v9901', 0]], [['v68812', 0], ['v83111', 21], ['v68812', 22]], [['v41716', 0], ['v68771', 9], ['v68812', 13], ['v18503', 14], ['v9498', 16], ['v6890', 18], ['v3305', 20], ['v74594', 23]], [['v41716', 0], ['v68771', 11], ['v68812', 13], ['v18503', 14], ['v9498', 15], ['v40168', 17], ['v6890', 20], ['v14785', 21], ['v18315', 23], ['v9901', 0]], [['v69912', 0], ['v36986', 11], ['v83111', 12], ['v2060', 13], ['v53888', 14], ['v3305', 21], ['v39147', 23], ['v74594', 0]], [['v18315', 0], ['v69912', 22]], [['v68775', 0], ['v64246', 8], ['v41716', 9], ['v83111', 10], ['v68771', 11], ['v68812', 12], ['v2060', 13], ['v18503', 14], ['v3305', 21], ['v61065', 23], ['v68771', 0], ['v29805', 7], ['v68771', 8], ['v68812', 12], ['v14124', 19], ['v3305', 22], ['v39147', 23], ['v9901', 0], ['v68775', 2], ['v68771', 3], ['v41716', 7], ['v83111', 8], ['v68771', 9]], [['v74594', 0], ['v12489', 20]], [['v83111', 0], ['v68771', 10], ['v68812', 13], ['v18503', 14], ['v9498', 16], ['v74594', 23], ['v9901', 0], ['v69912', 4], ['v29805', 9], ['v55121', 10], ['v68771', 11], ['v18503', 14], ['v8090', 21], ['v25457', 22], ['v18315', 23], ['v2603', 0], ['v68775', 1], ['v83111', 8], ['v6634', 9], ['v11563', 10], ['v68812', 11], ['v55121', 13], ['v18503', 14], ['v6890', 18], ['v14124', 19], ['v3305', 21], ['v9901', 0], ['v68775', 2], ['v83111', 9], ['v68771', 10], ['v18503', 13], ['v75121', 17], ['v9498', 19]], [['v57948', 0], ['v68771', 10], ['v83111', 11], ['v68812', 12], ['v11563', 13]], [['v18315', 0], ['v68812', 0], ['v68775', 1], ['v57948', 8], ['v83111', 9], ['v68771', 10], ['v68812', 12], ['v18503', 14], ['v1195', 19], ['v3305', 21], ['v61065', 23], ['v9901', 0], ['v68775', 2]], [['v83111', 0], ['v68771', 14], ['v2534', 16], ['v25647', 17], ['v68812', 18], ['v74594', 22], ['v68775', 3], ['v41716', 8], ['v68771', 9], ['v68812', 12], ['v18503', 14], ['v6890', 17], ['v39147', 23], ['v9901', 0]], [['v68771', 0], ['v68812', 12], ['v18503', 14]], [['v24511', 0], ['v3859', 23], ['v53888', 0]], [['v64246', 0], ['v41716', 10], ['v83111', 11], ['v68812', 12], ['v36986', 13], ['v18503', 14]], [['v74594', 0], ['v68775', 1], ['v41716', 6], ['v18503', 8], ['v14124', 9], ['v21315', 16], ['v12682', 18], ['v8389', 20]], [['v41716', 0], ['v68771', 9], ['v18503', 14], ['v6890', 15], ['v3305', 21], ['v39147', 23], ['v9901', 0]], [['v41716', 0], ['v4297', 11], ['v4692', 12]], [['v68812', 0], ['v68775', 5], ['v69912', 9], ['v68812', 10], ['v50483', 13], ['v53888', 16], ['v6127', 18], ['v74594', 22], ['v68775', 2], ['v68771', 9], ['v68812', 12], ['v18503', 14], ['v1195', 20], ['v3236', 22], ['v39147', 23], ['v9901', 0], ['v68771', 3], ['v41716', 8], ['v83111', 9], ['v68771', 10], ['v68812', 12], ['v18503', 14], ['v1303', 16], ['v39147', 23], ['v74594', 0], ['v29805', 7], ['v64246', 8], ['v6634', 9], ['v68812', 12], ['v18503', 13]], [['v3305', 0], ['v25647', 23], ['v68775', 0], ['v64246', 6], ['v6890', 13], ['v18503', 16], ['v25647', 17], ['v61065', 19], ['v69912', 21]], [['v68775', 0], ['v64246', 7], ['v68771', 8], ['v68812', 10], ['v18503', 14], ['v9498', 17], ['v9242', 18], ['v6890', 20], ['v395', 21], ['v3305', 22], ['v18315', 23], ['v68775', 5], ['v55121', 8], ['v68771', 9], ['v18503', 14], ['v1195', 17], ['v6890', 20], ['v3305', 22], ['v18315', 23], ['v9901', 0], ['v69912', 2], ['v55121', 9], ['v68768', 10], ['v881', 14], ['v68812', 16], ['v61065', 19], ['v74594', 22], ['v68771', 23], ['v68775', 4], ['v64246', 8], ['v11563', 9], ['v68768', 10], ['v68812', 12], ['v18503', 14], ['v9498', 15], ['v14124', 18], ['v25647', 23], ['v9901', 0]], [['v83111', 0], ['v68812', 11], ['v6890', 17], ['v18610', 20], ['v68775', 0]], [['v83111', 0], ['v68768', 9], ['v68771', 10], ['v18503', 14]], [['v74594', 0], ['v29805', 6]], [['v18503', 0], ['v68768', 17], ['v68812', 20], ['v74594', 21], ['v68771', 22]], [['v18503', 0], ['v58085', 12], ['v14124', 13], ['v6890', 14], ['v18315', 16], ['v68768', 17], ['v2240', 20]], [['v57948', 0], ['v83111', 9], ['v68771', 10], ['v68812', 12], ['v36986', 13], ['v18503', 14], ['v14124', 16], ['v13567', 19], ['v39147', 23]], [['v41716', 0], ['v68812', 8], ['v68768', 9], ['v68812', 11], ['v17690', 12], ['v64246', 15], ['v68768', 16], ['v74594', 18], ['v68771', 22], ['v68775', 0]], [['v68771', 0], ['v68812', 12], ['v18503', 14], ['v395', 15], ['v9498', 16], ['v18315', 23], ['v74594', 0], ['v9901', 1], ['v68775', 3]], [['v68771', 0], ['v710', 16], ['v14124', 20], ['v68775', 0], ['v41716', 7], ['v64246', 8], ['v11563', 10], ['v83111', 11], ['v68771', 12], ['v18503', 14], ['v14124', 19], ['v395', 22], ['v18315', 23], ['v29805', 6], ['v18503', 8], ['v14124', 9]], [['v53888', 0], ['v74594', 22], ['v69912', 23], ['v68775', 0]], [['v83111', 0], ['v68812', 11], ['v68768', 12], ['v18503', 14], ['v14124', 18], ['v18610', 20], ['v68775', 0]], [['v55121', 0], ['v68812', 12], ['v18503', 14], ['v47162', 16], ['v13567', 20], ['v6890', 21], ['v61065', 0]], [['v69912', 0], ['v6127', 9], ['v55121', 12], ['v68812', 16], ['v7382', 19], ['v61065', 22], ['v74594', 23], ['v68775', 0]], [['v83111', 0], ['v68771', 10], ['v68812', 12], ['v2060', 14]], [['v395', 0], ['v68768', 23], ['v9901', 0], ['v68775', 6], ['v41716', 11], ['v68812', 12], ['v18503', 14], ['v1155', 19], ['v395', 20], ['v40805', 21], ['v39147', 0], ['v68775', 1]], [['v6634', 0], ['v5310', 10], ['v68812', 11], ['v18503', 14], ['v14124', 16], ['v710', 17], ['v6890', 21], ['v53888', 23], ['v68775', 1], ['v68812', 6], ['v14124', 9], ['v9498', 13], ['v18503', 17], ['v68812', 18], ['v69912', 22], ['v68775', 23]], [['v83111', 0], ['v68771', 9], ['v68812', 10], ['v18503', 14], ['v77584', 17], ['v3305', 18], ['v395', 19], ['v74594', 23], ['v68775', 0]], [['v83111', 0], ['v68812', 11], ['v11563', 13], ['v18503', 14]], [['v15240', 0], ['v51500', 3]], [['v59530', 0], ['v68768', 17], ['v68812', 20], ['v61065', 22], ['v51500', 23], ['v9901', 0]], [['v68771', 0], ['v68812', 12], ['v18503', 14]], [['v3305', 0], ['v68775', 0]], [['v68812', 0], ['v18503', 14], ['v13567', 16], ['v395', 19], ['v890', 23], ['v68775', 0], ['v64246', 7], ['v14124', 9], ['v18315', 16], ['v68812', 20]], [['v68771', 0], ['v68812', 12], ['v18503', 14], ['v14124', 17], ['v395', 21], ['v77584', 22], ['v39147', 0]], [['v68812', 0], ['v18503', 14], ['v14225', 16], ['v33028', 17], ['v9775', 18], ['v61065', 0], ['v68775', 1], ['v68812', 8], ['v68768', 13], ['v74594', 19], ['v68775', 1], ['v41716', 8], ['v83111', 9], ['v68768', 10], ['v68812', 12], ['v42978', 14], ['v77584', 18], ['v81623', 19], ['v395', 21], ['v18315', 23], ['v575', 0], ['v9901', 1], ['v68775', 5], ['v64246', 10], ['v68812', 11], ['v18503', 14], ['v9498', 17], ['v39147', 0], ['v68775', 1]], [['v68768', 0], ['v2603', 14], ['v14124', 18]], [['v68812', 0], ['v68768', 14]], [['v74594', 0], ['v68771', 23]], [['v83111', 0], ['v68771', 11], ['v68812', 12], ['v64246', 13], ['v9498', 18], ['v18315', 1]], [['v41716', 0], ['v11563', 11], ['v3649', 12], ['v68812', 13], ['v68768', 15], ['v74594', 19], ['v68775', 2], ['v68812', 9], ['v83111', 15], ['v68771', 18], ['v61441', 19], ['v74594', 20], ['v68768', 22], ['v68775', 0]], [['v64246', 0], ['v68812', 11], ['v18503', 14], ['v40167', 17], ['v3305', 22], ['v9901', 0]], [['v68812', 0], ['v18503', 14], ['v6890', 18], ['v3305', 19], ['v2060', 23], ['v9901', 0], ['v68812', 3], ['v68771', 5], ['v64246', 12], ['v83111', 13], ['v68768', 14], ['v68812', 18], ['v74594', 19], ['v61065', 23], ['v68775', 1]], [['v14124', 0], ['v4628', 11], ['v43749', 13], ['v28851', 14], ['v68768', 17], ['v68812', 18], ['v68771', 21], ['v68775', 23]], [['v55121', 0], ['v68771', 17], ['v74594', 18], ['v68771', 20], ['v68812', 21], ['v68775', 22]], [['v2060', 0], ['v18503', 7], ['v14124', 12], ['v48715', 15], ['v55121', 16], ['v68771', 17], ['v74594', 18], ['v68812', 20], ['v68775', 22]], [['v18503', 0], ['v14124', 8], ['v43749', 12], ['v395', 14], ['v2603', 15], ['v83111', 16], ['v68812', 17], ['v25370', 19], ['v50977', 20], ['v9901', 23], ['v30302', 4]], [['v18503', 0], ['v43749', 17], ['v13567', 19], ['v71093', 22], ['v68775', 0], ['v64246', 5], ['v2060', 6], ['v18503', 7], ['v14124', 8], ['v6890', 14], ['v68768', 16], ['v61065', 20], ['v68812', 21], ['v68771', 23]], [['v18503', 0], ['v14124', 8], ['v4825', 11], ['v2603', 15], ['v68768', 16], ['v9901', 18], ['v68812', 20], ['v68775', 2], ['v68771', 3], ['v18503', 8], ['v19734', 9], ['v14124', 12], ['v28031', 14], ['v48715', 15], ['v68768', 16], ['v74594', 18], ['v68812', 20], ['v68775', 2], ['v69912', 6], ['v68771', 12], ['v18503', 14], ['v9498', 16], ['v48715', 22], ['v18315', 23], ['v68775', 1]], [['v41716', 0], ['v5310', 11], ['v68771', 12], ['v2060', 14]], [['v68812', 0], ['v9901', 23], ['v64246', 2], ['v68775', 4], ['v68768', 11]], [['v68812', 0], ['v64246', 12], ['v18503', 14], ['v78553', 16], ['v6676', 17], ['v2060', 23], ['v68775', 0]], [['v41716', 0], ['v83111', 10], ['v64246', 11], ['v18503', 14], ['v14124', 17], ['v48715', 22], ['v68775', 1], ['v83111', 6], ['v14124', 9], ['v17865', 15], ['v2603', 16], ['v74594', 18]], [['v41716', 0], ['v68812', 9], ['v69912', 10], ['v68812', 11], ['v64246', 12], ['v18315', 13], ['v18503', 14], ['v14124', 16], ['v395', 17], ['v14785', 20], ['v70663', 22]], [['v83111', 0], ['v68771', 11], ['v68812', 12], ['v2060', 14], ['v18503', 15], ['v9498', 17], ['v14785', 18], ['v14124', 19], ['v395', 20], ['v48715', 22], ['v18315', 3], ['v41716', 8], ['v64246', 11], ['v68768', 13], ['v68812', 14], ['v74594', 19], ['v68771', 21], ['v68775', 2]], [['v68768', 0], ['v68812', 14], ['v74594', 18], ['v64246', 21], ['v9901', 22]], [['v83111', 0], ['v68812', 12], ['v18503', 14], ['v14610', 15], ['v43749', 21], ['v18315', 0], ['v68775', 1]], [['v41716', 0], ['v83111', 10], ['v68771', 11], ['v18503', 14], ['v40167', 15], ['v43749', 16], ['v39584', 17], ['v14124', 19], ['v3305', 20], ['v74594', 23]], [['v18503', 0], ['v14124', 9], ['v6890', 10], ['v43749', 14], ['v74594', 18], ['v68771', 19], ['v68812', 20]], [['v68775', 0], ['v41716', 9], ['v83111', 10], ['v68812', 11], ['v64246', 12], ['v70663', 14]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzR53rfIljGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "800596cf-b06d-4b89-c0f4-6005b4a02ed8"
      },
      "source": [
        "import random\n",
        "n = len(m_events)  \n",
        "\n",
        "n_test = int( n * .2 ) \n",
        "n_train = n - (n_test)\n",
        "\n",
        "full_set = np.arange(n)\n",
        "train_set = random.sample(range(n), n_train)\n",
        "test_set = np.delete(full_set, train_set).tolist()\n",
        "\n",
        "print(f\"Dataset set terms: {n}\")\n",
        "print(f\"Train set terms: {n_train}\") \n",
        "print(f\"Test set terms: {n_test}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset set terms: 119\n",
            "Train set terms: 96\n",
            "Test set terms: 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWvls8lTj5up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_events = np.asarray(m_events)\n",
        "train_data = m_events[train_set]  \n",
        "test_data = m_events[test_set]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q4l6qbrEtaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "df27d4ef-88e3-4a57-8620-bdc129473bb3"
      },
      "source": [
        "%time\n",
        "def _venue_only(data):\n",
        "  all_sequences = []\n",
        "  for sequence in data:\n",
        "    events = []\n",
        "    for event in sequence:      \n",
        "      events.append(event[0])\n",
        "    all_sequences.append(events)\n",
        "  return all_sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.2 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB0wZjVIEwjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "39e6bf51-3f43-4ae3-bf7e-8a8b8694ea1e"
      },
      "source": [
        "%time\n",
        "def _time_only(data):\n",
        "  all_sequences = []\n",
        "  for sequence in data:\n",
        "    events = []\n",
        "    for event in sequence:      \n",
        "      events.append(event[1])\n",
        "    all_sequences.append(events)\n",
        "  return all_sequences\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
            "Wall time: 6.91 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMQ2EUijEVcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "eefe43ff-92f8-4d58-d335-4db7d3621c6d"
      },
      "source": [
        "#train data, split the features \n",
        "\n",
        "v_events_train = _venue_only(train_data)\n",
        "print(v_events_train)\n",
        "t_events_train = _time_only(train_data)\n",
        "print(t_events_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['v68812', 'v18503', 'v14225', 'v33028', 'v9775', 'v61065', 'v68775', 'v68812', 'v68768', 'v74594', 'v68775', 'v41716', 'v83111', 'v68768', 'v68812', 'v42978', 'v77584', 'v81623', 'v395', 'v18315', 'v575', 'v9901', 'v68775', 'v64246', 'v68812', 'v18503', 'v9498', 'v39147', 'v68775'], ['v68771', 'v68812', 'v18503'], ['v83111', 'v68771', 'v68812', 'v2060'], ['v68812', 'v68771'], ['v69912', 'v6127', 'v55121', 'v68812', 'v7382', 'v61065', 'v74594', 'v68775'], ['v55121', 'v68812', 'v18503', 'v47162', 'v13567', 'v6890', 'v61065'], ['v53888', 'v74594', 'v69912', 'v68775'], ['v18315', 'v9901', 'v68775', 'v68771', 'v68812', 'v18503', 'v8089', 'v1156', 'v20285', 'v3305', 'v39147', 'v9901', 'v69912', 'v68771', 'v57948', 'v83111', 'v18503', 'v28851'], ['v68812', 'v18503', 'v18610', 'v8738', 'v69912', 'v68775', 'v41716', 'v68812', 'v18503', 'v65878'], ['v68812', 'v68768'], ['v68812', 'v18503', 'v6890', 'v3305', 'v2060', 'v9901', 'v68812', 'v68771', 'v64246', 'v83111', 'v68768', 'v68812', 'v74594', 'v61065', 'v68775'], ['v83111', 'v68812', 'v11563', 'v18503'], ['v68771', 'v68812', 'v18503'], ['v68812', 'v68775', 'v69912'], ['v69912', 'v36986', 'v83111', 'v2060', 'v53888', 'v3305', 'v39147', 'v74594'], ['v68812', 'v9901', 'v64246', 'v68775', 'v68768'], ['v68812', 'v83111', 'v68775', 'v68812', 'v18503', 'v6111'], ['v83111', 'v68771', 'v68812', 'v18503', 'v28851', 'v80976', 'v11841', 'v3305', 'v9901', 'v40893', 'v83111', 'v68771', 'v68812', 'v18503', 'v1195', 'v18693', 'v12251', 'v74594', 'v68812', 'v68771', 'v83111', 'v6634', 'v18503', 'v1195', 'v14785', 'v74594', 'v68775', 'v68771', 'v29805', 'v83111', 'v68812', 'v19502', 'v9498', 'v6890', 'v68812', 'v74594', 'v68771'], ['v68775', 'v64246', 'v68771', 'v68812', 'v18503', 'v9498', 'v9242', 'v6890', 'v395', 'v3305', 'v18315', 'v68775', 'v55121', 'v68771', 'v18503', 'v1195', 'v6890', 'v3305', 'v18315', 'v9901', 'v69912', 'v55121', 'v68768', 'v881', 'v68812', 'v61065', 'v74594', 'v68771', 'v68775', 'v64246', 'v11563', 'v68768', 'v68812', 'v18503', 'v9498', 'v14124', 'v25647', 'v9901'], ['v83111', 'v68812', 'v68768', 'v18503', 'v14124', 'v18610', 'v68775'], ['v9901', 'v40893', 'v41716', 'v68812', 'v18503', 'v3305', 'v1195', 'v18315', 'v68775'], ['v68775', 'v64246', 'v41716', 'v83111', 'v68771', 'v68812', 'v2060', 'v18503', 'v3305', 'v61065', 'v68771', 'v29805', 'v68771', 'v68812', 'v14124', 'v3305', 'v39147', 'v9901', 'v68775', 'v68771', 'v41716', 'v83111', 'v68771'], ['v68771', 'v11563', 'v18503', 'v8089'], ['v68775', 'v41716', 'v83111', 'v68812', 'v18503'], ['v83111', 'v68812', 'v6890', 'v18610', 'v68775'], ['v59530', 'v68768', 'v68812', 'v61065', 'v51500', 'v9901'], ['v41716', 'v11563', 'v3649', 'v68812', 'v68768', 'v74594', 'v68775', 'v68812', 'v83111', 'v68771', 'v61441', 'v74594', 'v68768', 'v68775'], ['v395', 'v68768', 'v9901', 'v68775', 'v41716', 'v68812', 'v18503', 'v1155', 'v395', 'v40805', 'v39147', 'v68775'], ['v55121', 'v68771', 'v74594', 'v68771', 'v68812', 'v68775'], ['v24511', 'v3859', 'v53888'], ['v23056', 'v68812', 'v74594', 'v68775', 'v68771'], ['v74594', 'v12489'], ['v68771', 'v68812', 'v18503', 'v395', 'v9498', 'v18315', 'v74594', 'v9901', 'v68775'], ['v61065', 'v74594', 'v68771', 'v68775'], ['v18503', 'v14124', 'v6890', 'v43749', 'v74594', 'v68771', 'v68812'], ['v41716', 'v68771', 'v68812', 'v18503', 'v9498', 'v6890', 'v3305', 'v74594'], ['v68768', 'v68812', 'v2060'], ['v74594', 'v29805'], ['v68812', 'v68775', 'v69912', 'v68812', 'v50483', 'v53888', 'v6127', 'v74594', 'v68775', 'v68771', 'v68812', 'v18503', 'v1195', 'v3236', 'v39147', 'v9901', 'v68771', 'v41716', 'v83111', 'v68771', 'v68812', 'v18503', 'v1303', 'v39147', 'v74594', 'v29805', 'v64246', 'v6634', 'v68812', 'v18503'], ['v39147', 'v68812', 'v68771', 'v69912'], ['v57948', 'v68771', 'v83111', 'v68812', 'v11563'], ['v83111', 'v68771', 'v68812', 'v18503'], ['v57948', 'v29805', 'v18503', 'v1195'], ['v41716', 'v83111', 'v68771', 'v18503', 'v9257', 'v9498', 'v3305', 'v68812', 'v68771', 'v41716', 'v11563', 'v68771', 'v68812', 'v18503', 'v9498', 'v3305', 'v9901', 'v68775', 'v69912'], ['v74594', 'v68771'], ['v68812', 'v18503', 'v13567', 'v395', 'v890', 'v68775', 'v64246', 'v14124', 'v18315', 'v68812'], ['v18503', 'v14124', 'v4825', 'v2603', 'v68768', 'v9901', 'v68812', 'v68775', 'v68771', 'v18503', 'v19734', 'v14124', 'v28031', 'v48715', 'v68768', 'v74594', 'v68812', 'v68775', 'v69912', 'v68771', 'v18503', 'v9498', 'v48715', 'v18315', 'v68775'], ['v68775', 'v41716', 'v68812', 'v12197', 'v12489', 'v68771'], ['v83111', 'v68771', 'v68812', 'v64246', 'v9498', 'v18315'], ['v18503', 'v58085', 'v14124', 'v6890', 'v18315', 'v68768', 'v2240'], ['v68768', 'v68812', 'v74594', 'v64246', 'v9901'], ['v18315', 'v68812', 'v68775', 'v57948', 'v83111', 'v68771', 'v68812', 'v18503', 'v1195', 'v3305', 'v61065', 'v9901', 'v68775'], ['v68775', 'v68771', 'v18503', 'v11625', 'v9257', 'v69912'], ['v18503', 'v68768', 'v68812', 'v74594', 'v68771'], ['v64246', 'v41716', 'v83111', 'v68812', 'v36986', 'v18503'], ['v41716', 'v83111', 'v68771', 'v18503', 'v40167', 'v43749', 'v39584', 'v14124', 'v3305', 'v74594'], ['v68771', 'v68812', 'v18503', 'v7256', 'v2641'], ['v83111', 'v68771', 'v68812', 'v18503', 'v9498', 'v74594', 'v9901', 'v69912', 'v29805', 'v55121', 'v68771', 'v18503', 'v8090', 'v25457', 'v18315', 'v2603', 'v68775', 'v83111', 'v6634', 'v11563', 'v68812', 'v55121', 'v18503', 'v6890', 'v14124', 'v3305', 'v9901', 'v68775', 'v83111', 'v68771', 'v18503', 'v75121', 'v9498'], ['v3305', 'v25647', 'v68775', 'v64246', 'v6890', 'v18503', 'v25647', 'v61065', 'v69912'], ['v83111', 'v68771', 'v68812', 'v18503', 'v77584', 'v3305', 'v395', 'v74594', 'v68775'], ['v68771', 'v68812', 'v18503', 'v14124', 'v395', 'v77584', 'v39147'], ['v83111', 'v68771', 'v2534', 'v25647', 'v68812', 'v74594', 'v68775', 'v41716', 'v68771', 'v68812', 'v18503', 'v6890', 'v39147', 'v9901'], ['v68768', 'v2603', 'v14124'], ['v41716', 'v68771', 'v68812', 'v18503', 'v3305', 'v9901', 'v68775', 'v41716', 'v83111', 'v68812', 'v2042', 'v56693', 'v61065', 'v74594', 'v68812'], ['v18503', 'v14124', 'v43749', 'v395', 'v2603', 'v83111', 'v68812', 'v25370', 'v50977', 'v9901', 'v30302'], ['v57948', 'v83111', 'v68771', 'v68812', 'v2060', 'v85431', 'v3305', 'v61065', 'v9901'], ['v68775', 'v83111', 'v18503'], ['v68775', 'v55121', 'v68812', 'v18503', 'v44187', 'v5757', 'v81623', 'v44187', 'v69912'], ['v74594', 'v68771', 'v64246', 'v68812', 'v6890', 'v3305', 'v18315', 'v68768', 'v68775', 'v64246', 'v55121', 'v68812'], ['v74594', 'v69912', 'v68771', 'v61065', 'v68775'], ['v68771', 'v69912', 'v68768', 'v68771', 'v83111', 'v68771'], ['v41716', 'v83111', 'v64246', 'v18503', 'v14124', 'v48715', 'v68775', 'v83111', 'v14124', 'v17865', 'v2603', 'v74594'], ['v68775', 'v41716', 'v83111', 'v68812', 'v64246', 'v70663'], ['v68771', 'v710', 'v14124', 'v68775', 'v41716', 'v64246', 'v11563', 'v83111', 'v68771', 'v18503', 'v14124', 'v395', 'v18315', 'v29805', 'v18503', 'v14124'], ['v41716', 'v68771', 'v68812', 'v18503', 'v9498', 'v40168', 'v6890', 'v14785', 'v18315', 'v9901'], ['v68775', 'v68771', 'v83111', 'v68771', 'v18503', 'v9498', 'v39147', 'v68771'], ['v3305', 'v39147', 'v68771'], ['v18503', 'v69912', 'v68771'], ['v68812', 'v41716', 'v18503', 'v39550', 'v81598', 'v63209', 'v2060', 'v9901', 'v68771', 'v69912', 'v68771', 'v68812', 'v11563', 'v83111', 'v74594', 'v68771'], ['v83111', 'v68768', 'v68771', 'v18503'], ['v41716', 'v4297', 'v4692'], ['v14124', 'v4628', 'v43749', 'v28851', 'v68768', 'v68812', 'v68771', 'v68775'], ['v74594', 'v68775', 'v41716', 'v18503', 'v14124', 'v21315', 'v12682', 'v8389'], ['v68771', 'v69912', 'v64246', 'v29805', 'v18503', 'v25312', 'v27753', 'v74594', 'v68771', 'v68775', 'v68775', 'v68812', 'v18503', 'v24143', 'v82320', 'v74594', 'v9901'], ['v56693', 'v68812', 'v69912'], ['v68812', 'v55121', 'v18503', 'v1195', 'v1457', 'v13233', 'v53888', 'v61065'], ['v61065', 'v9901', 'v68775', 'v68771', 'v68771', 'v18503', 'v24143', 'v8915', 'v2060', 'v68775'], ['v68771', 'v68812', 'v2060', 'v18503', 'v3305'], ['v83111', 'v68771', 'v68812', 'v2060', 'v18503', 'v9498', 'v14785', 'v14124', 'v395', 'v48715', 'v18315', 'v41716', 'v64246', 'v68768', 'v68812', 'v74594', 'v68771', 'v68775'], ['v41716', 'v68812', 'v69912', 'v68812', 'v64246', 'v18315', 'v18503', 'v14124', 'v395', 'v14785', 'v70663'], ['v3240', 'v53888', 'v61065', 'v69912'], ['v6634', 'v5310', 'v68812', 'v18503', 'v14124', 'v710', 'v6890', 'v53888', 'v68775', 'v68812', 'v14124', 'v9498', 'v18503', 'v68812', 'v69912', 'v68775'], ['v18503', 'v43749', 'v13567', 'v71093', 'v68775', 'v64246', 'v2060', 'v18503', 'v14124', 'v6890', 'v68768', 'v61065', 'v68812', 'v68771'], ['v68812', 'v33365'], ['v41716', 'v68812', 'v68768', 'v68812', 'v17690', 'v64246', 'v68768', 'v74594', 'v68771', 'v68775'], ['v41716', 'v68812', 'v11563', 'v2060', 'v59700', 'v24511', 'v3240', 'v18315', 'v9901']]\n",
            "[[0, 14, 16, 17, 18, 0, 1, 8, 13, 19, 1, 8, 9, 10, 12, 14, 18, 19, 21, 23, 0, 1, 5, 10, 11, 14, 17, 0, 1], [0, 12, 14], [0, 10, 12, 14], [0, 1], [0, 9, 12, 16, 19, 22, 23, 0], [0, 12, 14, 16, 20, 21, 0], [0, 22, 23, 0], [0, 0, 3, 10, 12, 14, 15, 16, 20, 22, 23, 0, 1, 2, 9, 10, 14, 15], [0, 14, 15, 22, 0, 7, 9, 10, 14, 15], [0, 14], [0, 14, 18, 19, 23, 0, 3, 5, 12, 13, 14, 18, 19, 23, 1], [0, 11, 13, 14], [0, 12, 14], [0, 23, 0], [0, 11, 12, 13, 14, 21, 23, 0], [0, 23, 2, 4, 11], [0, 9, 10, 11, 12, 14], [0, 10, 12, 14, 16, 17, 20, 21, 0, 2, 9, 10, 13, 14, 15, 18, 19, 23, 0, 1, 8, 10, 14, 16, 21, 0, 1, 2, 8, 9, 11, 14, 17, 20, 22, 23, 0], [0, 7, 8, 10, 14, 17, 18, 20, 21, 22, 23, 5, 8, 9, 14, 17, 20, 22, 23, 0, 2, 9, 10, 14, 16, 19, 22, 23, 4, 8, 9, 10, 12, 14, 15, 18, 23, 0], [0, 11, 12, 14, 18, 20, 0], [0, 3, 10, 11, 14, 21, 22, 23, 0], [0, 8, 9, 10, 11, 12, 13, 14, 21, 23, 0, 7, 8, 12, 19, 22, 23, 0, 2, 3, 7, 8, 9], [0, 13, 14, 15], [0, 8, 10, 12, 14], [0, 11, 17, 20, 0], [0, 17, 20, 22, 23, 0], [0, 11, 12, 13, 15, 19, 2, 9, 15, 18, 19, 20, 22, 0], [0, 23, 0, 6, 11, 12, 14, 19, 20, 21, 0, 1], [0, 17, 18, 20, 21, 22], [0, 23, 0], [0, 16, 17, 19, 22], [0, 20], [0, 12, 14, 15, 16, 23, 0, 1, 3], [0, 17, 20, 23], [0, 9, 10, 14, 18, 19, 20], [0, 9, 13, 14, 16, 18, 20, 23], [0, 11, 12], [0, 6], [0, 5, 9, 10, 13, 16, 18, 22, 2, 9, 12, 14, 20, 22, 23, 0, 3, 8, 9, 10, 12, 14, 16, 23, 0, 7, 8, 9, 12, 13], [0, 22, 23, 0], [0, 10, 11, 12, 13], [0, 10, 12, 14], [0, 10, 12, 14], [0, 9, 10, 14, 17, 19, 21, 0, 1, 8, 10, 11, 12, 14, 19, 21, 0, 2, 3], [0, 23], [0, 14, 16, 19, 23, 0, 7, 9, 16, 20], [0, 8, 11, 15, 16, 18, 20, 2, 3, 8, 9, 12, 14, 15, 16, 18, 20, 2, 6, 12, 14, 16, 22, 23, 1], [0, 11, 12, 13, 20, 22], [0, 11, 12, 13, 18, 1], [0, 12, 13, 14, 16, 17, 20], [0, 14, 18, 21, 22], [0, 0, 1, 8, 9, 10, 12, 14, 19, 21, 23, 0, 2], [0, 9, 14, 15, 17, 0], [0, 17, 20, 21, 22], [0, 10, 11, 12, 13, 14], [0, 10, 11, 14, 15, 16, 17, 19, 20, 23], [0, 9, 12, 17, 18], [0, 10, 13, 14, 16, 23, 0, 4, 9, 10, 11, 14, 21, 22, 23, 0, 1, 8, 9, 10, 11, 13, 14, 18, 19, 21, 0, 2, 9, 10, 13, 17, 19], [0, 23, 0, 6, 13, 16, 17, 19, 21], [0, 9, 10, 14, 17, 18, 19, 23, 0], [0, 12, 14, 17, 21, 22, 0], [0, 14, 16, 17, 18, 22, 3, 8, 9, 12, 14, 17, 23, 0], [0, 14, 18], [0, 9, 12, 14, 20, 0, 4, 10, 11, 12, 13, 14, 17, 18, 21], [0, 8, 12, 14, 15, 16, 17, 19, 20, 23, 4], [0, 9, 10, 12, 13, 16, 22, 23, 0], [0, 9, 12], [0, 9, 11, 14, 15, 16, 17, 19, 0], [0, 1, 8, 11, 16, 19, 21, 22, 5, 8, 9, 12], [0, 11, 13, 15, 19], [0, 11, 17, 18, 19, 21], [0, 10, 11, 14, 17, 22, 1, 6, 9, 15, 16, 18], [0, 9, 10, 11, 12, 14], [0, 16, 20, 0, 7, 8, 10, 11, 12, 14, 19, 22, 23, 6, 8, 9], [0, 11, 13, 14, 15, 17, 20, 21, 23, 0], [0, 1, 8, 9, 12, 17, 21, 22], [0, 23, 0], [0, 22, 23], [0, 11, 12, 14, 15, 21, 22, 23, 1, 2, 9, 12, 14, 18, 19, 21], [0, 9, 10, 14], [0, 11, 12], [0, 11, 13, 14, 17, 18, 21, 23], [0, 1, 6, 8, 9, 16, 18, 20], [0, 8, 9, 10, 12, 13, 16, 22, 23, 0, 7, 11, 12, 13, 19, 21, 23], [0, 18, 22], [0, 11, 12, 14, 17, 19, 21, 23], [0, 23, 6, 9, 10, 12, 15, 19, 21, 23], [0, 11, 13, 14, 15], [0, 11, 12, 14, 15, 17, 18, 19, 20, 22, 3, 8, 11, 13, 14, 19, 21, 2], [0, 9, 10, 11, 12, 13, 14, 16, 17, 20, 22], [0, 21, 23, 0], [0, 10, 11, 14, 16, 17, 21, 23, 1, 6, 9, 13, 17, 18, 22, 23], [0, 17, 19, 22, 0, 5, 6, 7, 8, 14, 16, 20, 21, 23], [0, 10], [0, 8, 9, 11, 12, 15, 16, 18, 22, 0], [0, 11, 13, 14, 18, 21, 22, 23, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GOmZ97XJz4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "03b5ecea-7cbd-4eec-8135-132a9b4902be"
      },
      "source": [
        "#test data, split the features \n",
        "\n",
        "v_events_test = _venue_only(test_data)\n",
        "print(v_events_test)\n",
        "t_events_test = _time_only(test_data)\n",
        "print(t_events_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['v68771', 'v69912', 'v68771', 'v68812'], ['v68768', 'v68812', 'v44187', 'v13815', 'v2060', 'v69912', 'v68771'], ['v68771', 'v83111', 'v18503', 'v2133', 'v61065', 'v69912'], ['v68812', 'v11563', 'v4446', 'v74594', 'v68771', 'v69912'], ['v68775', 'v83111', 'v8056', 'v1195', 'v73617', 'v9901', 'v68771', 'v74594', 'v64246', 'v68812', 'v18503', 'v3897', 'v44187', 'v2641', 'v68812'], ['v18315', 'v9901'], ['v68771', 'v68812', 'v18503', 'v44187', 'v1156', 'v74594', 'v68771', 'v41716', 'v83111', 'v68812', 'v18503', 'v1195', 'v28851', 'v39147', 'v68775', 'v68771', 'v39147', 'v228', 'v230', 'v68812', 'v74594'], ['v41716', 'v83111', 'v68812', 'v18503', 'v9257', 'v1303', 'v19502', 'v44187', 'v38600', 'v74594', 'v68771', 'v68775', 'v57948', 'v64246', 'v83111', 'v68812', 'v18503', 'v6890', 'v3305', 'v18315', 'v9901', 'v68771', 'v68775', 'v41716', 'v68812', 'v11563', 'v18315', 'v68812'], ['v41716', 'v83111', 'v18503', 'v3305', 'v18315', 'v9901', 'v68771', 'v41716', 'v83111', 'v18503'], ['v2721', 'v74594', 'v68775'], ['v41716', 'v83111', 'v68771', 'v18503', 'v14124', 'v6890', 'v9901', 'v68775', 'v83111', 'v68771', 'v18503'], ['v39147', 'v68812', 'v68771', 'v41716', 'v68771', 'v13268'], ['v68812', 'v83111', 'v68812'], ['v18315', 'v69912'], ['v41716', 'v68771', 'v18503', 'v6890', 'v3305', 'v39147', 'v9901'], ['v57948', 'v83111', 'v68771', 'v68812', 'v36986', 'v18503', 'v14124', 'v13567', 'v39147'], ['v15240', 'v51500'], ['v3305', 'v68775'], ['v64246', 'v68812', 'v18503', 'v40167', 'v3305', 'v9901'], ['v2060', 'v18503', 'v14124', 'v48715', 'v55121', 'v68771', 'v74594', 'v68812', 'v68775'], ['v41716', 'v5310', 'v68771', 'v2060'], ['v68812', 'v64246', 'v18503', 'v78553', 'v6676', 'v2060', 'v68775'], ['v83111', 'v68812', 'v18503', 'v14610', 'v43749', 'v18315', 'v68775']]\n",
            "[[0, 13, 17, 19], [0, 9, 14, 20, 22, 23, 0], [0, 8, 12, 19, 21, 22], [0, 14, 16, 20, 21, 23], [0, 10, 16, 20, 21, 0, 4, 8, 9, 10, 14, 17, 19, 21, 23], [0, 0], [0, 12, 14, 15, 18, 0, 1, 8, 9, 12, 14, 15, 17, 23, 0, 1, 6, 9, 10, 17, 22], [0, 10, 11, 14, 15, 16, 17, 18, 19, 23, 0, 5, 8, 9, 10, 11, 14, 15, 20, 23, 0, 2, 3, 8, 11, 13, 14, 17], [0, 9, 14, 20, 23, 0, 3, 10, 12, 14], [0, 23, 0], [0, 9, 10, 14, 17, 19, 0, 5, 10, 12, 14], [0, 0, 1, 8, 12, 13], [0, 21, 22], [0, 22], [0, 9, 14, 15, 21, 23, 0], [0, 9, 10, 12, 13, 14, 16, 19, 23], [0, 3], [0, 0], [0, 11, 14, 17, 22, 0], [0, 7, 12, 15, 16, 17, 18, 20, 22], [0, 11, 12, 14], [0, 12, 14, 16, 17, 23, 0], [0, 12, 14, 15, 21, 0, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LRJiBZR7T9G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "121c8da4-0fd0-4374-e479-91163cb92734"
      },
      "source": [
        "def _get_maxlength_seq(data):\n",
        "  t = []\n",
        "  for i in data:\n",
        "    t.append([i,len(i)])\n",
        "  temp_df = pd.DataFrame(t)\n",
        "  temp_df.sort_values(by=1, ascending=False,inplace=True)\n",
        "  return np.max(temp_df[1])\n",
        "\n",
        "max_length_train= _get_maxlength_seq(train_data)\n",
        "max_length_test= _get_maxlength_seq(test_data)\n",
        "\n",
        "print(f\"max_length_train: {max_length_train}\")\n",
        "print(f\"max_length_test: {max_length_test}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_length_train: 38\n",
            "max_length_test: 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6rpGJim7nIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _all_venue_index():\n",
        "  count = 1\n",
        "  for venue in Checkin_u2651_nodup.VenueID.unique():\n",
        "    all_venues[venue] = count\n",
        "    count+=1\n",
        "  return all_venues\n",
        "\n",
        "all_venues = {}\n",
        "all_venues = _all_venue_index()\n",
        "all_venues_list = Checkin_u2651_nodup.VenueID.unique()\n",
        "no_of_samples_train = len(train_data)\n",
        "no_of_samples_test = len(test_data)\n",
        "no_of_venues = len(Checkin_u2651_nodup.VenueID.unique())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLBlj6W_78s2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _new_split(data):\n",
        "  features = []\n",
        "  targets = []\n",
        "  for sequences in data:\n",
        "    if(len(sequences)) >= 2:\n",
        "      features.append(sequences[:-1])\n",
        "      targets.append(sequences[-1])\n",
        "  return features, targets\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVhuq5Mm8G-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_s, targets_s = _new_split(v_events_train)\n",
        "features_t, targets_t = _new_split(t_events_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpZE1eytKHd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_s_test, targets_s_test = _new_split(v_events_test)\n",
        "features_t_test, targets_t_test = _new_split(t_events_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--Sq6Ghp8MIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7ad4675b-e720-4bc0-df99-f56bf3451650"
      },
      "source": [
        "print(features_s[1], targets_s[1])\n",
        "\n",
        "print(features_t[1], targets_t[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['v68771', 'v68812'] v18503\n",
            "[0, 12] 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X93At7bI2cRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train x and y\n",
        "\n",
        "x_train = np.zeros((no_of_samples_train, max_length_train, no_of_venues+1), dtype=np.bool)\n",
        "y_train = np.zeros((no_of_samples_train, no_of_venues+1), dtype=np.bool)\n",
        "\n",
        "def _one_hot(x,y,features_s,targets_s):\n",
        "  for i, sequence in enumerate(features_s):\n",
        "    for t, venue in enumerate(sequence):\n",
        "        x[i, t, all_venues[venue]] = 1\n",
        "    y[i, all_venues[targets_s[i]]] = 1\n",
        "\n",
        "_one_hot(x_train, y_train, features_s,targets_s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJQzVobi6XkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_test = np.zeros((no_of_samples_test, max_length_test, no_of_venues+1), dtype=np.bool)\n",
        "y_test = np.zeros((no_of_samples_test, no_of_venues+1), dtype=np.bool)\n",
        "\n",
        "def _one_hot(x,y,features_s_test,targets_s_test):\n",
        "  for i, sequence in enumerate(features_s_test):\n",
        "    for t, venue in enumerate(sequence):\n",
        "        x_test[i, t, all_venues[venue]] = 1\n",
        "    y_test[i, all_venues[targets_s_test[i]]] = 1\n",
        "\n",
        "_one_hot(x_test, y_test, features_s_test,targets_s_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWduRyMbR64D",
        "colab_type": "text"
      },
      "source": [
        "1. **LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvtKXKMs83uv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2578d07b-64df-4307-9c75-8ac017908ba0"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZRUc_D6UiWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Flatten, Embedding\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEqCsSgjAwFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 139   # number of outputs = number of digits\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT = 0.2 # how much TRAIN is reserved for VALIDATION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwUd-MLhIxza",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "28baf621-6589-417f-d79b-1bcd4ec8114f"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(128, name='lstm_layer', input_shape=(max_length_train,no_of_venues+1)))\n",
        "model.add(tf.keras.layers.Dense(no_of_venues+1, name='dense_layer', activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#https://keras.io/examples/lstm_text_generation/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_layer (LSTM)            (None, 128)               137728    \n",
            "_________________________________________________________________\n",
            "dense_layer (Dense)          (None, 140)               18060     \n",
            "=================================================================\n",
            "Total params: 155,788\n",
            "Trainable params: 155,788\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ6i2RvFIIr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT3ZQp7ex7Oi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dfde984a-7175-4c7c-c76d-bb4236cb72b7"
      },
      "source": [
        "print('Train...')\n",
        "model.fit(x_train, \n",
        "          y_train,\n",
        "          epochs=1000,\n",
        "          verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/1000\n",
            "3/3 - 0s - loss: 4.9382 - accuracy: 0.1458\n",
            "Epoch 2/1000\n",
            "3/3 - 0s - loss: 4.9208 - accuracy: 0.2188\n",
            "Epoch 3/1000\n",
            "3/3 - 0s - loss: 4.8771 - accuracy: 0.2188\n",
            "Epoch 4/1000\n",
            "3/3 - 0s - loss: 4.6621 - accuracy: 0.2188\n",
            "Epoch 5/1000\n",
            "3/3 - 0s - loss: 3.7237 - accuracy: 0.2188\n",
            "Epoch 6/1000\n",
            "3/3 - 0s - loss: 3.2685 - accuracy: 0.2188\n",
            "Epoch 7/1000\n",
            "3/3 - 0s - loss: 3.1357 - accuracy: 0.2188\n",
            "Epoch 8/1000\n",
            "3/3 - 0s - loss: 3.0301 - accuracy: 0.2188\n",
            "Epoch 9/1000\n",
            "3/3 - 0s - loss: 2.9817 - accuracy: 0.2188\n",
            "Epoch 10/1000\n",
            "3/3 - 0s - loss: 2.9340 - accuracy: 0.2188\n",
            "Epoch 11/1000\n",
            "3/3 - 0s - loss: 2.9029 - accuracy: 0.2188\n",
            "Epoch 12/1000\n",
            "3/3 - 0s - loss: 2.8873 - accuracy: 0.2188\n",
            "Epoch 13/1000\n",
            "3/3 - 0s - loss: 2.8641 - accuracy: 0.2188\n",
            "Epoch 14/1000\n",
            "3/3 - 0s - loss: 2.8564 - accuracy: 0.2188\n",
            "Epoch 15/1000\n",
            "3/3 - 0s - loss: 2.8463 - accuracy: 0.2188\n",
            "Epoch 16/1000\n",
            "3/3 - 0s - loss: 2.8399 - accuracy: 0.2188\n",
            "Epoch 17/1000\n",
            "3/3 - 0s - loss: 2.8375 - accuracy: 0.2188\n",
            "Epoch 18/1000\n",
            "3/3 - 0s - loss: 2.8326 - accuracy: 0.2188\n",
            "Epoch 19/1000\n",
            "3/3 - 0s - loss: 2.8316 - accuracy: 0.2188\n",
            "Epoch 20/1000\n",
            "3/3 - 0s - loss: 2.8290 - accuracy: 0.2188\n",
            "Epoch 21/1000\n",
            "3/3 - 0s - loss: 2.8277 - accuracy: 0.2188\n",
            "Epoch 22/1000\n",
            "3/3 - 0s - loss: 2.8288 - accuracy: 0.2188\n",
            "Epoch 23/1000\n",
            "3/3 - 0s - loss: 2.8265 - accuracy: 0.2188\n",
            "Epoch 24/1000\n",
            "3/3 - 0s - loss: 2.8253 - accuracy: 0.2188\n",
            "Epoch 25/1000\n",
            "3/3 - 0s - loss: 2.8260 - accuracy: 0.2188\n",
            "Epoch 26/1000\n",
            "3/3 - 0s - loss: 2.8237 - accuracy: 0.2188\n",
            "Epoch 27/1000\n",
            "3/3 - 0s - loss: 2.8256 - accuracy: 0.2188\n",
            "Epoch 28/1000\n",
            "3/3 - 0s - loss: 2.8232 - accuracy: 0.2188\n",
            "Epoch 29/1000\n",
            "3/3 - 0s - loss: 2.8269 - accuracy: 0.2188\n",
            "Epoch 30/1000\n",
            "3/3 - 0s - loss: 2.8257 - accuracy: 0.2188\n",
            "Epoch 31/1000\n",
            "3/3 - 0s - loss: 2.8245 - accuracy: 0.2188\n",
            "Epoch 32/1000\n",
            "3/3 - 0s - loss: 2.8262 - accuracy: 0.2188\n",
            "Epoch 33/1000\n",
            "3/3 - 0s - loss: 2.8217 - accuracy: 0.2188\n",
            "Epoch 34/1000\n",
            "3/3 - 0s - loss: 2.8248 - accuracy: 0.2188\n",
            "Epoch 35/1000\n",
            "3/3 - 0s - loss: 2.8201 - accuracy: 0.2188\n",
            "Epoch 36/1000\n",
            "3/3 - 0s - loss: 2.8213 - accuracy: 0.2188\n",
            "Epoch 37/1000\n",
            "3/3 - 0s - loss: 2.8211 - accuracy: 0.2188\n",
            "Epoch 38/1000\n",
            "3/3 - 0s - loss: 2.8246 - accuracy: 0.2188\n",
            "Epoch 39/1000\n",
            "3/3 - 0s - loss: 2.8222 - accuracy: 0.2188\n",
            "Epoch 40/1000\n",
            "3/3 - 0s - loss: 2.8204 - accuracy: 0.2188\n",
            "Epoch 41/1000\n",
            "3/3 - 0s - loss: 2.8193 - accuracy: 0.2188\n",
            "Epoch 42/1000\n",
            "3/3 - 0s - loss: 2.8204 - accuracy: 0.2188\n",
            "Epoch 43/1000\n",
            "3/3 - 0s - loss: 2.8210 - accuracy: 0.2188\n",
            "Epoch 44/1000\n",
            "3/3 - 0s - loss: 2.8188 - accuracy: 0.2188\n",
            "Epoch 45/1000\n",
            "3/3 - 0s - loss: 2.8208 - accuracy: 0.2188\n",
            "Epoch 46/1000\n",
            "3/3 - 0s - loss: 2.8193 - accuracy: 0.2188\n",
            "Epoch 47/1000\n",
            "3/3 - 0s - loss: 2.8207 - accuracy: 0.2188\n",
            "Epoch 48/1000\n",
            "3/3 - 0s - loss: 2.8191 - accuracy: 0.2188\n",
            "Epoch 49/1000\n",
            "3/3 - 0s - loss: 2.8201 - accuracy: 0.2188\n",
            "Epoch 50/1000\n",
            "3/3 - 0s - loss: 2.8215 - accuracy: 0.2188\n",
            "Epoch 51/1000\n",
            "3/3 - 0s - loss: 2.8181 - accuracy: 0.2188\n",
            "Epoch 52/1000\n",
            "3/3 - 0s - loss: 2.8194 - accuracy: 0.2188\n",
            "Epoch 53/1000\n",
            "3/3 - 0s - loss: 2.8212 - accuracy: 0.2188\n",
            "Epoch 54/1000\n",
            "3/3 - 0s - loss: 2.8198 - accuracy: 0.2188\n",
            "Epoch 55/1000\n",
            "3/3 - 0s - loss: 2.8190 - accuracy: 0.2188\n",
            "Epoch 56/1000\n",
            "3/3 - 0s - loss: 2.8201 - accuracy: 0.2188\n",
            "Epoch 57/1000\n",
            "3/3 - 0s - loss: 2.8207 - accuracy: 0.2188\n",
            "Epoch 58/1000\n",
            "3/3 - 0s - loss: 2.8182 - accuracy: 0.2188\n",
            "Epoch 59/1000\n",
            "3/3 - 0s - loss: 2.8184 - accuracy: 0.2188\n",
            "Epoch 60/1000\n",
            "3/3 - 0s - loss: 2.8212 - accuracy: 0.2188\n",
            "Epoch 61/1000\n",
            "3/3 - 0s - loss: 2.8192 - accuracy: 0.2188\n",
            "Epoch 62/1000\n",
            "3/3 - 0s - loss: 2.8177 - accuracy: 0.2188\n",
            "Epoch 63/1000\n",
            "3/3 - 0s - loss: 2.8173 - accuracy: 0.2188\n",
            "Epoch 64/1000\n",
            "3/3 - 0s - loss: 2.8176 - accuracy: 0.2188\n",
            "Epoch 65/1000\n",
            "3/3 - 0s - loss: 2.8194 - accuracy: 0.2188\n",
            "Epoch 66/1000\n",
            "3/3 - 0s - loss: 2.8199 - accuracy: 0.2188\n",
            "Epoch 67/1000\n",
            "3/3 - 0s - loss: 2.8186 - accuracy: 0.2188\n",
            "Epoch 68/1000\n",
            "3/3 - 0s - loss: 2.8187 - accuracy: 0.2188\n",
            "Epoch 69/1000\n",
            "3/3 - 0s - loss: 2.8190 - accuracy: 0.2188\n",
            "Epoch 70/1000\n",
            "3/3 - 0s - loss: 2.8172 - accuracy: 0.2188\n",
            "Epoch 71/1000\n",
            "3/3 - 0s - loss: 2.8184 - accuracy: 0.2188\n",
            "Epoch 72/1000\n",
            "3/3 - 0s - loss: 2.8177 - accuracy: 0.2188\n",
            "Epoch 73/1000\n",
            "3/3 - 0s - loss: 2.8188 - accuracy: 0.2188\n",
            "Epoch 74/1000\n",
            "3/3 - 0s - loss: 2.8184 - accuracy: 0.2188\n",
            "Epoch 75/1000\n",
            "3/3 - 0s - loss: 2.8177 - accuracy: 0.2188\n",
            "Epoch 76/1000\n",
            "3/3 - 0s - loss: 2.8204 - accuracy: 0.2188\n",
            "Epoch 77/1000\n",
            "3/3 - 0s - loss: 2.8179 - accuracy: 0.2188\n",
            "Epoch 78/1000\n",
            "3/3 - 0s - loss: 2.8166 - accuracy: 0.2188\n",
            "Epoch 79/1000\n",
            "3/3 - 0s - loss: 2.8190 - accuracy: 0.2188\n",
            "Epoch 80/1000\n",
            "3/3 - 0s - loss: 2.8178 - accuracy: 0.2188\n",
            "Epoch 81/1000\n",
            "3/3 - 0s - loss: 2.8171 - accuracy: 0.2188\n",
            "Epoch 82/1000\n",
            "3/3 - 0s - loss: 2.8220 - accuracy: 0.2188\n",
            "Epoch 83/1000\n",
            "3/3 - 0s - loss: 2.8195 - accuracy: 0.2188\n",
            "Epoch 84/1000\n",
            "3/3 - 0s - loss: 2.8173 - accuracy: 0.2188\n",
            "Epoch 85/1000\n",
            "3/3 - 0s - loss: 2.8173 - accuracy: 0.2188\n",
            "Epoch 86/1000\n",
            "3/3 - 0s - loss: 2.8184 - accuracy: 0.2188\n",
            "Epoch 87/1000\n",
            "3/3 - 0s - loss: 2.8199 - accuracy: 0.2188\n",
            "Epoch 88/1000\n",
            "3/3 - 0s - loss: 2.8175 - accuracy: 0.2188\n",
            "Epoch 89/1000\n",
            "3/3 - 0s - loss: 2.8161 - accuracy: 0.2188\n",
            "Epoch 90/1000\n",
            "3/3 - 0s - loss: 2.8187 - accuracy: 0.2188\n",
            "Epoch 91/1000\n",
            "3/3 - 0s - loss: 2.8172 - accuracy: 0.2188\n",
            "Epoch 92/1000\n",
            "3/3 - 0s - loss: 2.8196 - accuracy: 0.2188\n",
            "Epoch 93/1000\n",
            "3/3 - 0s - loss: 2.8174 - accuracy: 0.2188\n",
            "Epoch 94/1000\n",
            "3/3 - 0s - loss: 2.8180 - accuracy: 0.2188\n",
            "Epoch 95/1000\n",
            "3/3 - 0s - loss: 2.8197 - accuracy: 0.2188\n",
            "Epoch 96/1000\n",
            "3/3 - 0s - loss: 2.8170 - accuracy: 0.2188\n",
            "Epoch 97/1000\n",
            "3/3 - 0s - loss: 2.8164 - accuracy: 0.2188\n",
            "Epoch 98/1000\n",
            "3/3 - 0s - loss: 2.8186 - accuracy: 0.2188\n",
            "Epoch 99/1000\n",
            "3/3 - 0s - loss: 2.8187 - accuracy: 0.2188\n",
            "Epoch 100/1000\n",
            "3/3 - 0s - loss: 2.8188 - accuracy: 0.2188\n",
            "Epoch 101/1000\n",
            "3/3 - 0s - loss: 2.8170 - accuracy: 0.2188\n",
            "Epoch 102/1000\n",
            "3/3 - 0s - loss: 2.8178 - accuracy: 0.2188\n",
            "Epoch 103/1000\n",
            "3/3 - 0s - loss: 2.8171 - accuracy: 0.2188\n",
            "Epoch 104/1000\n",
            "3/3 - 0s - loss: 2.8183 - accuracy: 0.2188\n",
            "Epoch 105/1000\n",
            "3/3 - 0s - loss: 2.8172 - accuracy: 0.2188\n",
            "Epoch 106/1000\n",
            "3/3 - 0s - loss: 2.8170 - accuracy: 0.2188\n",
            "Epoch 107/1000\n",
            "3/3 - 0s - loss: 2.8175 - accuracy: 0.2188\n",
            "Epoch 108/1000\n",
            "3/3 - 0s - loss: 2.8184 - accuracy: 0.2188\n",
            "Epoch 109/1000\n",
            "3/3 - 0s - loss: 2.8183 - accuracy: 0.2188\n",
            "Epoch 110/1000\n",
            "3/3 - 0s - loss: 2.8168 - accuracy: 0.2188\n",
            "Epoch 111/1000\n",
            "3/3 - 0s - loss: 2.8170 - accuracy: 0.2188\n",
            "Epoch 112/1000\n",
            "3/3 - 0s - loss: 2.8176 - accuracy: 0.2188\n",
            "Epoch 113/1000\n",
            "3/3 - 0s - loss: 2.8174 - accuracy: 0.2188\n",
            "Epoch 114/1000\n",
            "3/3 - 0s - loss: 2.8165 - accuracy: 0.2188\n",
            "Epoch 115/1000\n",
            "3/3 - 0s - loss: 2.8179 - accuracy: 0.2188\n",
            "Epoch 116/1000\n",
            "3/3 - 0s - loss: 2.8187 - accuracy: 0.2188\n",
            "Epoch 117/1000\n",
            "3/3 - 0s - loss: 2.8183 - accuracy: 0.2188\n",
            "Epoch 118/1000\n",
            "3/3 - 0s - loss: 2.8161 - accuracy: 0.2188\n",
            "Epoch 119/1000\n",
            "3/3 - 0s - loss: 2.8163 - accuracy: 0.2188\n",
            "Epoch 120/1000\n",
            "3/3 - 0s - loss: 2.8181 - accuracy: 0.2188\n",
            "Epoch 121/1000\n",
            "3/3 - 0s - loss: 2.8192 - accuracy: 0.2188\n",
            "Epoch 122/1000\n",
            "3/3 - 0s - loss: 2.8165 - accuracy: 0.2188\n",
            "Epoch 123/1000\n",
            "3/3 - 0s - loss: 2.8174 - accuracy: 0.2188\n",
            "Epoch 124/1000\n",
            "3/3 - 0s - loss: 2.8158 - accuracy: 0.2188\n",
            "Epoch 125/1000\n",
            "3/3 - 0s - loss: 2.8190 - accuracy: 0.2188\n",
            "Epoch 126/1000\n",
            "3/3 - 0s - loss: 2.8177 - accuracy: 0.2188\n",
            "Epoch 127/1000\n",
            "3/3 - 0s - loss: 2.8173 - accuracy: 0.2188\n",
            "Epoch 128/1000\n",
            "3/3 - 0s - loss: 2.8181 - accuracy: 0.2188\n",
            "Epoch 129/1000\n",
            "3/3 - 0s - loss: 2.8183 - accuracy: 0.2188\n",
            "Epoch 130/1000\n",
            "3/3 - 0s - loss: 2.8170 - accuracy: 0.2188\n",
            "Epoch 131/1000\n",
            "3/3 - 0s - loss: 2.8158 - accuracy: 0.2188\n",
            "Epoch 132/1000\n",
            "3/3 - 0s - loss: 2.8172 - accuracy: 0.2188\n",
            "Epoch 133/1000\n",
            "3/3 - 0s - loss: 2.8179 - accuracy: 0.2188\n",
            "Epoch 134/1000\n",
            "3/3 - 0s - loss: 2.8183 - accuracy: 0.2188\n",
            "Epoch 135/1000\n",
            "3/3 - 0s - loss: 2.8174 - accuracy: 0.2188\n",
            "Epoch 136/1000\n",
            "3/3 - 0s - loss: 2.8166 - accuracy: 0.2188\n",
            "Epoch 137/1000\n",
            "3/3 - 0s - loss: 2.8187 - accuracy: 0.2188\n",
            "Epoch 138/1000\n",
            "3/3 - 0s - loss: 2.8164 - accuracy: 0.2188\n",
            "Epoch 139/1000\n",
            "3/3 - 0s - loss: 2.8192 - accuracy: 0.2188\n",
            "Epoch 140/1000\n",
            "3/3 - 0s - loss: 2.8175 - accuracy: 0.2188\n",
            "Epoch 141/1000\n",
            "3/3 - 0s - loss: 2.8168 - accuracy: 0.2188\n",
            "Epoch 142/1000\n",
            "3/3 - 0s - loss: 2.8209 - accuracy: 0.2188\n",
            "Epoch 143/1000\n",
            "3/3 - 0s - loss: 2.8193 - accuracy: 0.2188\n",
            "Epoch 144/1000\n",
            "3/3 - 0s - loss: 2.8179 - accuracy: 0.2188\n",
            "Epoch 145/1000\n",
            "3/3 - 0s - loss: 2.8170 - accuracy: 0.2188\n",
            "Epoch 146/1000\n",
            "3/3 - 0s - loss: 2.8174 - accuracy: 0.2188\n",
            "Epoch 147/1000\n",
            "3/3 - 0s - loss: 2.8168 - accuracy: 0.2188\n",
            "Epoch 148/1000\n",
            "3/3 - 0s - loss: 2.8154 - accuracy: 0.2188\n",
            "Epoch 149/1000\n",
            "3/3 - 0s - loss: 2.8175 - accuracy: 0.2188\n",
            "Epoch 150/1000\n",
            "3/3 - 0s - loss: 2.8165 - accuracy: 0.2188\n",
            "Epoch 151/1000\n",
            "3/3 - 0s - loss: 2.8165 - accuracy: 0.2188\n",
            "Epoch 152/1000\n",
            "3/3 - 0s - loss: 2.8209 - accuracy: 0.2188\n",
            "Epoch 153/1000\n",
            "3/3 - 0s - loss: 2.8176 - accuracy: 0.2188\n",
            "Epoch 154/1000\n",
            "3/3 - 0s - loss: 2.8194 - accuracy: 0.2188\n",
            "Epoch 155/1000\n",
            "3/3 - 0s - loss: 2.8184 - accuracy: 0.2188\n",
            "Epoch 156/1000\n",
            "3/3 - 0s - loss: 2.8175 - accuracy: 0.2188\n",
            "Epoch 157/1000\n",
            "3/3 - 0s - loss: 2.8152 - accuracy: 0.2188\n",
            "Epoch 158/1000\n",
            "3/3 - 0s - loss: 2.8169 - accuracy: 0.2188\n",
            "Epoch 159/1000\n",
            "3/3 - 0s - loss: 2.8163 - accuracy: 0.2188\n",
            "Epoch 160/1000\n",
            "3/3 - 0s - loss: 2.8197 - accuracy: 0.2188\n",
            "Epoch 161/1000\n",
            "3/3 - 0s - loss: 2.8153 - accuracy: 0.2188\n",
            "Epoch 162/1000\n",
            "3/3 - 0s - loss: 2.8180 - accuracy: 0.2188\n",
            "Epoch 163/1000\n",
            "3/3 - 0s - loss: 2.8166 - accuracy: 0.2188\n",
            "Epoch 164/1000\n",
            "3/3 - 0s - loss: 2.8187 - accuracy: 0.2188\n",
            "Epoch 165/1000\n",
            "3/3 - 0s - loss: 2.8195 - accuracy: 0.2188\n",
            "Epoch 166/1000\n",
            "3/3 - 0s - loss: 2.8181 - accuracy: 0.2188\n",
            "Epoch 167/1000\n",
            "3/3 - 0s - loss: 2.8172 - accuracy: 0.2188\n",
            "Epoch 168/1000\n",
            "3/3 - 0s - loss: 2.8193 - accuracy: 0.2188\n",
            "Epoch 169/1000\n",
            "3/3 - 0s - loss: 2.8164 - accuracy: 0.2188\n",
            "Epoch 170/1000\n",
            "3/3 - 0s - loss: 2.8165 - accuracy: 0.2188\n",
            "Epoch 171/1000\n",
            "3/3 - 0s - loss: 2.8196 - accuracy: 0.2188\n",
            "Epoch 172/1000\n",
            "3/3 - 0s - loss: 2.8187 - accuracy: 0.2188\n",
            "Epoch 173/1000\n",
            "3/3 - 0s - loss: 2.8170 - accuracy: 0.2188\n",
            "Epoch 174/1000\n",
            "3/3 - 0s - loss: 2.8178 - accuracy: 0.2188\n",
            "Epoch 175/1000\n",
            "3/3 - 0s - loss: 2.8189 - accuracy: 0.2188\n",
            "Epoch 176/1000\n",
            "3/3 - 0s - loss: 2.8175 - accuracy: 0.2188\n",
            "Epoch 177/1000\n",
            "3/3 - 0s - loss: 2.8190 - accuracy: 0.2188\n",
            "Epoch 178/1000\n",
            "3/3 - 0s - loss: 2.8183 - accuracy: 0.2188\n",
            "Epoch 179/1000\n",
            "3/3 - 0s - loss: 2.8173 - accuracy: 0.2188\n",
            "Epoch 180/1000\n",
            "3/3 - 0s - loss: 2.8168 - accuracy: 0.2188\n",
            "Epoch 181/1000\n",
            "3/3 - 0s - loss: 2.8180 - accuracy: 0.2188\n",
            "Epoch 182/1000\n",
            "3/3 - 0s - loss: 2.8183 - accuracy: 0.2188\n",
            "Epoch 183/1000\n",
            "3/3 - 0s - loss: 2.8181 - accuracy: 0.2188\n",
            "Epoch 184/1000\n",
            "3/3 - 0s - loss: 2.8188 - accuracy: 0.2188\n",
            "Epoch 185/1000\n",
            "3/3 - 0s - loss: 2.8160 - accuracy: 0.2188\n",
            "Epoch 186/1000\n",
            "3/3 - 0s - loss: 2.8155 - accuracy: 0.2188\n",
            "Epoch 187/1000\n",
            "3/3 - 0s - loss: 2.8162 - accuracy: 0.2188\n",
            "Epoch 188/1000\n",
            "3/3 - 0s - loss: 2.8165 - accuracy: 0.2188\n",
            "Epoch 189/1000\n",
            "3/3 - 0s - loss: 2.8149 - accuracy: 0.2188\n",
            "Epoch 190/1000\n",
            "3/3 - 0s - loss: 2.8166 - accuracy: 0.2188\n",
            "Epoch 191/1000\n",
            "3/3 - 0s - loss: 2.8166 - accuracy: 0.2188\n",
            "Epoch 192/1000\n",
            "3/3 - 0s - loss: 2.8175 - accuracy: 0.2188\n",
            "Epoch 193/1000\n",
            "3/3 - 0s - loss: 2.8207 - accuracy: 0.2188\n",
            "Epoch 194/1000\n",
            "3/3 - 0s - loss: 2.8148 - accuracy: 0.2188\n",
            "Epoch 195/1000\n",
            "3/3 - 0s - loss: 2.8183 - accuracy: 0.2188\n",
            "Epoch 196/1000\n",
            "3/3 - 0s - loss: 2.8175 - accuracy: 0.2188\n",
            "Epoch 197/1000\n",
            "3/3 - 0s - loss: 2.8166 - accuracy: 0.2188\n",
            "Epoch 198/1000\n",
            "3/3 - 0s - loss: 2.8200 - accuracy: 0.2188\n",
            "Epoch 199/1000\n",
            "3/3 - 0s - loss: 2.8152 - accuracy: 0.2188\n",
            "Epoch 200/1000\n",
            "3/3 - 0s - loss: 2.8181 - accuracy: 0.2188\n",
            "Epoch 201/1000\n",
            "3/3 - 0s - loss: 2.8167 - accuracy: 0.2188\n",
            "Epoch 202/1000\n",
            "3/3 - 0s - loss: 2.8163 - accuracy: 0.2188\n",
            "Epoch 203/1000\n",
            "3/3 - 0s - loss: 2.8153 - accuracy: 0.2188\n",
            "Epoch 204/1000\n",
            "3/3 - 0s - loss: 2.8168 - accuracy: 0.2188\n",
            "Epoch 205/1000\n",
            "3/3 - 0s - loss: 2.8180 - accuracy: 0.2188\n",
            "Epoch 206/1000\n",
            "3/3 - 0s - loss: 2.8160 - accuracy: 0.2188\n",
            "Epoch 207/1000\n",
            "3/3 - 0s - loss: 2.8174 - accuracy: 0.2188\n",
            "Epoch 208/1000\n",
            "3/3 - 0s - loss: 2.8172 - accuracy: 0.2188\n",
            "Epoch 209/1000\n",
            "3/3 - 0s - loss: 2.8159 - accuracy: 0.2188\n",
            "Epoch 210/1000\n",
            "3/3 - 0s - loss: 2.8187 - accuracy: 0.2188\n",
            "Epoch 211/1000\n",
            "3/3 - 0s - loss: 2.8174 - accuracy: 0.2188\n",
            "Epoch 212/1000\n",
            "3/3 - 0s - loss: 2.8166 - accuracy: 0.2188\n",
            "Epoch 213/1000\n",
            "3/3 - 0s - loss: 2.8150 - accuracy: 0.2188\n",
            "Epoch 214/1000\n",
            "3/3 - 0s - loss: 2.8164 - accuracy: 0.2188\n",
            "Epoch 215/1000\n",
            "3/3 - 0s - loss: 2.8144 - accuracy: 0.2188\n",
            "Epoch 216/1000\n",
            "3/3 - 0s - loss: 2.8176 - accuracy: 0.2188\n",
            "Epoch 217/1000\n",
            "3/3 - 0s - loss: 2.8167 - accuracy: 0.2188\n",
            "Epoch 218/1000\n",
            "3/3 - 0s - loss: 2.8189 - accuracy: 0.2188\n",
            "Epoch 219/1000\n",
            "3/3 - 0s - loss: 2.8165 - accuracy: 0.2188\n",
            "Epoch 220/1000\n",
            "3/3 - 0s - loss: 2.8183 - accuracy: 0.2188\n",
            "Epoch 221/1000\n",
            "3/3 - 0s - loss: 2.8149 - accuracy: 0.2188\n",
            "Epoch 222/1000\n",
            "3/3 - 0s - loss: 2.8189 - accuracy: 0.2188\n",
            "Epoch 223/1000\n",
            "3/3 - 0s - loss: 2.8157 - accuracy: 0.2188\n",
            "Epoch 224/1000\n",
            "3/3 - 0s - loss: 2.8162 - accuracy: 0.2188\n",
            "Epoch 225/1000\n",
            "3/3 - 0s - loss: 2.8189 - accuracy: 0.2188\n",
            "Epoch 226/1000\n",
            "3/3 - 0s - loss: 2.8176 - accuracy: 0.2188\n",
            "Epoch 227/1000\n",
            "3/3 - 0s - loss: 2.8171 - accuracy: 0.2188\n",
            "Epoch 228/1000\n",
            "3/3 - 0s - loss: 2.8171 - accuracy: 0.2188\n",
            "Epoch 229/1000\n",
            "3/3 - 0s - loss: 2.8179 - accuracy: 0.2188\n",
            "Epoch 230/1000\n",
            "3/3 - 0s - loss: 2.8161 - accuracy: 0.2188\n",
            "Epoch 231/1000\n",
            "3/3 - 0s - loss: 2.8155 - accuracy: 0.2188\n",
            "Epoch 232/1000\n",
            "3/3 - 0s - loss: 2.8164 - accuracy: 0.2188\n",
            "Epoch 233/1000\n",
            "3/3 - 0s - loss: 2.8154 - accuracy: 0.2188\n",
            "Epoch 234/1000\n",
            "3/3 - 0s - loss: 2.8157 - accuracy: 0.2188\n",
            "Epoch 235/1000\n",
            "3/3 - 0s - loss: 2.8148 - accuracy: 0.2188\n",
            "Epoch 236/1000\n",
            "3/3 - 0s - loss: 2.8161 - accuracy: 0.2188\n",
            "Epoch 237/1000\n",
            "3/3 - 0s - loss: 2.8154 - accuracy: 0.2188\n",
            "Epoch 238/1000\n",
            "3/3 - 0s - loss: 2.8157 - accuracy: 0.2188\n",
            "Epoch 239/1000\n",
            "3/3 - 0s - loss: 2.8178 - accuracy: 0.2188\n",
            "Epoch 240/1000\n",
            "3/3 - 0s - loss: 2.8151 - accuracy: 0.2188\n",
            "Epoch 241/1000\n",
            "3/3 - 0s - loss: 2.8215 - accuracy: 0.2188\n",
            "Epoch 242/1000\n",
            "3/3 - 0s - loss: 2.8166 - accuracy: 0.2188\n",
            "Epoch 243/1000\n",
            "3/3 - 0s - loss: 2.8162 - accuracy: 0.2188\n",
            "Epoch 244/1000\n",
            "3/3 - 0s - loss: 2.8148 - accuracy: 0.2188\n",
            "Epoch 245/1000\n",
            "3/3 - 0s - loss: 2.8152 - accuracy: 0.2188\n",
            "Epoch 246/1000\n",
            "3/3 - 0s - loss: 2.8154 - accuracy: 0.2188\n",
            "Epoch 247/1000\n",
            "3/3 - 0s - loss: 2.8164 - accuracy: 0.2188\n",
            "Epoch 248/1000\n",
            "3/3 - 0s - loss: 2.8151 - accuracy: 0.2188\n",
            "Epoch 249/1000\n",
            "3/3 - 0s - loss: 2.8153 - accuracy: 0.2188\n",
            "Epoch 250/1000\n",
            "3/3 - 0s - loss: 2.8156 - accuracy: 0.2188\n",
            "Epoch 251/1000\n",
            "3/3 - 0s - loss: 2.8158 - accuracy: 0.2188\n",
            "Epoch 252/1000\n",
            "3/3 - 0s - loss: 2.8166 - accuracy: 0.2188\n",
            "Epoch 253/1000\n",
            "3/3 - 0s - loss: 2.8175 - accuracy: 0.2188\n",
            "Epoch 254/1000\n",
            "3/3 - 0s - loss: 2.8173 - accuracy: 0.2188\n",
            "Epoch 255/1000\n",
            "3/3 - 0s - loss: 2.8164 - accuracy: 0.2188\n",
            "Epoch 256/1000\n",
            "3/3 - 0s - loss: 2.8159 - accuracy: 0.2188\n",
            "Epoch 257/1000\n",
            "3/3 - 0s - loss: 2.8178 - accuracy: 0.2188\n",
            "Epoch 258/1000\n",
            "3/3 - 0s - loss: 2.8197 - accuracy: 0.2188\n",
            "Epoch 259/1000\n",
            "3/3 - 0s - loss: 2.8162 - accuracy: 0.2188\n",
            "Epoch 260/1000\n",
            "3/3 - 0s - loss: 2.8151 - accuracy: 0.2188\n",
            "Epoch 261/1000\n",
            "3/3 - 0s - loss: 2.8141 - accuracy: 0.2188\n",
            "Epoch 262/1000\n",
            "3/3 - 0s - loss: 2.8171 - accuracy: 0.2188\n",
            "Epoch 263/1000\n",
            "3/3 - 0s - loss: 2.8164 - accuracy: 0.2188\n",
            "Epoch 264/1000\n",
            "3/3 - 0s - loss: 2.8146 - accuracy: 0.2188\n",
            "Epoch 265/1000\n",
            "3/3 - 0s - loss: 2.8141 - accuracy: 0.2188\n",
            "Epoch 266/1000\n",
            "3/3 - 0s - loss: 2.8150 - accuracy: 0.2188\n",
            "Epoch 267/1000\n",
            "3/3 - 0s - loss: 2.8144 - accuracy: 0.2188\n",
            "Epoch 268/1000\n",
            "3/3 - 0s - loss: 2.8179 - accuracy: 0.2188\n",
            "Epoch 269/1000\n",
            "3/3 - 0s - loss: 2.8158 - accuracy: 0.2188\n",
            "Epoch 270/1000\n",
            "3/3 - 0s - loss: 2.8204 - accuracy: 0.2188\n",
            "Epoch 271/1000\n",
            "3/3 - 0s - loss: 2.8169 - accuracy: 0.2188\n",
            "Epoch 272/1000\n",
            "3/3 - 0s - loss: 2.8147 - accuracy: 0.2188\n",
            "Epoch 273/1000\n",
            "3/3 - 0s - loss: 2.8165 - accuracy: 0.2188\n",
            "Epoch 274/1000\n",
            "3/3 - 0s - loss: 2.8173 - accuracy: 0.2188\n",
            "Epoch 275/1000\n",
            "3/3 - 0s - loss: 2.8169 - accuracy: 0.2188\n",
            "Epoch 276/1000\n",
            "3/3 - 0s - loss: 2.8154 - accuracy: 0.2188\n",
            "Epoch 277/1000\n",
            "3/3 - 0s - loss: 2.8159 - accuracy: 0.2188\n",
            "Epoch 278/1000\n",
            "3/3 - 0s - loss: 2.8130 - accuracy: 0.2188\n",
            "Epoch 279/1000\n",
            "3/3 - 0s - loss: 2.8157 - accuracy: 0.2188\n",
            "Epoch 280/1000\n",
            "3/3 - 0s - loss: 2.8162 - accuracy: 0.2188\n",
            "Epoch 281/1000\n",
            "3/3 - 0s - loss: 2.8181 - accuracy: 0.2188\n",
            "Epoch 282/1000\n",
            "3/3 - 0s - loss: 2.8195 - accuracy: 0.2188\n",
            "Epoch 283/1000\n",
            "3/3 - 0s - loss: 2.8144 - accuracy: 0.2188\n",
            "Epoch 284/1000\n",
            "3/3 - 0s - loss: 2.8177 - accuracy: 0.2188\n",
            "Epoch 285/1000\n",
            "3/3 - 0s - loss: 2.8129 - accuracy: 0.2188\n",
            "Epoch 286/1000\n",
            "3/3 - 0s - loss: 2.8157 - accuracy: 0.2188\n",
            "Epoch 287/1000\n",
            "3/3 - 0s - loss: 2.8151 - accuracy: 0.2188\n",
            "Epoch 288/1000\n",
            "3/3 - 0s - loss: 2.8175 - accuracy: 0.2188\n",
            "Epoch 289/1000\n",
            "3/3 - 0s - loss: 2.8147 - accuracy: 0.2188\n",
            "Epoch 290/1000\n",
            "3/3 - 0s - loss: 2.8162 - accuracy: 0.2188\n",
            "Epoch 291/1000\n",
            "3/3 - 0s - loss: 2.8142 - accuracy: 0.2188\n",
            "Epoch 292/1000\n",
            "3/3 - 0s - loss: 2.8195 - accuracy: 0.2188\n",
            "Epoch 293/1000\n",
            "3/3 - 0s - loss: 2.8174 - accuracy: 0.2188\n",
            "Epoch 294/1000\n",
            "3/3 - 0s - loss: 2.8152 - accuracy: 0.2188\n",
            "Epoch 295/1000\n",
            "3/3 - 0s - loss: 2.8198 - accuracy: 0.2188\n",
            "Epoch 296/1000\n",
            "3/3 - 0s - loss: 2.8159 - accuracy: 0.2188\n",
            "Epoch 297/1000\n",
            "3/3 - 0s - loss: 2.8160 - accuracy: 0.2188\n",
            "Epoch 298/1000\n",
            "3/3 - 0s - loss: 2.8147 - accuracy: 0.2188\n",
            "Epoch 299/1000\n",
            "3/3 - 0s - loss: 2.8139 - accuracy: 0.2188\n",
            "Epoch 300/1000\n",
            "3/3 - 0s - loss: 2.8143 - accuracy: 0.2188\n",
            "Epoch 301/1000\n",
            "3/3 - 0s - loss: 2.8128 - accuracy: 0.2188\n",
            "Epoch 302/1000\n",
            "3/3 - 0s - loss: 2.8139 - accuracy: 0.2188\n",
            "Epoch 303/1000\n",
            "3/3 - 0s - loss: 2.8145 - accuracy: 0.2188\n",
            "Epoch 304/1000\n",
            "3/3 - 0s - loss: 2.8136 - accuracy: 0.2188\n",
            "Epoch 305/1000\n",
            "3/3 - 0s - loss: 2.8131 - accuracy: 0.2188\n",
            "Epoch 306/1000\n",
            "3/3 - 0s - loss: 2.8158 - accuracy: 0.2188\n",
            "Epoch 307/1000\n",
            "3/3 - 0s - loss: 2.8182 - accuracy: 0.2188\n",
            "Epoch 308/1000\n",
            "3/3 - 0s - loss: 2.8150 - accuracy: 0.2188\n",
            "Epoch 309/1000\n",
            "3/3 - 0s - loss: 2.8152 - accuracy: 0.2188\n",
            "Epoch 310/1000\n",
            "3/3 - 0s - loss: 2.8166 - accuracy: 0.2188\n",
            "Epoch 311/1000\n",
            "3/3 - 0s - loss: 2.8155 - accuracy: 0.2188\n",
            "Epoch 312/1000\n",
            "3/3 - 0s - loss: 2.8140 - accuracy: 0.2188\n",
            "Epoch 313/1000\n",
            "3/3 - 0s - loss: 2.8138 - accuracy: 0.2188\n",
            "Epoch 314/1000\n",
            "3/3 - 0s - loss: 2.8139 - accuracy: 0.2188\n",
            "Epoch 315/1000\n",
            "3/3 - 0s - loss: 2.8133 - accuracy: 0.2188\n",
            "Epoch 316/1000\n",
            "3/3 - 0s - loss: 2.8149 - accuracy: 0.2188\n",
            "Epoch 317/1000\n",
            "3/3 - 0s - loss: 2.8161 - accuracy: 0.2188\n",
            "Epoch 318/1000\n",
            "3/3 - 0s - loss: 2.8119 - accuracy: 0.2188\n",
            "Epoch 319/1000\n",
            "3/3 - 0s - loss: 2.8128 - accuracy: 0.2188\n",
            "Epoch 320/1000\n",
            "3/3 - 0s - loss: 2.8132 - accuracy: 0.2188\n",
            "Epoch 321/1000\n",
            "3/3 - 0s - loss: 2.8125 - accuracy: 0.2188\n",
            "Epoch 322/1000\n",
            "3/3 - 0s - loss: 2.8114 - accuracy: 0.2188\n",
            "Epoch 323/1000\n",
            "3/3 - 0s - loss: 2.8137 - accuracy: 0.2188\n",
            "Epoch 324/1000\n",
            "3/3 - 0s - loss: 2.8176 - accuracy: 0.2188\n",
            "Epoch 325/1000\n",
            "3/3 - 0s - loss: 2.8133 - accuracy: 0.2188\n",
            "Epoch 326/1000\n",
            "3/3 - 0s - loss: 2.8148 - accuracy: 0.2188\n",
            "Epoch 327/1000\n",
            "3/3 - 0s - loss: 2.8118 - accuracy: 0.2188\n",
            "Epoch 328/1000\n",
            "3/3 - 0s - loss: 2.8115 - accuracy: 0.2188\n",
            "Epoch 329/1000\n",
            "3/3 - 0s - loss: 2.8167 - accuracy: 0.2188\n",
            "Epoch 330/1000\n",
            "3/3 - 0s - loss: 2.8204 - accuracy: 0.2188\n",
            "Epoch 331/1000\n",
            "3/3 - 0s - loss: 2.8179 - accuracy: 0.2188\n",
            "Epoch 332/1000\n",
            "3/3 - 0s - loss: 2.8129 - accuracy: 0.2188\n",
            "Epoch 333/1000\n",
            "3/3 - 0s - loss: 2.8173 - accuracy: 0.2188\n",
            "Epoch 334/1000\n",
            "3/3 - 0s - loss: 2.8144 - accuracy: 0.2188\n",
            "Epoch 335/1000\n",
            "3/3 - 0s - loss: 2.8133 - accuracy: 0.2188\n",
            "Epoch 336/1000\n",
            "3/3 - 0s - loss: 2.8119 - accuracy: 0.2188\n",
            "Epoch 337/1000\n",
            "3/3 - 0s - loss: 2.8153 - accuracy: 0.2188\n",
            "Epoch 338/1000\n",
            "3/3 - 0s - loss: 2.8134 - accuracy: 0.2188\n",
            "Epoch 339/1000\n",
            "3/3 - 0s - loss: 2.8125 - accuracy: 0.2188\n",
            "Epoch 340/1000\n",
            "3/3 - 0s - loss: 2.8116 - accuracy: 0.2188\n",
            "Epoch 341/1000\n",
            "3/3 - 0s - loss: 2.8114 - accuracy: 0.2188\n",
            "Epoch 342/1000\n",
            "3/3 - 0s - loss: 2.8119 - accuracy: 0.2188\n",
            "Epoch 343/1000\n",
            "3/3 - 0s - loss: 2.8105 - accuracy: 0.2188\n",
            "Epoch 344/1000\n",
            "3/3 - 0s - loss: 2.8125 - accuracy: 0.2188\n",
            "Epoch 345/1000\n",
            "3/3 - 0s - loss: 2.8108 - accuracy: 0.2188\n",
            "Epoch 346/1000\n",
            "3/3 - 0s - loss: 2.8120 - accuracy: 0.2188\n",
            "Epoch 347/1000\n",
            "3/3 - 0s - loss: 2.8115 - accuracy: 0.2188\n",
            "Epoch 348/1000\n",
            "3/3 - 0s - loss: 2.8098 - accuracy: 0.2188\n",
            "Epoch 349/1000\n",
            "3/3 - 0s - loss: 2.8100 - accuracy: 0.2188\n",
            "Epoch 350/1000\n",
            "3/3 - 0s - loss: 2.8130 - accuracy: 0.2188\n",
            "Epoch 351/1000\n",
            "3/3 - 0s - loss: 2.8130 - accuracy: 0.2188\n",
            "Epoch 352/1000\n",
            "3/3 - 0s - loss: 2.8345 - accuracy: 0.2188\n",
            "Epoch 353/1000\n",
            "3/3 - 0s - loss: 2.8101 - accuracy: 0.2188\n",
            "Epoch 354/1000\n",
            "3/3 - 0s - loss: 2.8118 - accuracy: 0.2188\n",
            "Epoch 355/1000\n",
            "3/3 - 0s - loss: 2.8075 - accuracy: 0.2188\n",
            "Epoch 356/1000\n",
            "3/3 - 0s - loss: 2.8135 - accuracy: 0.2188\n",
            "Epoch 357/1000\n",
            "3/3 - 0s - loss: 2.8094 - accuracy: 0.2188\n",
            "Epoch 358/1000\n",
            "3/3 - 0s - loss: 2.8089 - accuracy: 0.2188\n",
            "Epoch 359/1000\n",
            "3/3 - 0s - loss: 2.8272 - accuracy: 0.2188\n",
            "Epoch 360/1000\n",
            "3/3 - 0s - loss: 2.8288 - accuracy: 0.2188\n",
            "Epoch 361/1000\n",
            "3/3 - 0s - loss: 2.8246 - accuracy: 0.2188\n",
            "Epoch 362/1000\n",
            "3/3 - 0s - loss: 2.8242 - accuracy: 0.2188\n",
            "Epoch 363/1000\n",
            "3/3 - 0s - loss: 2.8214 - accuracy: 0.2188\n",
            "Epoch 364/1000\n",
            "3/3 - 0s - loss: 2.8185 - accuracy: 0.2188\n",
            "Epoch 365/1000\n",
            "3/3 - 0s - loss: 2.8218 - accuracy: 0.2188\n",
            "Epoch 366/1000\n",
            "3/3 - 0s - loss: 2.8217 - accuracy: 0.2188\n",
            "Epoch 367/1000\n",
            "3/3 - 0s - loss: 2.8146 - accuracy: 0.2188\n",
            "Epoch 368/1000\n",
            "3/3 - 0s - loss: 2.8140 - accuracy: 0.2188\n",
            "Epoch 369/1000\n",
            "3/3 - 0s - loss: 2.8101 - accuracy: 0.2188\n",
            "Epoch 370/1000\n",
            "3/3 - 0s - loss: 2.8098 - accuracy: 0.2188\n",
            "Epoch 371/1000\n",
            "3/3 - 0s - loss: 2.8080 - accuracy: 0.2188\n",
            "Epoch 372/1000\n",
            "3/3 - 0s - loss: 2.8034 - accuracy: 0.2188\n",
            "Epoch 373/1000\n",
            "3/3 - 0s - loss: 2.8022 - accuracy: 0.2188\n",
            "Epoch 374/1000\n",
            "3/3 - 0s - loss: 2.8039 - accuracy: 0.2188\n",
            "Epoch 375/1000\n",
            "3/3 - 0s - loss: 2.8011 - accuracy: 0.2292\n",
            "Epoch 376/1000\n",
            "3/3 - 0s - loss: 2.7953 - accuracy: 0.2292\n",
            "Epoch 377/1000\n",
            "3/3 - 0s - loss: 2.7974 - accuracy: 0.2292\n",
            "Epoch 378/1000\n",
            "3/3 - 0s - loss: 2.7959 - accuracy: 0.2292\n",
            "Epoch 379/1000\n",
            "3/3 - 0s - loss: 2.7923 - accuracy: 0.2292\n",
            "Epoch 380/1000\n",
            "3/3 - 0s - loss: 2.7930 - accuracy: 0.2188\n",
            "Epoch 381/1000\n",
            "3/3 - 0s - loss: 2.7913 - accuracy: 0.2292\n",
            "Epoch 382/1000\n",
            "3/3 - 0s - loss: 2.7926 - accuracy: 0.2292\n",
            "Epoch 383/1000\n",
            "3/3 - 0s - loss: 2.7900 - accuracy: 0.2292\n",
            "Epoch 384/1000\n",
            "3/3 - 0s - loss: 2.7890 - accuracy: 0.2396\n",
            "Epoch 385/1000\n",
            "3/3 - 0s - loss: 2.7876 - accuracy: 0.2396\n",
            "Epoch 386/1000\n",
            "3/3 - 0s - loss: 2.7983 - accuracy: 0.2396\n",
            "Epoch 387/1000\n",
            "3/3 - 0s - loss: 2.7846 - accuracy: 0.2396\n",
            "Epoch 388/1000\n",
            "3/3 - 0s - loss: 2.7881 - accuracy: 0.2292\n",
            "Epoch 389/1000\n",
            "3/3 - 0s - loss: 2.7859 - accuracy: 0.2292\n",
            "Epoch 390/1000\n",
            "3/3 - 0s - loss: 2.7818 - accuracy: 0.2396\n",
            "Epoch 391/1000\n",
            "3/3 - 0s - loss: 2.7783 - accuracy: 0.2396\n",
            "Epoch 392/1000\n",
            "3/3 - 0s - loss: 2.7847 - accuracy: 0.2396\n",
            "Epoch 393/1000\n",
            "3/3 - 0s - loss: 2.7912 - accuracy: 0.2396\n",
            "Epoch 394/1000\n",
            "3/3 - 0s - loss: 2.7774 - accuracy: 0.2396\n",
            "Epoch 395/1000\n",
            "3/3 - 0s - loss: 2.7681 - accuracy: 0.2396\n",
            "Epoch 396/1000\n",
            "3/3 - 0s - loss: 2.8067 - accuracy: 0.2396\n",
            "Epoch 397/1000\n",
            "3/3 - 0s - loss: 2.7608 - accuracy: 0.2396\n",
            "Epoch 398/1000\n",
            "3/3 - 0s - loss: 2.7483 - accuracy: 0.2396\n",
            "Epoch 399/1000\n",
            "3/3 - 0s - loss: 2.7446 - accuracy: 0.2396\n",
            "Epoch 400/1000\n",
            "3/3 - 0s - loss: 2.7691 - accuracy: 0.2500\n",
            "Epoch 401/1000\n",
            "3/3 - 0s - loss: 2.8046 - accuracy: 0.2604\n",
            "Epoch 402/1000\n",
            "3/3 - 0s - loss: 2.7907 - accuracy: 0.1771\n",
            "Epoch 403/1000\n",
            "3/3 - 0s - loss: 2.8127 - accuracy: 0.2396\n",
            "Epoch 404/1000\n",
            "3/3 - 0s - loss: 2.8366 - accuracy: 0.2292\n",
            "Epoch 405/1000\n",
            "3/3 - 0s - loss: 2.8627 - accuracy: 0.2292\n",
            "Epoch 406/1000\n",
            "3/3 - 0s - loss: 2.8293 - accuracy: 0.2292\n",
            "Epoch 407/1000\n",
            "3/3 - 0s - loss: 2.8188 - accuracy: 0.2292\n",
            "Epoch 408/1000\n",
            "3/3 - 0s - loss: 2.8140 - accuracy: 0.2292\n",
            "Epoch 409/1000\n",
            "3/3 - 0s - loss: 2.8173 - accuracy: 0.2292\n",
            "Epoch 410/1000\n",
            "3/3 - 0s - loss: 2.7974 - accuracy: 0.2292\n",
            "Epoch 411/1000\n",
            "3/3 - 0s - loss: 2.7918 - accuracy: 0.2292\n",
            "Epoch 412/1000\n",
            "3/3 - 0s - loss: 2.7819 - accuracy: 0.2292\n",
            "Epoch 413/1000\n",
            "3/3 - 0s - loss: 2.7762 - accuracy: 0.2292\n",
            "Epoch 414/1000\n",
            "3/3 - 0s - loss: 2.7690 - accuracy: 0.2292\n",
            "Epoch 415/1000\n",
            "3/3 - 0s - loss: 2.7710 - accuracy: 0.2292\n",
            "Epoch 416/1000\n",
            "3/3 - 0s - loss: 2.7609 - accuracy: 0.2292\n",
            "Epoch 417/1000\n",
            "3/3 - 0s - loss: 2.7542 - accuracy: 0.2292\n",
            "Epoch 418/1000\n",
            "3/3 - 0s - loss: 2.7485 - accuracy: 0.2292\n",
            "Epoch 419/1000\n",
            "3/3 - 0s - loss: 2.7403 - accuracy: 0.2292\n",
            "Epoch 420/1000\n",
            "3/3 - 0s - loss: 2.7336 - accuracy: 0.2292\n",
            "Epoch 421/1000\n",
            "3/3 - 0s - loss: 2.7247 - accuracy: 0.2292\n",
            "Epoch 422/1000\n",
            "3/3 - 0s - loss: 2.7140 - accuracy: 0.2292\n",
            "Epoch 423/1000\n",
            "3/3 - 0s - loss: 2.7073 - accuracy: 0.2292\n",
            "Epoch 424/1000\n",
            "3/3 - 0s - loss: 2.6975 - accuracy: 0.2396\n",
            "Epoch 425/1000\n",
            "3/3 - 0s - loss: 2.6587 - accuracy: 0.2604\n",
            "Epoch 426/1000\n",
            "3/3 - 0s - loss: 2.6646 - accuracy: 0.3125\n",
            "Epoch 427/1000\n",
            "3/3 - 0s - loss: 2.9873 - accuracy: 0.2396\n",
            "Epoch 428/1000\n",
            "3/3 - 0s - loss: 3.9151 - accuracy: 0.1250\n",
            "Epoch 429/1000\n",
            "3/3 - 0s - loss: 4.4376 - accuracy: 0.0521\n",
            "Epoch 430/1000\n",
            "3/3 - 0s - loss: 4.3153 - accuracy: 0.0521\n",
            "Epoch 431/1000\n",
            "3/3 - 0s - loss: 4.0659 - accuracy: 0.0417\n",
            "Epoch 432/1000\n",
            "3/3 - 0s - loss: 3.8447 - accuracy: 0.0312\n",
            "Epoch 433/1000\n",
            "3/3 - 0s - loss: 3.6494 - accuracy: 0.0208\n",
            "Epoch 434/1000\n",
            "3/3 - 0s - loss: 3.4946 - accuracy: 0.0417\n",
            "Epoch 435/1000\n",
            "3/3 - 0s - loss: 3.3256 - accuracy: 0.0938\n",
            "Epoch 436/1000\n",
            "3/3 - 0s - loss: 3.1889 - accuracy: 0.0938\n",
            "Epoch 437/1000\n",
            "3/3 - 0s - loss: 3.0827 - accuracy: 0.0938\n",
            "Epoch 438/1000\n",
            "3/3 - 0s - loss: 2.9853 - accuracy: 0.1458\n",
            "Epoch 439/1000\n",
            "3/3 - 0s - loss: 2.9160 - accuracy: 0.2292\n",
            "Epoch 440/1000\n",
            "3/3 - 0s - loss: 2.8739 - accuracy: 0.2292\n",
            "Epoch 441/1000\n",
            "3/3 - 0s - loss: 2.8468 - accuracy: 0.2292\n",
            "Epoch 442/1000\n",
            "3/3 - 0s - loss: 2.8345 - accuracy: 0.2292\n",
            "Epoch 443/1000\n",
            "3/3 - 0s - loss: 2.8272 - accuracy: 0.2292\n",
            "Epoch 444/1000\n",
            "3/3 - 0s - loss: 2.8232 - accuracy: 0.2292\n",
            "Epoch 445/1000\n",
            "3/3 - 0s - loss: 2.8164 - accuracy: 0.2292\n",
            "Epoch 446/1000\n",
            "3/3 - 0s - loss: 2.8151 - accuracy: 0.2292\n",
            "Epoch 447/1000\n",
            "3/3 - 0s - loss: 2.8100 - accuracy: 0.2396\n",
            "Epoch 448/1000\n",
            "3/3 - 0s - loss: 2.7937 - accuracy: 0.2500\n",
            "Epoch 449/1000\n",
            "3/3 - 0s - loss: 2.7906 - accuracy: 0.2604\n",
            "Epoch 450/1000\n",
            "3/3 - 0s - loss: 2.8072 - accuracy: 0.2292\n",
            "Epoch 451/1000\n",
            "3/3 - 0s - loss: 2.8049 - accuracy: 0.2292\n",
            "Epoch 452/1000\n",
            "3/3 - 0s - loss: 2.8054 - accuracy: 0.2292\n",
            "Epoch 453/1000\n",
            "3/3 - 0s - loss: 2.8191 - accuracy: 0.2188\n",
            "Epoch 454/1000\n",
            "3/3 - 0s - loss: 2.8187 - accuracy: 0.2188\n",
            "Epoch 455/1000\n",
            "3/3 - 0s - loss: 2.8172 - accuracy: 0.2188\n",
            "Epoch 456/1000\n",
            "3/3 - 0s - loss: 2.8169 - accuracy: 0.2188\n",
            "Epoch 457/1000\n",
            "3/3 - 0s - loss: 2.8149 - accuracy: 0.2188\n",
            "Epoch 458/1000\n",
            "3/3 - 0s - loss: 2.8155 - accuracy: 0.2188\n",
            "Epoch 459/1000\n",
            "3/3 - 0s - loss: 2.8149 - accuracy: 0.2188\n",
            "Epoch 460/1000\n",
            "3/3 - 0s - loss: 2.8148 - accuracy: 0.2188\n",
            "Epoch 461/1000\n",
            "3/3 - 0s - loss: 2.8142 - accuracy: 0.2188\n",
            "Epoch 462/1000\n",
            "3/3 - 0s - loss: 2.8144 - accuracy: 0.2188\n",
            "Epoch 463/1000\n",
            "3/3 - 0s - loss: 2.8149 - accuracy: 0.2188\n",
            "Epoch 464/1000\n",
            "3/3 - 0s - loss: 2.8142 - accuracy: 0.2188\n",
            "Epoch 465/1000\n",
            "3/3 - 0s - loss: 2.8138 - accuracy: 0.2188\n",
            "Epoch 466/1000\n",
            "3/3 - 0s - loss: 2.8275 - accuracy: 0.2083\n",
            "Epoch 467/1000\n",
            "3/3 - 0s - loss: 2.8129 - accuracy: 0.2188\n",
            "Epoch 468/1000\n",
            "3/3 - 0s - loss: 2.8127 - accuracy: 0.2188\n",
            "Epoch 469/1000\n",
            "3/3 - 0s - loss: 2.8124 - accuracy: 0.2188\n",
            "Epoch 470/1000\n",
            "3/3 - 0s - loss: 2.8126 - accuracy: 0.2188\n",
            "Epoch 471/1000\n",
            "3/3 - 0s - loss: 2.8128 - accuracy: 0.2188\n",
            "Epoch 472/1000\n",
            "3/3 - 0s - loss: 2.8110 - accuracy: 0.2188\n",
            "Epoch 473/1000\n",
            "3/3 - 0s - loss: 2.8106 - accuracy: 0.2188\n",
            "Epoch 474/1000\n",
            "3/3 - 0s - loss: 2.8067 - accuracy: 0.2188\n",
            "Epoch 475/1000\n",
            "3/3 - 0s - loss: 2.8149 - accuracy: 0.2188\n",
            "Epoch 476/1000\n",
            "3/3 - 0s - loss: 2.7880 - accuracy: 0.2188\n",
            "Epoch 477/1000\n",
            "3/3 - 0s - loss: 2.7746 - accuracy: 0.2188\n",
            "Epoch 478/1000\n",
            "3/3 - 0s - loss: 2.7612 - accuracy: 0.2188\n",
            "Epoch 479/1000\n",
            "3/3 - 0s - loss: 2.7629 - accuracy: 0.2188\n",
            "Epoch 480/1000\n",
            "3/3 - 0s - loss: 2.7726 - accuracy: 0.2188\n",
            "Epoch 481/1000\n",
            "3/3 - 0s - loss: 2.7948 - accuracy: 0.2188\n",
            "Epoch 482/1000\n",
            "3/3 - 0s - loss: 2.8334 - accuracy: 0.2188\n",
            "Epoch 483/1000\n",
            "3/3 - 0s - loss: 2.8296 - accuracy: 0.2188\n",
            "Epoch 484/1000\n",
            "3/3 - 0s - loss: 2.8479 - accuracy: 0.2083\n",
            "Epoch 485/1000\n",
            "3/3 - 0s - loss: 2.8351 - accuracy: 0.2083\n",
            "Epoch 486/1000\n",
            "3/3 - 0s - loss: 2.8206 - accuracy: 0.2188\n",
            "Epoch 487/1000\n",
            "3/3 - 0s - loss: 2.8188 - accuracy: 0.2188\n",
            "Epoch 488/1000\n",
            "3/3 - 0s - loss: 2.8165 - accuracy: 0.2188\n",
            "Epoch 489/1000\n",
            "3/3 - 0s - loss: 2.8163 - accuracy: 0.2188\n",
            "Epoch 490/1000\n",
            "3/3 - 0s - loss: 2.8177 - accuracy: 0.2188\n",
            "Epoch 491/1000\n",
            "3/3 - 0s - loss: 2.8179 - accuracy: 0.2188\n",
            "Epoch 492/1000\n",
            "3/3 - 0s - loss: 2.8162 - accuracy: 0.2188\n",
            "Epoch 493/1000\n",
            "3/3 - 0s - loss: 2.8155 - accuracy: 0.2188\n",
            "Epoch 494/1000\n",
            "3/3 - 0s - loss: 2.8150 - accuracy: 0.2188\n",
            "Epoch 495/1000\n",
            "3/3 - 0s - loss: 2.8143 - accuracy: 0.2188\n",
            "Epoch 496/1000\n",
            "3/3 - 0s - loss: 2.8157 - accuracy: 0.2188\n",
            "Epoch 497/1000\n",
            "3/3 - 0s - loss: 2.8138 - accuracy: 0.2188\n",
            "Epoch 498/1000\n",
            "3/3 - 0s - loss: 2.8146 - accuracy: 0.2188\n",
            "Epoch 499/1000\n",
            "3/3 - 0s - loss: 2.8135 - accuracy: 0.2188\n",
            "Epoch 500/1000\n",
            "3/3 - 0s - loss: 2.8143 - accuracy: 0.2188\n",
            "Epoch 501/1000\n",
            "3/3 - 0s - loss: 2.8143 - accuracy: 0.2188\n",
            "Epoch 502/1000\n",
            "3/3 - 0s - loss: 2.8131 - accuracy: 0.2188\n",
            "Epoch 503/1000\n",
            "3/3 - 0s - loss: 2.8132 - accuracy: 0.2188\n",
            "Epoch 504/1000\n",
            "3/3 - 0s - loss: 2.8138 - accuracy: 0.2188\n",
            "Epoch 505/1000\n",
            "3/3 - 0s - loss: 2.8136 - accuracy: 0.2188\n",
            "Epoch 506/1000\n",
            "3/3 - 0s - loss: 2.8143 - accuracy: 0.2188\n",
            "Epoch 507/1000\n",
            "3/3 - 0s - loss: 2.8128 - accuracy: 0.2188\n",
            "Epoch 508/1000\n",
            "3/3 - 0s - loss: 2.8128 - accuracy: 0.2188\n",
            "Epoch 509/1000\n",
            "3/3 - 0s - loss: 2.8134 - accuracy: 0.2188\n",
            "Epoch 510/1000\n",
            "3/3 - 0s - loss: 2.8136 - accuracy: 0.2188\n",
            "Epoch 511/1000\n",
            "3/3 - 0s - loss: 2.8134 - accuracy: 0.2188\n",
            "Epoch 512/1000\n",
            "3/3 - 0s - loss: 2.8131 - accuracy: 0.2188\n",
            "Epoch 513/1000\n",
            "3/3 - 0s - loss: 2.8135 - accuracy: 0.2188\n",
            "Epoch 514/1000\n",
            "3/3 - 0s - loss: 2.8128 - accuracy: 0.2188\n",
            "Epoch 515/1000\n",
            "3/3 - 0s - loss: 2.8133 - accuracy: 0.2188\n",
            "Epoch 516/1000\n",
            "3/3 - 0s - loss: 2.8133 - accuracy: 0.2188\n",
            "Epoch 517/1000\n",
            "3/3 - 0s - loss: 2.8129 - accuracy: 0.2188\n",
            "Epoch 518/1000\n",
            "3/3 - 0s - loss: 2.8133 - accuracy: 0.2188\n",
            "Epoch 519/1000\n",
            "3/3 - 0s - loss: 2.8131 - accuracy: 0.2188\n",
            "Epoch 520/1000\n",
            "3/3 - 0s - loss: 2.8123 - accuracy: 0.2188\n",
            "Epoch 521/1000\n",
            "3/3 - 0s - loss: 2.8129 - accuracy: 0.2188\n",
            "Epoch 522/1000\n",
            "3/3 - 0s - loss: 2.8123 - accuracy: 0.2188\n",
            "Epoch 523/1000\n",
            "3/3 - 0s - loss: 2.8138 - accuracy: 0.2188\n",
            "Epoch 524/1000\n",
            "3/3 - 0s - loss: 2.8129 - accuracy: 0.2188\n",
            "Epoch 525/1000\n",
            "3/3 - 0s - loss: 2.8129 - accuracy: 0.2188\n",
            "Epoch 526/1000\n",
            "3/3 - 0s - loss: 2.8144 - accuracy: 0.2188\n",
            "Epoch 527/1000\n",
            "3/3 - 0s - loss: 2.8138 - accuracy: 0.2188\n",
            "Epoch 528/1000\n",
            "3/3 - 0s - loss: 2.8128 - accuracy: 0.2188\n",
            "Epoch 529/1000\n",
            "3/3 - 0s - loss: 2.8131 - accuracy: 0.2188\n",
            "Epoch 530/1000\n",
            "3/3 - 0s - loss: 2.8122 - accuracy: 0.2188\n",
            "Epoch 531/1000\n",
            "3/3 - 0s - loss: 2.8131 - accuracy: 0.2188\n",
            "Epoch 532/1000\n",
            "3/3 - 0s - loss: 2.8123 - accuracy: 0.2188\n",
            "Epoch 533/1000\n",
            "3/3 - 0s - loss: 2.8131 - accuracy: 0.2188\n",
            "Epoch 534/1000\n",
            "3/3 - 0s - loss: 2.8125 - accuracy: 0.2188\n",
            "Epoch 535/1000\n",
            "3/3 - 0s - loss: 2.8122 - accuracy: 0.2188\n",
            "Epoch 536/1000\n",
            "3/3 - 0s - loss: 2.8121 - accuracy: 0.2188\n",
            "Epoch 537/1000\n",
            "3/3 - 0s - loss: 2.8124 - accuracy: 0.2188\n",
            "Epoch 538/1000\n",
            "3/3 - 0s - loss: 2.8126 - accuracy: 0.2188\n",
            "Epoch 539/1000\n",
            "3/3 - 0s - loss: 2.8118 - accuracy: 0.2188\n",
            "Epoch 540/1000\n",
            "3/3 - 0s - loss: 2.8119 - accuracy: 0.2188\n",
            "Epoch 541/1000\n",
            "3/3 - 0s - loss: 2.8121 - accuracy: 0.2188\n",
            "Epoch 542/1000\n",
            "3/3 - 0s - loss: 2.8127 - accuracy: 0.2188\n",
            "Epoch 543/1000\n",
            "3/3 - 0s - loss: 2.8121 - accuracy: 0.2188\n",
            "Epoch 544/1000\n",
            "3/3 - 0s - loss: 2.8120 - accuracy: 0.2188\n",
            "Epoch 545/1000\n",
            "3/3 - 0s - loss: 2.8121 - accuracy: 0.2188\n",
            "Epoch 546/1000\n",
            "3/3 - 0s - loss: 2.8141 - accuracy: 0.2188\n",
            "Epoch 547/1000\n",
            "3/3 - 0s - loss: 2.8124 - accuracy: 0.2188\n",
            "Epoch 548/1000\n",
            "3/3 - 0s - loss: 2.8117 - accuracy: 0.2188\n",
            "Epoch 549/1000\n",
            "3/3 - 0s - loss: 2.8121 - accuracy: 0.2188\n",
            "Epoch 550/1000\n",
            "3/3 - 0s - loss: 2.8112 - accuracy: 0.2188\n",
            "Epoch 551/1000\n",
            "3/3 - 0s - loss: 2.8119 - accuracy: 0.2188\n",
            "Epoch 552/1000\n",
            "3/3 - 0s - loss: 2.8124 - accuracy: 0.2188\n",
            "Epoch 553/1000\n",
            "3/3 - 0s - loss: 2.8129 - accuracy: 0.2188\n",
            "Epoch 554/1000\n",
            "3/3 - 0s - loss: 2.8123 - accuracy: 0.2188\n",
            "Epoch 555/1000\n",
            "3/3 - 0s - loss: 2.8116 - accuracy: 0.2188\n",
            "Epoch 556/1000\n",
            "3/3 - 0s - loss: 2.8116 - accuracy: 0.2188\n",
            "Epoch 557/1000\n",
            "3/3 - 0s - loss: 2.8122 - accuracy: 0.2188\n",
            "Epoch 558/1000\n",
            "3/3 - 0s - loss: 2.8112 - accuracy: 0.2188\n",
            "Epoch 559/1000\n",
            "3/3 - 0s - loss: 2.8128 - accuracy: 0.2188\n",
            "Epoch 560/1000\n",
            "3/3 - 0s - loss: 2.8118 - accuracy: 0.2188\n",
            "Epoch 561/1000\n",
            "3/3 - 0s - loss: 2.8111 - accuracy: 0.2188\n",
            "Epoch 562/1000\n",
            "3/3 - 0s - loss: 2.8120 - accuracy: 0.2188\n",
            "Epoch 563/1000\n",
            "3/3 - 0s - loss: 2.8113 - accuracy: 0.2188\n",
            "Epoch 564/1000\n",
            "3/3 - 0s - loss: 2.8123 - accuracy: 0.2188\n",
            "Epoch 565/1000\n",
            "3/3 - 0s - loss: 2.8110 - accuracy: 0.2188\n",
            "Epoch 566/1000\n",
            "3/3 - 0s - loss: 2.8107 - accuracy: 0.2188\n",
            "Epoch 567/1000\n",
            "3/3 - 0s - loss: 2.8111 - accuracy: 0.2188\n",
            "Epoch 568/1000\n",
            "3/3 - 0s - loss: 2.8111 - accuracy: 0.2188\n",
            "Epoch 569/1000\n",
            "3/3 - 0s - loss: 2.8102 - accuracy: 0.2188\n",
            "Epoch 570/1000\n",
            "3/3 - 0s - loss: 2.8104 - accuracy: 0.2188\n",
            "Epoch 571/1000\n",
            "3/3 - 0s - loss: 2.8100 - accuracy: 0.2188\n",
            "Epoch 572/1000\n",
            "3/3 - 0s - loss: 2.8110 - accuracy: 0.2188\n",
            "Epoch 573/1000\n",
            "3/3 - 0s - loss: 2.8105 - accuracy: 0.2188\n",
            "Epoch 574/1000\n",
            "3/3 - 0s - loss: 2.8107 - accuracy: 0.2188\n",
            "Epoch 575/1000\n",
            "3/3 - 0s - loss: 2.8103 - accuracy: 0.2188\n",
            "Epoch 576/1000\n",
            "3/3 - 0s - loss: 2.8109 - accuracy: 0.2188\n",
            "Epoch 577/1000\n",
            "3/3 - 0s - loss: 2.8112 - accuracy: 0.2188\n",
            "Epoch 578/1000\n",
            "3/3 - 0s - loss: 2.8110 - accuracy: 0.2188\n",
            "Epoch 579/1000\n",
            "3/3 - 0s - loss: 2.8104 - accuracy: 0.2188\n",
            "Epoch 580/1000\n",
            "3/3 - 0s - loss: 2.8097 - accuracy: 0.2188\n",
            "Epoch 581/1000\n",
            "3/3 - 0s - loss: 2.8098 - accuracy: 0.2188\n",
            "Epoch 582/1000\n",
            "3/3 - 0s - loss: 2.8098 - accuracy: 0.2188\n",
            "Epoch 583/1000\n",
            "3/3 - 0s - loss: 2.8090 - accuracy: 0.2188\n",
            "Epoch 584/1000\n",
            "3/3 - 0s - loss: 2.8101 - accuracy: 0.2188\n",
            "Epoch 585/1000\n",
            "3/3 - 0s - loss: 2.8106 - accuracy: 0.2188\n",
            "Epoch 586/1000\n",
            "3/3 - 0s - loss: 2.8096 - accuracy: 0.2188\n",
            "Epoch 587/1000\n",
            "3/3 - 0s - loss: 2.8095 - accuracy: 0.2188\n",
            "Epoch 588/1000\n",
            "3/3 - 0s - loss: 2.8108 - accuracy: 0.2188\n",
            "Epoch 589/1000\n",
            "3/3 - 0s - loss: 2.8099 - accuracy: 0.2188\n",
            "Epoch 590/1000\n",
            "3/3 - 0s - loss: 2.8096 - accuracy: 0.2188\n",
            "Epoch 591/1000\n",
            "3/3 - 0s - loss: 2.8098 - accuracy: 0.2188\n",
            "Epoch 592/1000\n",
            "3/3 - 0s - loss: 2.8091 - accuracy: 0.2188\n",
            "Epoch 593/1000\n",
            "3/3 - 0s - loss: 2.8106 - accuracy: 0.2188\n",
            "Epoch 594/1000\n",
            "3/3 - 0s - loss: 2.8093 - accuracy: 0.2188\n",
            "Epoch 595/1000\n",
            "3/3 - 0s - loss: 2.8096 - accuracy: 0.2188\n",
            "Epoch 596/1000\n",
            "3/3 - 0s - loss: 2.8097 - accuracy: 0.2188\n",
            "Epoch 597/1000\n",
            "3/3 - 0s - loss: 2.8101 - accuracy: 0.2188\n",
            "Epoch 598/1000\n",
            "3/3 - 0s - loss: 2.8084 - accuracy: 0.2188\n",
            "Epoch 599/1000\n",
            "3/3 - 0s - loss: 2.8088 - accuracy: 0.2188\n",
            "Epoch 600/1000\n",
            "3/3 - 0s - loss: 2.8091 - accuracy: 0.2188\n",
            "Epoch 601/1000\n",
            "3/3 - 0s - loss: 2.8093 - accuracy: 0.2188\n",
            "Epoch 602/1000\n",
            "3/3 - 0s - loss: 2.8087 - accuracy: 0.2188\n",
            "Epoch 603/1000\n",
            "3/3 - 0s - loss: 2.8093 - accuracy: 0.2188\n",
            "Epoch 604/1000\n",
            "3/3 - 0s - loss: 2.8091 - accuracy: 0.2188\n",
            "Epoch 605/1000\n",
            "3/3 - 0s - loss: 2.8092 - accuracy: 0.2188\n",
            "Epoch 606/1000\n",
            "3/3 - 0s - loss: 2.8079 - accuracy: 0.2188\n",
            "Epoch 607/1000\n",
            "3/3 - 0s - loss: 2.8073 - accuracy: 0.2188\n",
            "Epoch 608/1000\n",
            "3/3 - 0s - loss: 2.8090 - accuracy: 0.2188\n",
            "Epoch 609/1000\n",
            "3/3 - 0s - loss: 2.8084 - accuracy: 0.2188\n",
            "Epoch 610/1000\n",
            "3/3 - 0s - loss: 2.8088 - accuracy: 0.2188\n",
            "Epoch 611/1000\n",
            "3/3 - 0s - loss: 2.8160 - accuracy: 0.2083\n",
            "Epoch 612/1000\n",
            "3/3 - 0s - loss: 2.8144 - accuracy: 0.2083\n",
            "Epoch 613/1000\n",
            "3/3 - 0s - loss: 2.8162 - accuracy: 0.2083\n",
            "Epoch 614/1000\n",
            "3/3 - 0s - loss: 2.8065 - accuracy: 0.2188\n",
            "Epoch 615/1000\n",
            "3/3 - 0s - loss: 2.8066 - accuracy: 0.2188\n",
            "Epoch 616/1000\n",
            "3/3 - 0s - loss: 2.8068 - accuracy: 0.2188\n",
            "Epoch 617/1000\n",
            "3/3 - 0s - loss: 2.8067 - accuracy: 0.2188\n",
            "Epoch 618/1000\n",
            "3/3 - 0s - loss: 2.8070 - accuracy: 0.2188\n",
            "Epoch 619/1000\n",
            "3/3 - 0s - loss: 2.8059 - accuracy: 0.2188\n",
            "Epoch 620/1000\n",
            "3/3 - 0s - loss: 2.8084 - accuracy: 0.2083\n",
            "Epoch 621/1000\n",
            "3/3 - 0s - loss: 2.8136 - accuracy: 0.1979\n",
            "Epoch 622/1000\n",
            "3/3 - 0s - loss: 2.8137 - accuracy: 0.1979\n",
            "Epoch 623/1000\n",
            "3/3 - 0s - loss: 2.8098 - accuracy: 0.1979\n",
            "Epoch 624/1000\n",
            "3/3 - 0s - loss: 2.8047 - accuracy: 0.1979\n",
            "Epoch 625/1000\n",
            "3/3 - 0s - loss: 2.8039 - accuracy: 0.1979\n",
            "Epoch 626/1000\n",
            "3/3 - 0s - loss: 2.8060 - accuracy: 0.1979\n",
            "Epoch 627/1000\n",
            "3/3 - 0s - loss: 2.8009 - accuracy: 0.2188\n",
            "Epoch 628/1000\n",
            "3/3 - 0s - loss: 2.7960 - accuracy: 0.2188\n",
            "Epoch 629/1000\n",
            "3/3 - 0s - loss: 2.7940 - accuracy: 0.2188\n",
            "Epoch 630/1000\n",
            "3/3 - 0s - loss: 2.8012 - accuracy: 0.2188\n",
            "Epoch 631/1000\n",
            "3/3 - 0s - loss: 2.7985 - accuracy: 0.2188\n",
            "Epoch 632/1000\n",
            "3/3 - 0s - loss: 2.7957 - accuracy: 0.2188\n",
            "Epoch 633/1000\n",
            "3/3 - 0s - loss: 2.7918 - accuracy: 0.2188\n",
            "Epoch 634/1000\n",
            "3/3 - 0s - loss: 2.7890 - accuracy: 0.2188\n",
            "Epoch 635/1000\n",
            "3/3 - 0s - loss: 2.7881 - accuracy: 0.2188\n",
            "Epoch 636/1000\n",
            "3/3 - 0s - loss: 2.7822 - accuracy: 0.2188\n",
            "Epoch 637/1000\n",
            "3/3 - 0s - loss: 2.7811 - accuracy: 0.2188\n",
            "Epoch 638/1000\n",
            "3/3 - 0s - loss: 2.7673 - accuracy: 0.2188\n",
            "Epoch 639/1000\n",
            "3/3 - 0s - loss: 2.7616 - accuracy: 0.2188\n",
            "Epoch 640/1000\n",
            "3/3 - 0s - loss: 2.7604 - accuracy: 0.2188\n",
            "Epoch 641/1000\n",
            "3/3 - 0s - loss: 2.7588 - accuracy: 0.2188\n",
            "Epoch 642/1000\n",
            "3/3 - 0s - loss: 2.7527 - accuracy: 0.2188\n",
            "Epoch 643/1000\n",
            "3/3 - 0s - loss: 2.7264 - accuracy: 0.2188\n",
            "Epoch 644/1000\n",
            "3/3 - 0s - loss: 2.7257 - accuracy: 0.2188\n",
            "Epoch 645/1000\n",
            "3/3 - 0s - loss: 2.7370 - accuracy: 0.2188\n",
            "Epoch 646/1000\n",
            "3/3 - 0s - loss: 2.7219 - accuracy: 0.2188\n",
            "Epoch 647/1000\n",
            "3/3 - 0s - loss: 2.6988 - accuracy: 0.2188\n",
            "Epoch 648/1000\n",
            "3/3 - 0s - loss: 2.6992 - accuracy: 0.2396\n",
            "Epoch 649/1000\n",
            "3/3 - 0s - loss: 2.7003 - accuracy: 0.2396\n",
            "Epoch 650/1000\n",
            "3/3 - 0s - loss: 2.6959 - accuracy: 0.2396\n",
            "Epoch 651/1000\n",
            "3/3 - 0s - loss: 2.6934 - accuracy: 0.2396\n",
            "Epoch 652/1000\n",
            "3/3 - 0s - loss: 2.6911 - accuracy: 0.2396\n",
            "Epoch 653/1000\n",
            "3/3 - 0s - loss: 2.6910 - accuracy: 0.2396\n",
            "Epoch 654/1000\n",
            "3/3 - 0s - loss: 2.6872 - accuracy: 0.2396\n",
            "Epoch 655/1000\n",
            "3/3 - 0s - loss: 2.7104 - accuracy: 0.2188\n",
            "Epoch 656/1000\n",
            "3/3 - 0s - loss: 2.7728 - accuracy: 0.2188\n",
            "Epoch 657/1000\n",
            "3/3 - 0s - loss: 2.6870 - accuracy: 0.2292\n",
            "Epoch 658/1000\n",
            "3/3 - 0s - loss: 2.7818 - accuracy: 0.2396\n",
            "Epoch 659/1000\n",
            "3/3 - 0s - loss: 2.7520 - accuracy: 0.2396\n",
            "Epoch 660/1000\n",
            "3/3 - 0s - loss: 2.7188 - accuracy: 0.2396\n",
            "Epoch 661/1000\n",
            "3/3 - 0s - loss: 2.8011 - accuracy: 0.2396\n",
            "Epoch 662/1000\n",
            "3/3 - 0s - loss: 2.8266 - accuracy: 0.2292\n",
            "Epoch 663/1000\n",
            "3/3 - 0s - loss: 2.8215 - accuracy: 0.2292\n",
            "Epoch 664/1000\n",
            "3/3 - 0s - loss: 2.7586 - accuracy: 0.2292\n",
            "Epoch 665/1000\n",
            "3/3 - 0s - loss: 2.8172 - accuracy: 0.2396\n",
            "Epoch 666/1000\n",
            "3/3 - 0s - loss: 2.7183 - accuracy: 0.2500\n",
            "Epoch 667/1000\n",
            "3/3 - 0s - loss: 2.6477 - accuracy: 0.2604\n",
            "Epoch 668/1000\n",
            "3/3 - 0s - loss: 2.6700 - accuracy: 0.2396\n",
            "Epoch 669/1000\n",
            "3/3 - 0s - loss: 2.6627 - accuracy: 0.2188\n",
            "Epoch 670/1000\n",
            "3/3 - 0s - loss: 2.6476 - accuracy: 0.2188\n",
            "Epoch 671/1000\n",
            "3/3 - 0s - loss: 2.6353 - accuracy: 0.2188\n",
            "Epoch 672/1000\n",
            "3/3 - 0s - loss: 2.6264 - accuracy: 0.2188\n",
            "Epoch 673/1000\n",
            "3/3 - 0s - loss: 2.6149 - accuracy: 0.2292\n",
            "Epoch 674/1000\n",
            "3/3 - 0s - loss: 2.6036 - accuracy: 0.2292\n",
            "Epoch 675/1000\n",
            "3/3 - 0s - loss: 2.5920 - accuracy: 0.2292\n",
            "Epoch 676/1000\n",
            "3/3 - 0s - loss: 2.5836 - accuracy: 0.2188\n",
            "Epoch 677/1000\n",
            "3/3 - 0s - loss: 2.5749 - accuracy: 0.2188\n",
            "Epoch 678/1000\n",
            "3/3 - 0s - loss: 2.5714 - accuracy: 0.1875\n",
            "Epoch 679/1000\n",
            "3/3 - 0s - loss: 2.5661 - accuracy: 0.2292\n",
            "Epoch 680/1000\n",
            "3/3 - 0s - loss: 2.5623 - accuracy: 0.2292\n",
            "Epoch 681/1000\n",
            "3/3 - 0s - loss: 2.5563 - accuracy: 0.2292\n",
            "Epoch 682/1000\n",
            "3/3 - 0s - loss: 2.5543 - accuracy: 0.2292\n",
            "Epoch 683/1000\n",
            "3/3 - 0s - loss: 2.5568 - accuracy: 0.2292\n",
            "Epoch 684/1000\n",
            "3/3 - 0s - loss: 2.5434 - accuracy: 0.1875\n",
            "Epoch 685/1000\n",
            "3/3 - 0s - loss: 2.5565 - accuracy: 0.1979\n",
            "Epoch 686/1000\n",
            "3/3 - 0s - loss: 2.5544 - accuracy: 0.2292\n",
            "Epoch 687/1000\n",
            "3/3 - 0s - loss: 2.5355 - accuracy: 0.2292\n",
            "Epoch 688/1000\n",
            "3/3 - 0s - loss: 2.5343 - accuracy: 0.2188\n",
            "Epoch 689/1000\n",
            "3/3 - 0s - loss: 2.5301 - accuracy: 0.2188\n",
            "Epoch 690/1000\n",
            "3/3 - 0s - loss: 2.5209 - accuracy: 0.2188\n",
            "Epoch 691/1000\n",
            "3/3 - 0s - loss: 2.5165 - accuracy: 0.2188\n",
            "Epoch 692/1000\n",
            "3/3 - 0s - loss: 2.5414 - accuracy: 0.2083\n",
            "Epoch 693/1000\n",
            "3/3 - 0s - loss: 2.5330 - accuracy: 0.2188\n",
            "Epoch 694/1000\n",
            "3/3 - 0s - loss: 2.5275 - accuracy: 0.2083\n",
            "Epoch 695/1000\n",
            "3/3 - 0s - loss: 2.5272 - accuracy: 0.1875\n",
            "Epoch 696/1000\n",
            "3/3 - 0s - loss: 2.5221 - accuracy: 0.1979\n",
            "Epoch 697/1000\n",
            "3/3 - 0s - loss: 2.5182 - accuracy: 0.2083\n",
            "Epoch 698/1000\n",
            "3/3 - 0s - loss: 2.5155 - accuracy: 0.2188\n",
            "Epoch 699/1000\n",
            "3/3 - 0s - loss: 2.5122 - accuracy: 0.1771\n",
            "Epoch 700/1000\n",
            "3/3 - 0s - loss: 2.5091 - accuracy: 0.1979\n",
            "Epoch 701/1000\n",
            "3/3 - 0s - loss: 2.5055 - accuracy: 0.2083\n",
            "Epoch 702/1000\n",
            "3/3 - 0s - loss: 2.5004 - accuracy: 0.2083\n",
            "Epoch 703/1000\n",
            "3/3 - 0s - loss: 2.4965 - accuracy: 0.2083\n",
            "Epoch 704/1000\n",
            "3/3 - 0s - loss: 2.4962 - accuracy: 0.2188\n",
            "Epoch 705/1000\n",
            "3/3 - 0s - loss: 2.4922 - accuracy: 0.2188\n",
            "Epoch 706/1000\n",
            "3/3 - 0s - loss: 2.4964 - accuracy: 0.2083\n",
            "Epoch 707/1000\n",
            "3/3 - 0s - loss: 2.4834 - accuracy: 0.1875\n",
            "Epoch 708/1000\n",
            "3/3 - 0s - loss: 2.4757 - accuracy: 0.2083\n",
            "Epoch 709/1000\n",
            "3/3 - 0s - loss: 2.4712 - accuracy: 0.2083\n",
            "Epoch 710/1000\n",
            "3/3 - 0s - loss: 2.4597 - accuracy: 0.2604\n",
            "Epoch 711/1000\n",
            "3/3 - 0s - loss: 2.4499 - accuracy: 0.2604\n",
            "Epoch 712/1000\n",
            "3/3 - 0s - loss: 2.4405 - accuracy: 0.2604\n",
            "Epoch 713/1000\n",
            "3/3 - 0s - loss: 2.4478 - accuracy: 0.2604\n",
            "Epoch 714/1000\n",
            "3/3 - 0s - loss: 2.4270 - accuracy: 0.2292\n",
            "Epoch 715/1000\n",
            "3/3 - 0s - loss: 2.4445 - accuracy: 0.2708\n",
            "Epoch 716/1000\n",
            "3/3 - 0s - loss: 2.3999 - accuracy: 0.3125\n",
            "Epoch 717/1000\n",
            "3/3 - 0s - loss: 2.4044 - accuracy: 0.2708\n",
            "Epoch 718/1000\n",
            "3/3 - 0s - loss: 2.3909 - accuracy: 0.3125\n",
            "Epoch 719/1000\n",
            "3/3 - 0s - loss: 2.3954 - accuracy: 0.2812\n",
            "Epoch 720/1000\n",
            "3/3 - 0s - loss: 2.4147 - accuracy: 0.2812\n",
            "Epoch 721/1000\n",
            "3/3 - 0s - loss: 2.4134 - accuracy: 0.2917\n",
            "Epoch 722/1000\n",
            "3/3 - 0s - loss: 2.4531 - accuracy: 0.2604\n",
            "Epoch 723/1000\n",
            "3/3 - 0s - loss: 2.4351 - accuracy: 0.2708\n",
            "Epoch 724/1000\n",
            "3/3 - 0s - loss: 2.3993 - accuracy: 0.2917\n",
            "Epoch 725/1000\n",
            "3/3 - 0s - loss: 2.3604 - accuracy: 0.3125\n",
            "Epoch 726/1000\n",
            "3/3 - 0s - loss: 2.3464 - accuracy: 0.3229\n",
            "Epoch 727/1000\n",
            "3/3 - 0s - loss: 2.3486 - accuracy: 0.3229\n",
            "Epoch 728/1000\n",
            "3/3 - 0s - loss: 2.4409 - accuracy: 0.2812\n",
            "Epoch 729/1000\n",
            "3/3 - 0s - loss: 2.4576 - accuracy: 0.2604\n",
            "Epoch 730/1000\n",
            "3/3 - 0s - loss: 2.4531 - accuracy: 0.2604\n",
            "Epoch 731/1000\n",
            "3/3 - 0s - loss: 2.4481 - accuracy: 0.2708\n",
            "Epoch 732/1000\n",
            "3/3 - 0s - loss: 2.4382 - accuracy: 0.2708\n",
            "Epoch 733/1000\n",
            "3/3 - 0s - loss: 2.4545 - accuracy: 0.2604\n",
            "Epoch 734/1000\n",
            "3/3 - 0s - loss: 2.4640 - accuracy: 0.2604\n",
            "Epoch 735/1000\n",
            "3/3 - 0s - loss: 2.4476 - accuracy: 0.2604\n",
            "Epoch 736/1000\n",
            "3/3 - 0s - loss: 2.4376 - accuracy: 0.2708\n",
            "Epoch 737/1000\n",
            "3/3 - 0s - loss: 2.4313 - accuracy: 0.2708\n",
            "Epoch 738/1000\n",
            "3/3 - 0s - loss: 2.4298 - accuracy: 0.2812\n",
            "Epoch 739/1000\n",
            "3/3 - 0s - loss: 2.4330 - accuracy: 0.2500\n",
            "Epoch 740/1000\n",
            "3/3 - 0s - loss: 2.4294 - accuracy: 0.2396\n",
            "Epoch 741/1000\n",
            "3/3 - 0s - loss: 2.4369 - accuracy: 0.2500\n",
            "Epoch 742/1000\n",
            "3/3 - 0s - loss: 2.4293 - accuracy: 0.2708\n",
            "Epoch 743/1000\n",
            "3/3 - 0s - loss: 2.4258 - accuracy: 0.2708\n",
            "Epoch 744/1000\n",
            "3/3 - 0s - loss: 2.4228 - accuracy: 0.2708\n",
            "Epoch 745/1000\n",
            "3/3 - 0s - loss: 2.4217 - accuracy: 0.2708\n",
            "Epoch 746/1000\n",
            "3/3 - 0s - loss: 2.4196 - accuracy: 0.2708\n",
            "Epoch 747/1000\n",
            "3/3 - 0s - loss: 2.4155 - accuracy: 0.2708\n",
            "Epoch 748/1000\n",
            "3/3 - 0s - loss: 2.4100 - accuracy: 0.2708\n",
            "Epoch 749/1000\n",
            "3/3 - 0s - loss: 2.4043 - accuracy: 0.2708\n",
            "Epoch 750/1000\n",
            "3/3 - 0s - loss: 2.4012 - accuracy: 0.2396\n",
            "Epoch 751/1000\n",
            "3/3 - 0s - loss: 2.3740 - accuracy: 0.2917\n",
            "Epoch 752/1000\n",
            "3/3 - 0s - loss: 2.3751 - accuracy: 0.2917\n",
            "Epoch 753/1000\n",
            "3/3 - 0s - loss: 2.3218 - accuracy: 0.2917\n",
            "Epoch 754/1000\n",
            "3/3 - 0s - loss: 2.3122 - accuracy: 0.2708\n",
            "Epoch 755/1000\n",
            "3/3 - 0s - loss: 2.3010 - accuracy: 0.3125\n",
            "Epoch 756/1000\n",
            "3/3 - 0s - loss: 2.3256 - accuracy: 0.3021\n",
            "Epoch 757/1000\n",
            "3/3 - 0s - loss: 2.3549 - accuracy: 0.2917\n",
            "Epoch 758/1000\n",
            "3/3 - 0s - loss: 2.3978 - accuracy: 0.2708\n",
            "Epoch 759/1000\n",
            "3/3 - 0s - loss: 2.3945 - accuracy: 0.2500\n",
            "Epoch 760/1000\n",
            "3/3 - 0s - loss: 2.7045 - accuracy: 0.2083\n",
            "Epoch 761/1000\n",
            "3/3 - 0s - loss: 2.6528 - accuracy: 0.2083\n",
            "Epoch 762/1000\n",
            "3/3 - 0s - loss: 2.6197 - accuracy: 0.2396\n",
            "Epoch 763/1000\n",
            "3/3 - 0s - loss: 2.7928 - accuracy: 0.2708\n",
            "Epoch 764/1000\n",
            "3/3 - 0s - loss: 2.7372 - accuracy: 0.2708\n",
            "Epoch 765/1000\n",
            "3/3 - 0s - loss: 2.5979 - accuracy: 0.2500\n",
            "Epoch 766/1000\n",
            "3/3 - 0s - loss: 2.7296 - accuracy: 0.1979\n",
            "Epoch 767/1000\n",
            "3/3 - 0s - loss: 2.7926 - accuracy: 0.1771\n",
            "Epoch 768/1000\n",
            "3/3 - 0s - loss: 2.7830 - accuracy: 0.1667\n",
            "Epoch 769/1000\n",
            "3/3 - 0s - loss: 2.7646 - accuracy: 0.2188\n",
            "Epoch 770/1000\n",
            "3/3 - 0s - loss: 2.7389 - accuracy: 0.2292\n",
            "Epoch 771/1000\n",
            "3/3 - 0s - loss: 2.7225 - accuracy: 0.2292\n",
            "Epoch 772/1000\n",
            "3/3 - 0s - loss: 2.6933 - accuracy: 0.2188\n",
            "Epoch 773/1000\n",
            "3/3 - 0s - loss: 2.7069 - accuracy: 0.2292\n",
            "Epoch 774/1000\n",
            "3/3 - 0s - loss: 2.6873 - accuracy: 0.2292\n",
            "Epoch 775/1000\n",
            "3/3 - 0s - loss: 2.6381 - accuracy: 0.2188\n",
            "Epoch 776/1000\n",
            "3/3 - 0s - loss: 2.6337 - accuracy: 0.2188\n",
            "Epoch 777/1000\n",
            "3/3 - 0s - loss: 2.6228 - accuracy: 0.2188\n",
            "Epoch 778/1000\n",
            "3/3 - 0s - loss: 2.6175 - accuracy: 0.2188\n",
            "Epoch 779/1000\n",
            "3/3 - 0s - loss: 2.6123 - accuracy: 0.2188\n",
            "Epoch 780/1000\n",
            "3/3 - 0s - loss: 2.6062 - accuracy: 0.2188\n",
            "Epoch 781/1000\n",
            "3/3 - 0s - loss: 2.6024 - accuracy: 0.2188\n",
            "Epoch 782/1000\n",
            "3/3 - 0s - loss: 2.6185 - accuracy: 0.2188\n",
            "Epoch 783/1000\n",
            "3/3 - 0s - loss: 2.6066 - accuracy: 0.2188\n",
            "Epoch 784/1000\n",
            "3/3 - 0s - loss: 2.5998 - accuracy: 0.2188\n",
            "Epoch 785/1000\n",
            "3/3 - 0s - loss: 2.5904 - accuracy: 0.2188\n",
            "Epoch 786/1000\n",
            "3/3 - 0s - loss: 2.5773 - accuracy: 0.2188\n",
            "Epoch 787/1000\n",
            "3/3 - 0s - loss: 2.5753 - accuracy: 0.2188\n",
            "Epoch 788/1000\n",
            "3/3 - 0s - loss: 2.6092 - accuracy: 0.2188\n",
            "Epoch 789/1000\n",
            "3/3 - 0s - loss: 2.6068 - accuracy: 0.2188\n",
            "Epoch 790/1000\n",
            "3/3 - 0s - loss: 2.5968 - accuracy: 0.2188\n",
            "Epoch 791/1000\n",
            "3/3 - 0s - loss: 2.5939 - accuracy: 0.2188\n",
            "Epoch 792/1000\n",
            "3/3 - 0s - loss: 2.5893 - accuracy: 0.2188\n",
            "Epoch 793/1000\n",
            "3/3 - 0s - loss: 2.5885 - accuracy: 0.2188\n",
            "Epoch 794/1000\n",
            "3/3 - 0s - loss: 2.5764 - accuracy: 0.2188\n",
            "Epoch 795/1000\n",
            "3/3 - 0s - loss: 2.5721 - accuracy: 0.2188\n",
            "Epoch 796/1000\n",
            "3/3 - 0s - loss: 2.5728 - accuracy: 0.2188\n",
            "Epoch 797/1000\n",
            "3/3 - 0s - loss: 2.5424 - accuracy: 0.2188\n",
            "Epoch 798/1000\n",
            "3/3 - 0s - loss: 2.5277 - accuracy: 0.2292\n",
            "Epoch 799/1000\n",
            "3/3 - 0s - loss: 2.4992 - accuracy: 0.2292\n",
            "Epoch 800/1000\n",
            "3/3 - 0s - loss: 2.5563 - accuracy: 0.2292\n",
            "Epoch 801/1000\n",
            "3/3 - 0s - loss: 2.5628 - accuracy: 0.2188\n",
            "Epoch 802/1000\n",
            "3/3 - 0s - loss: 2.5657 - accuracy: 0.2188\n",
            "Epoch 803/1000\n",
            "3/3 - 0s - loss: 2.5624 - accuracy: 0.2292\n",
            "Epoch 804/1000\n",
            "3/3 - 0s - loss: 2.5601 - accuracy: 0.2292\n",
            "Epoch 805/1000\n",
            "3/3 - 0s - loss: 2.5518 - accuracy: 0.2292\n",
            "Epoch 806/1000\n",
            "3/3 - 0s - loss: 2.5496 - accuracy: 0.2292\n",
            "Epoch 807/1000\n",
            "3/3 - 0s - loss: 2.5454 - accuracy: 0.2396\n",
            "Epoch 808/1000\n",
            "3/3 - 0s - loss: 2.5414 - accuracy: 0.2500\n",
            "Epoch 809/1000\n",
            "3/3 - 0s - loss: 2.5374 - accuracy: 0.2500\n",
            "Epoch 810/1000\n",
            "3/3 - 0s - loss: 2.5326 - accuracy: 0.2604\n",
            "Epoch 811/1000\n",
            "3/3 - 0s - loss: 2.5634 - accuracy: 0.2292\n",
            "Epoch 812/1000\n",
            "3/3 - 0s - loss: 2.5477 - accuracy: 0.2604\n",
            "Epoch 813/1000\n",
            "3/3 - 0s - loss: 2.5907 - accuracy: 0.2292\n",
            "Epoch 814/1000\n",
            "3/3 - 0s - loss: 2.5645 - accuracy: 0.2188\n",
            "Epoch 815/1000\n",
            "3/3 - 0s - loss: 2.5955 - accuracy: 0.2188\n",
            "Epoch 816/1000\n",
            "3/3 - 0s - loss: 2.5916 - accuracy: 0.2292\n",
            "Epoch 817/1000\n",
            "3/3 - 0s - loss: 2.5748 - accuracy: 0.2396\n",
            "Epoch 818/1000\n",
            "3/3 - 0s - loss: 2.5796 - accuracy: 0.2292\n",
            "Epoch 819/1000\n",
            "3/3 - 0s - loss: 2.6166 - accuracy: 0.2292\n",
            "Epoch 820/1000\n",
            "3/3 - 0s - loss: 2.6158 - accuracy: 0.2396\n",
            "Epoch 821/1000\n",
            "3/3 - 0s - loss: 2.6105 - accuracy: 0.2396\n",
            "Epoch 822/1000\n",
            "3/3 - 0s - loss: 2.6064 - accuracy: 0.2396\n",
            "Epoch 823/1000\n",
            "3/3 - 0s - loss: 2.6003 - accuracy: 0.2396\n",
            "Epoch 824/1000\n",
            "3/3 - 0s - loss: 2.5963 - accuracy: 0.2292\n",
            "Epoch 825/1000\n",
            "3/3 - 0s - loss: 2.5905 - accuracy: 0.2292\n",
            "Epoch 826/1000\n",
            "3/3 - 0s - loss: 2.6025 - accuracy: 0.2396\n",
            "Epoch 827/1000\n",
            "3/3 - 0s - loss: 2.5955 - accuracy: 0.2500\n",
            "Epoch 828/1000\n",
            "3/3 - 0s - loss: 2.5948 - accuracy: 0.2396\n",
            "Epoch 829/1000\n",
            "3/3 - 0s - loss: 2.5922 - accuracy: 0.2396\n",
            "Epoch 830/1000\n",
            "3/3 - 0s - loss: 2.5874 - accuracy: 0.2396\n",
            "Epoch 831/1000\n",
            "3/3 - 0s - loss: 2.5798 - accuracy: 0.2500\n",
            "Epoch 832/1000\n",
            "3/3 - 0s - loss: 2.5833 - accuracy: 0.2500\n",
            "Epoch 833/1000\n",
            "3/3 - 0s - loss: 2.5719 - accuracy: 0.2500\n",
            "Epoch 834/1000\n",
            "3/3 - 0s - loss: 2.5793 - accuracy: 0.2396\n",
            "Epoch 835/1000\n",
            "3/3 - 0s - loss: 2.5651 - accuracy: 0.2396\n",
            "Epoch 836/1000\n",
            "3/3 - 0s - loss: 2.5607 - accuracy: 0.2500\n",
            "Epoch 837/1000\n",
            "3/3 - 0s - loss: 2.5605 - accuracy: 0.2500\n",
            "Epoch 838/1000\n",
            "3/3 - 0s - loss: 2.5507 - accuracy: 0.2500\n",
            "Epoch 839/1000\n",
            "3/3 - 0s - loss: 2.5559 - accuracy: 0.2500\n",
            "Epoch 840/1000\n",
            "3/3 - 0s - loss: 2.5592 - accuracy: 0.2396\n",
            "Epoch 841/1000\n",
            "3/3 - 0s - loss: 2.5701 - accuracy: 0.2396\n",
            "Epoch 842/1000\n",
            "3/3 - 0s - loss: 2.5798 - accuracy: 0.2396\n",
            "Epoch 843/1000\n",
            "3/3 - 0s - loss: 2.5571 - accuracy: 0.2396\n",
            "Epoch 844/1000\n",
            "3/3 - 0s - loss: 2.5707 - accuracy: 0.2500\n",
            "Epoch 845/1000\n",
            "3/3 - 0s - loss: 2.5869 - accuracy: 0.2500\n",
            "Epoch 846/1000\n",
            "3/3 - 0s - loss: 2.5888 - accuracy: 0.2396\n",
            "Epoch 847/1000\n",
            "3/3 - 0s - loss: 2.5797 - accuracy: 0.2396\n",
            "Epoch 848/1000\n",
            "3/3 - 0s - loss: 2.5706 - accuracy: 0.2396\n",
            "Epoch 849/1000\n",
            "3/3 - 0s - loss: 2.5597 - accuracy: 0.2396\n",
            "Epoch 850/1000\n",
            "3/3 - 0s - loss: 2.5485 - accuracy: 0.2396\n",
            "Epoch 851/1000\n",
            "3/3 - 0s - loss: 2.5398 - accuracy: 0.2396\n",
            "Epoch 852/1000\n",
            "3/3 - 0s - loss: 2.5332 - accuracy: 0.2396\n",
            "Epoch 853/1000\n",
            "3/3 - 0s - loss: 2.5509 - accuracy: 0.2396\n",
            "Epoch 854/1000\n",
            "3/3 - 0s - loss: 2.5521 - accuracy: 0.2396\n",
            "Epoch 855/1000\n",
            "3/3 - 0s - loss: 2.5368 - accuracy: 0.2396\n",
            "Epoch 856/1000\n",
            "3/3 - 0s - loss: 2.5145 - accuracy: 0.2396\n",
            "Epoch 857/1000\n",
            "3/3 - 0s - loss: 2.5201 - accuracy: 0.2292\n",
            "Epoch 858/1000\n",
            "3/3 - 0s - loss: 2.6301 - accuracy: 0.2292\n",
            "Epoch 859/1000\n",
            "3/3 - 0s - loss: 2.6295 - accuracy: 0.2292\n",
            "Epoch 860/1000\n",
            "3/3 - 0s - loss: 2.6222 - accuracy: 0.2292\n",
            "Epoch 861/1000\n",
            "3/3 - 0s - loss: 2.6204 - accuracy: 0.2292\n",
            "Epoch 862/1000\n",
            "3/3 - 0s - loss: 2.6145 - accuracy: 0.2292\n",
            "Epoch 863/1000\n",
            "3/3 - 0s - loss: 2.6826 - accuracy: 0.2292\n",
            "Epoch 864/1000\n",
            "3/3 - 0s - loss: 2.6814 - accuracy: 0.2292\n",
            "Epoch 865/1000\n",
            "3/3 - 0s - loss: 2.6576 - accuracy: 0.2708\n",
            "Epoch 866/1000\n",
            "3/3 - 0s - loss: 2.6216 - accuracy: 0.3021\n",
            "Epoch 867/1000\n",
            "3/3 - 0s - loss: 2.6220 - accuracy: 0.2396\n",
            "Epoch 868/1000\n",
            "3/3 - 0s - loss: 2.6176 - accuracy: 0.2396\n",
            "Epoch 869/1000\n",
            "3/3 - 0s - loss: 2.6132 - accuracy: 0.2500\n",
            "Epoch 870/1000\n",
            "3/3 - 0s - loss: 2.5956 - accuracy: 0.2500\n",
            "Epoch 871/1000\n",
            "3/3 - 0s - loss: 2.5890 - accuracy: 0.2500\n",
            "Epoch 872/1000\n",
            "3/3 - 0s - loss: 2.5842 - accuracy: 0.2500\n",
            "Epoch 873/1000\n",
            "3/3 - 0s - loss: 2.5753 - accuracy: 0.2500\n",
            "Epoch 874/1000\n",
            "3/3 - 0s - loss: 2.5686 - accuracy: 0.2500\n",
            "Epoch 875/1000\n",
            "3/3 - 0s - loss: 2.5737 - accuracy: 0.2396\n",
            "Epoch 876/1000\n",
            "3/3 - 0s - loss: 2.5795 - accuracy: 0.2396\n",
            "Epoch 877/1000\n",
            "3/3 - 0s - loss: 2.5925 - accuracy: 0.2708\n",
            "Epoch 878/1000\n",
            "3/3 - 0s - loss: 2.6248 - accuracy: 0.2500\n",
            "Epoch 879/1000\n",
            "3/3 - 0s - loss: 2.6281 - accuracy: 0.2396\n",
            "Epoch 880/1000\n",
            "3/3 - 0s - loss: 2.6318 - accuracy: 0.2292\n",
            "Epoch 881/1000\n",
            "3/3 - 0s - loss: 2.6248 - accuracy: 0.2500\n",
            "Epoch 882/1000\n",
            "3/3 - 0s - loss: 2.6242 - accuracy: 0.2500\n",
            "Epoch 883/1000\n",
            "3/3 - 0s - loss: 2.6799 - accuracy: 0.2500\n",
            "Epoch 884/1000\n",
            "3/3 - 0s - loss: 2.6666 - accuracy: 0.2604\n",
            "Epoch 885/1000\n",
            "3/3 - 0s - loss: 2.6450 - accuracy: 0.2812\n",
            "Epoch 886/1000\n",
            "3/3 - 0s - loss: 2.6312 - accuracy: 0.2812\n",
            "Epoch 887/1000\n",
            "3/3 - 0s - loss: 2.5973 - accuracy: 0.3021\n",
            "Epoch 888/1000\n",
            "3/3 - 0s - loss: 2.6068 - accuracy: 0.1979\n",
            "Epoch 889/1000\n",
            "3/3 - 0s - loss: 2.6679 - accuracy: 0.1458\n",
            "Epoch 890/1000\n",
            "3/3 - 0s - loss: 2.6752 - accuracy: 0.1771\n",
            "Epoch 891/1000\n",
            "3/3 - 0s - loss: 2.6452 - accuracy: 0.2500\n",
            "Epoch 892/1000\n",
            "3/3 - 0s - loss: 2.6199 - accuracy: 0.2500\n",
            "Epoch 893/1000\n",
            "3/3 - 0s - loss: 2.6146 - accuracy: 0.2396\n",
            "Epoch 894/1000\n",
            "3/3 - 0s - loss: 2.5983 - accuracy: 0.2396\n",
            "Epoch 895/1000\n",
            "3/3 - 0s - loss: 2.5915 - accuracy: 0.2396\n",
            "Epoch 896/1000\n",
            "3/3 - 0s - loss: 2.5829 - accuracy: 0.2500\n",
            "Epoch 897/1000\n",
            "3/3 - 0s - loss: 2.5697 - accuracy: 0.2500\n",
            "Epoch 898/1000\n",
            "3/3 - 0s - loss: 2.5594 - accuracy: 0.2604\n",
            "Epoch 899/1000\n",
            "3/3 - 0s - loss: 2.5608 - accuracy: 0.2604\n",
            "Epoch 900/1000\n",
            "3/3 - 0s - loss: 2.5460 - accuracy: 0.2604\n",
            "Epoch 901/1000\n",
            "3/3 - 0s - loss: 2.5529 - accuracy: 0.2708\n",
            "Epoch 902/1000\n",
            "3/3 - 0s - loss: 2.5954 - accuracy: 0.2708\n",
            "Epoch 903/1000\n",
            "3/3 - 0s - loss: 2.5732 - accuracy: 0.2604\n",
            "Epoch 904/1000\n",
            "3/3 - 0s - loss: 2.5189 - accuracy: 0.3125\n",
            "Epoch 905/1000\n",
            "3/3 - 0s - loss: 2.4990 - accuracy: 0.3125\n",
            "Epoch 906/1000\n",
            "3/3 - 0s - loss: 2.4946 - accuracy: 0.3021\n",
            "Epoch 907/1000\n",
            "3/3 - 0s - loss: 2.4585 - accuracy: 0.2812\n",
            "Epoch 908/1000\n",
            "3/3 - 0s - loss: 2.4430 - accuracy: 0.2917\n",
            "Epoch 909/1000\n",
            "3/3 - 0s - loss: 2.4301 - accuracy: 0.2917\n",
            "Epoch 910/1000\n",
            "3/3 - 0s - loss: 2.4016 - accuracy: 0.3021\n",
            "Epoch 911/1000\n",
            "3/3 - 0s - loss: 2.3800 - accuracy: 0.3021\n",
            "Epoch 912/1000\n",
            "3/3 - 0s - loss: 2.3854 - accuracy: 0.3125\n",
            "Epoch 913/1000\n",
            "3/3 - 0s - loss: 2.3897 - accuracy: 0.3021\n",
            "Epoch 914/1000\n",
            "3/3 - 0s - loss: 2.4068 - accuracy: 0.2812\n",
            "Epoch 915/1000\n",
            "3/3 - 0s - loss: 2.4878 - accuracy: 0.2604\n",
            "Epoch 916/1000\n",
            "3/3 - 0s - loss: 2.4503 - accuracy: 0.2917\n",
            "Epoch 917/1000\n",
            "3/3 - 0s - loss: 2.4052 - accuracy: 0.3125\n",
            "Epoch 918/1000\n",
            "3/3 - 0s - loss: 2.4156 - accuracy: 0.2500\n",
            "Epoch 919/1000\n",
            "3/3 - 0s - loss: 2.4463 - accuracy: 0.2604\n",
            "Epoch 920/1000\n",
            "3/3 - 0s - loss: 2.4282 - accuracy: 0.2708\n",
            "Epoch 921/1000\n",
            "3/3 - 0s - loss: 2.3894 - accuracy: 0.2708\n",
            "Epoch 922/1000\n",
            "3/3 - 0s - loss: 2.3927 - accuracy: 0.3021\n",
            "Epoch 923/1000\n",
            "3/3 - 0s - loss: 2.4376 - accuracy: 0.3125\n",
            "Epoch 924/1000\n",
            "3/3 - 0s - loss: 2.4027 - accuracy: 0.3438\n",
            "Epoch 925/1000\n",
            "3/3 - 0s - loss: 2.3721 - accuracy: 0.3333\n",
            "Epoch 926/1000\n",
            "3/3 - 0s - loss: 2.3639 - accuracy: 0.3333\n",
            "Epoch 927/1000\n",
            "3/3 - 0s - loss: 2.3877 - accuracy: 0.2917\n",
            "Epoch 928/1000\n",
            "3/3 - 0s - loss: 2.3900 - accuracy: 0.2708\n",
            "Epoch 929/1000\n",
            "3/3 - 0s - loss: 2.3392 - accuracy: 0.2708\n",
            "Epoch 930/1000\n",
            "3/3 - 0s - loss: 2.4032 - accuracy: 0.2396\n",
            "Epoch 931/1000\n",
            "3/3 - 0s - loss: 2.4910 - accuracy: 0.3021\n",
            "Epoch 932/1000\n",
            "3/3 - 0s - loss: 2.5020 - accuracy: 0.2812\n",
            "Epoch 933/1000\n",
            "3/3 - 0s - loss: 2.4556 - accuracy: 0.2812\n",
            "Epoch 934/1000\n",
            "3/3 - 0s - loss: 2.3694 - accuracy: 0.3125\n",
            "Epoch 935/1000\n",
            "3/3 - 0s - loss: 2.6013 - accuracy: 0.2396\n",
            "Epoch 936/1000\n",
            "3/3 - 0s - loss: 2.7494 - accuracy: 0.1771\n",
            "Epoch 937/1000\n",
            "3/3 - 0s - loss: 2.8087 - accuracy: 0.1667\n",
            "Epoch 938/1000\n",
            "3/3 - 0s - loss: 2.7931 - accuracy: 0.1667\n",
            "Epoch 939/1000\n",
            "3/3 - 0s - loss: 2.7327 - accuracy: 0.1562\n",
            "Epoch 940/1000\n",
            "3/3 - 0s - loss: 2.6853 - accuracy: 0.2396\n",
            "Epoch 941/1000\n",
            "3/3 - 0s - loss: 2.6591 - accuracy: 0.2396\n",
            "Epoch 942/1000\n",
            "3/3 - 0s - loss: 2.6449 - accuracy: 0.2396\n",
            "Epoch 943/1000\n",
            "3/3 - 0s - loss: 2.6317 - accuracy: 0.2396\n",
            "Epoch 944/1000\n",
            "3/3 - 0s - loss: 2.6285 - accuracy: 0.2396\n",
            "Epoch 945/1000\n",
            "3/3 - 0s - loss: 2.6238 - accuracy: 0.2396\n",
            "Epoch 946/1000\n",
            "3/3 - 0s - loss: 2.6191 - accuracy: 0.2396\n",
            "Epoch 947/1000\n",
            "3/3 - 0s - loss: 2.6190 - accuracy: 0.2396\n",
            "Epoch 948/1000\n",
            "3/3 - 0s - loss: 2.6163 - accuracy: 0.2396\n",
            "Epoch 949/1000\n",
            "3/3 - 0s - loss: 2.6138 - accuracy: 0.2396\n",
            "Epoch 950/1000\n",
            "3/3 - 0s - loss: 2.6120 - accuracy: 0.2396\n",
            "Epoch 951/1000\n",
            "3/3 - 0s - loss: 2.6120 - accuracy: 0.2396\n",
            "Epoch 952/1000\n",
            "3/3 - 0s - loss: 2.6086 - accuracy: 0.2396\n",
            "Epoch 953/1000\n",
            "3/3 - 0s - loss: 2.6075 - accuracy: 0.2396\n",
            "Epoch 954/1000\n",
            "3/3 - 0s - loss: 2.6059 - accuracy: 0.2396\n",
            "Epoch 955/1000\n",
            "3/3 - 0s - loss: 2.6083 - accuracy: 0.2396\n",
            "Epoch 956/1000\n",
            "3/3 - 0s - loss: 2.6292 - accuracy: 0.2396\n",
            "Epoch 957/1000\n",
            "3/3 - 0s - loss: 2.6285 - accuracy: 0.2396\n",
            "Epoch 958/1000\n",
            "3/3 - 0s - loss: 2.6268 - accuracy: 0.2396\n",
            "Epoch 959/1000\n",
            "3/3 - 0s - loss: 2.6257 - accuracy: 0.2396\n",
            "Epoch 960/1000\n",
            "3/3 - 0s - loss: 2.6243 - accuracy: 0.2396\n",
            "Epoch 961/1000\n",
            "3/3 - 0s - loss: 2.6290 - accuracy: 0.2292\n",
            "Epoch 962/1000\n",
            "3/3 - 0s - loss: 2.6297 - accuracy: 0.2292\n",
            "Epoch 963/1000\n",
            "3/3 - 0s - loss: 2.6254 - accuracy: 0.2292\n",
            "Epoch 964/1000\n",
            "3/3 - 0s - loss: 2.6243 - accuracy: 0.2292\n",
            "Epoch 965/1000\n",
            "3/3 - 0s - loss: 2.6235 - accuracy: 0.2292\n",
            "Epoch 966/1000\n",
            "3/3 - 0s - loss: 2.6230 - accuracy: 0.2292\n",
            "Epoch 967/1000\n",
            "3/3 - 0s - loss: 2.6216 - accuracy: 0.2292\n",
            "Epoch 968/1000\n",
            "3/3 - 0s - loss: 2.6209 - accuracy: 0.2292\n",
            "Epoch 969/1000\n",
            "3/3 - 0s - loss: 2.6206 - accuracy: 0.2396\n",
            "Epoch 970/1000\n",
            "3/3 - 0s - loss: 2.6209 - accuracy: 0.2292\n",
            "Epoch 971/1000\n",
            "3/3 - 0s - loss: 2.6200 - accuracy: 0.2396\n",
            "Epoch 972/1000\n",
            "3/3 - 0s - loss: 2.6199 - accuracy: 0.2396\n",
            "Epoch 973/1000\n",
            "3/3 - 0s - loss: 2.6197 - accuracy: 0.2396\n",
            "Epoch 974/1000\n",
            "3/3 - 0s - loss: 2.6194 - accuracy: 0.2396\n",
            "Epoch 975/1000\n",
            "3/3 - 0s - loss: 2.6192 - accuracy: 0.2396\n",
            "Epoch 976/1000\n",
            "3/3 - 0s - loss: 2.6188 - accuracy: 0.2396\n",
            "Epoch 977/1000\n",
            "3/3 - 0s - loss: 2.6181 - accuracy: 0.2396\n",
            "Epoch 978/1000\n",
            "3/3 - 0s - loss: 2.6197 - accuracy: 0.2396\n",
            "Epoch 979/1000\n",
            "3/3 - 0s - loss: 2.6182 - accuracy: 0.2396\n",
            "Epoch 980/1000\n",
            "3/3 - 0s - loss: 2.6181 - accuracy: 0.2396\n",
            "Epoch 981/1000\n",
            "3/3 - 0s - loss: 2.6172 - accuracy: 0.2396\n",
            "Epoch 982/1000\n",
            "3/3 - 0s - loss: 2.6176 - accuracy: 0.2396\n",
            "Epoch 983/1000\n",
            "3/3 - 0s - loss: 2.6166 - accuracy: 0.2396\n",
            "Epoch 984/1000\n",
            "3/3 - 0s - loss: 2.6166 - accuracy: 0.2396\n",
            "Epoch 985/1000\n",
            "3/3 - 0s - loss: 2.6164 - accuracy: 0.2396\n",
            "Epoch 986/1000\n",
            "3/3 - 0s - loss: 2.6159 - accuracy: 0.2396\n",
            "Epoch 987/1000\n",
            "3/3 - 0s - loss: 2.6157 - accuracy: 0.2396\n",
            "Epoch 988/1000\n",
            "3/3 - 0s - loss: 2.6165 - accuracy: 0.2292\n",
            "Epoch 989/1000\n",
            "3/3 - 0s - loss: 2.6154 - accuracy: 0.2396\n",
            "Epoch 990/1000\n",
            "3/3 - 0s - loss: 2.6148 - accuracy: 0.2292\n",
            "Epoch 991/1000\n",
            "3/3 - 0s - loss: 2.6147 - accuracy: 0.2292\n",
            "Epoch 992/1000\n",
            "3/3 - 0s - loss: 2.6144 - accuracy: 0.2396\n",
            "Epoch 993/1000\n",
            "3/3 - 0s - loss: 2.6143 - accuracy: 0.2396\n",
            "Epoch 994/1000\n",
            "3/3 - 0s - loss: 2.6147 - accuracy: 0.2292\n",
            "Epoch 995/1000\n",
            "3/3 - 0s - loss: 2.6150 - accuracy: 0.2292\n",
            "Epoch 996/1000\n",
            "3/3 - 0s - loss: 2.6137 - accuracy: 0.2292\n",
            "Epoch 997/1000\n",
            "3/3 - 0s - loss: 2.6139 - accuracy: 0.2292\n",
            "Epoch 998/1000\n",
            "3/3 - 0s - loss: 2.6133 - accuracy: 0.2292\n",
            "Epoch 999/1000\n",
            "3/3 - 0s - loss: 2.6143 - accuracy: 0.2292\n",
            "Epoch 1000/1000\n",
            "3/3 - 0s - loss: 2.6131 - accuracy: 0.2396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f385d5c3e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtiCym5aYYTG",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "def _code_features(data):\n",
        "  all_sequences = []\n",
        "  for sequence in data:\n",
        "    all_events = []\n",
        "    for venue in sequence:\n",
        "      venue = all_venues.get(venue)\n",
        "      all_events.append(venue)\n",
        "    all_sequences.append(all_events)\n",
        "  return all_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT4rtRVR0dG0",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "def _target_code(targets_s):\n",
        "  targets_s_codeded = np.zeros((no_of_samples_train,no_of_venues),dtype=np.bool)\n",
        "  for index,data in enumerate(targets_s_codeded):\n",
        "    venue_index = all_venues.get(targets_s[index])\n",
        "    targets_s_codeded[index][venue_index] =1 \n",
        "  return targets_s_codeded\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vS7zrKoRNOD",
        "colab_type": "text"
      },
      "source": [
        "2. **GRU Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZsOeI0QcjGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load libraries\n",
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmpD1-hMa0bK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "020c9629-5b62-415b-c889-70d0106793ee"
      },
      "source": [
        "# Start neural network\n",
        "network = models.Sequential()\n",
        "\n",
        "network.add(layers.GRU(units=256,name='GRU_layer', input_shape=(max_length_train,no_of_venues+1)))\n",
        "network.add(Dropout(0.25))\n",
        "network.add(layers.Dense(units=no_of_venues+1, activation='softmax'))\n",
        "network.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "GRU_layer (GRU)              (None, 256)               304896    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 140)               35980     \n",
            "=================================================================\n",
            "Total params: 340,876\n",
            "Trainable params: 340,876\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B80b4EGhcdgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile neural network\n",
        "network.compile(loss='categorical_crossentropy', # Cross-entropy\n",
        "                optimizer='Adam', # Adam optimization\n",
        "                metrics=['accuracy']) # Accuracy performance metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbndmWb3cynK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95dc720b-30fa-4cbf-cd0f-efe19dfa1ab2"
      },
      "source": [
        "# Train neural network\n",
        "history = network.fit(x_train, # Features\n",
        "                      y_train, # Target\n",
        "                      epochs=1000, \n",
        "                      verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 4.9380 - accuracy: 0.1042\n",
            "Epoch 2/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 4.9179 - accuracy: 0.2292\n",
            "Epoch 3/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 4.8762 - accuracy: 0.2292\n",
            "Epoch 4/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 4.7434 - accuracy: 0.2292\n",
            "Epoch 5/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 4.1174 - accuracy: 0.2188\n",
            "Epoch 6/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 3.4107 - accuracy: 0.2188\n",
            "Epoch 7/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 3.3531 - accuracy: 0.2188\n",
            "Epoch 8/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 3.0546 - accuracy: 0.1979\n",
            "Epoch 9/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.9269 - accuracy: 0.2188\n",
            "Epoch 10/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.9458 - accuracy: 0.1875\n",
            "Epoch 11/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.9476 - accuracy: 0.1979\n",
            "Epoch 12/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8409 - accuracy: 0.1875\n",
            "Epoch 13/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.9058 - accuracy: 0.2188\n",
            "Epoch 14/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8882 - accuracy: 0.2083\n",
            "Epoch 15/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8950 - accuracy: 0.2188\n",
            "Epoch 16/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8064 - accuracy: 0.2188\n",
            "Epoch 17/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8209 - accuracy: 0.1979\n",
            "Epoch 18/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8648 - accuracy: 0.2188\n",
            "Epoch 19/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8416 - accuracy: 0.2188\n",
            "Epoch 20/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8514 - accuracy: 0.2083\n",
            "Epoch 21/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8364 - accuracy: 0.2292\n",
            "Epoch 22/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8127 - accuracy: 0.2500\n",
            "Epoch 23/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8580 - accuracy: 0.1979\n",
            "Epoch 24/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8053 - accuracy: 0.2083\n",
            "Epoch 25/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8643 - accuracy: 0.2396\n",
            "Epoch 26/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.7947 - accuracy: 0.1979\n",
            "Epoch 27/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.7961 - accuracy: 0.1979\n",
            "Epoch 28/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.7957 - accuracy: 0.1979\n",
            "Epoch 29/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8282 - accuracy: 0.1875\n",
            "Epoch 30/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.7237 - accuracy: 0.2083\n",
            "Epoch 31/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.8011 - accuracy: 0.1979\n",
            "Epoch 32/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.7693 - accuracy: 0.1979\n",
            "Epoch 33/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.7135 - accuracy: 0.2292\n",
            "Epoch 34/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.7316 - accuracy: 0.1979\n",
            "Epoch 35/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.6937 - accuracy: 0.1771\n",
            "Epoch 36/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.6465 - accuracy: 0.1979\n",
            "Epoch 37/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.6673 - accuracy: 0.1979\n",
            "Epoch 38/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.6119 - accuracy: 0.2188\n",
            "Epoch 39/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.5923 - accuracy: 0.2396\n",
            "Epoch 40/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.5883 - accuracy: 0.2083\n",
            "Epoch 41/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.5806 - accuracy: 0.1979\n",
            "Epoch 42/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.5134 - accuracy: 0.2188\n",
            "Epoch 43/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.5310 - accuracy: 0.2708\n",
            "Epoch 44/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.5268 - accuracy: 0.2604\n",
            "Epoch 45/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.5852 - accuracy: 0.2396\n",
            "Epoch 46/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.4357 - accuracy: 0.2708\n",
            "Epoch 47/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.4466 - accuracy: 0.2917\n",
            "Epoch 48/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.5208 - accuracy: 0.2708\n",
            "Epoch 49/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.6390 - accuracy: 0.2812\n",
            "Epoch 50/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.5414 - accuracy: 0.2083\n",
            "Epoch 51/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.5079 - accuracy: 0.2812\n",
            "Epoch 52/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.4374 - accuracy: 0.3229\n",
            "Epoch 53/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.4327 - accuracy: 0.2812\n",
            "Epoch 54/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3828 - accuracy: 0.2708\n",
            "Epoch 55/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.4093 - accuracy: 0.2604\n",
            "Epoch 56/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3696 - accuracy: 0.2708\n",
            "Epoch 57/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3525 - accuracy: 0.3125\n",
            "Epoch 58/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3410 - accuracy: 0.3125\n",
            "Epoch 59/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.2587 - accuracy: 0.3542\n",
            "Epoch 60/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3266 - accuracy: 0.3229\n",
            "Epoch 61/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3954 - accuracy: 0.3021\n",
            "Epoch 62/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.5635 - accuracy: 0.3229\n",
            "Epoch 63/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.7053 - accuracy: 0.2500\n",
            "Epoch 64/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.5825 - accuracy: 0.2604\n",
            "Epoch 65/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.6531 - accuracy: 0.2292\n",
            "Epoch 66/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.6570 - accuracy: 0.2708\n",
            "Epoch 67/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.4204 - accuracy: 0.3229\n",
            "Epoch 68/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.4297 - accuracy: 0.2917\n",
            "Epoch 69/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3525 - accuracy: 0.3750\n",
            "Epoch 70/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3721 - accuracy: 0.2708\n",
            "Epoch 71/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3284 - accuracy: 0.3229\n",
            "Epoch 72/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3073 - accuracy: 0.3229\n",
            "Epoch 73/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3312 - accuracy: 0.3021\n",
            "Epoch 74/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.2539 - accuracy: 0.3229\n",
            "Epoch 75/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.2513 - accuracy: 0.3542\n",
            "Epoch 76/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.2273 - accuracy: 0.3021\n",
            "Epoch 77/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.2830 - accuracy: 0.3333\n",
            "Epoch 78/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3508 - accuracy: 0.2812\n",
            "Epoch 79/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3783 - accuracy: 0.3125\n",
            "Epoch 80/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.2983 - accuracy: 0.2708\n",
            "Epoch 81/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.2904 - accuracy: 0.3542\n",
            "Epoch 82/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.2730 - accuracy: 0.3333\n",
            "Epoch 83/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.2152 - accuracy: 0.3854\n",
            "Epoch 84/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.1955 - accuracy: 0.3438\n",
            "Epoch 85/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.2005 - accuracy: 0.3542\n",
            "Epoch 86/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.1969 - accuracy: 0.3438\n",
            "Epoch 87/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.1543 - accuracy: 0.3958\n",
            "Epoch 88/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.1296 - accuracy: 0.3854\n",
            "Epoch 89/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.1016 - accuracy: 0.3958\n",
            "Epoch 90/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.1193 - accuracy: 0.3646\n",
            "Epoch 91/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.1152 - accuracy: 0.3750\n",
            "Epoch 92/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.0851 - accuracy: 0.3646\n",
            "Epoch 93/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.1363 - accuracy: 0.3854\n",
            "Epoch 94/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.1425 - accuracy: 0.3229\n",
            "Epoch 95/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.0334 - accuracy: 0.4167\n",
            "Epoch 96/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.0729 - accuracy: 0.3438\n",
            "Epoch 97/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.0597 - accuracy: 0.3958\n",
            "Epoch 98/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.0472 - accuracy: 0.4167\n",
            "Epoch 99/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.0354 - accuracy: 0.3542\n",
            "Epoch 100/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.9751 - accuracy: 0.3854\n",
            "Epoch 101/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.9883 - accuracy: 0.3646\n",
            "Epoch 102/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.9254 - accuracy: 0.3854\n",
            "Epoch 103/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.2389 - accuracy: 0.3021\n",
            "Epoch 104/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.0978 - accuracy: 0.3333\n",
            "Epoch 105/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.0976 - accuracy: 0.3542\n",
            "Epoch 106/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.0079 - accuracy: 0.3854\n",
            "Epoch 107/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.0031 - accuracy: 0.4271\n",
            "Epoch 108/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.9905 - accuracy: 0.4167\n",
            "Epoch 109/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.9531 - accuracy: 0.4062\n",
            "Epoch 110/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.9473 - accuracy: 0.4375\n",
            "Epoch 111/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.9800 - accuracy: 0.3958\n",
            "Epoch 112/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8962 - accuracy: 0.4062\n",
            "Epoch 113/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.9304 - accuracy: 0.4583\n",
            "Epoch 114/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8857 - accuracy: 0.4375\n",
            "Epoch 115/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.0465 - accuracy: 0.3854\n",
            "Epoch 116/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.3388 - accuracy: 0.3021\n",
            "Epoch 117/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.4076 - accuracy: 0.3229\n",
            "Epoch 118/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.2022 - accuracy: 0.3438\n",
            "Epoch 119/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.1239 - accuracy: 0.3750\n",
            "Epoch 120/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.9481 - accuracy: 0.3646\n",
            "Epoch 121/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.9473 - accuracy: 0.4271\n",
            "Epoch 122/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8592 - accuracy: 0.3958\n",
            "Epoch 123/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8802 - accuracy: 0.4271\n",
            "Epoch 124/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8425 - accuracy: 0.4271\n",
            "Epoch 125/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8706 - accuracy: 0.4167\n",
            "Epoch 126/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8626 - accuracy: 0.4479\n",
            "Epoch 127/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8664 - accuracy: 0.4479\n",
            "Epoch 128/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.7941 - accuracy: 0.4792\n",
            "Epoch 129/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.7526 - accuracy: 0.4583\n",
            "Epoch 130/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.9070 - accuracy: 0.4271\n",
            "Epoch 131/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8605 - accuracy: 0.3854\n",
            "Epoch 132/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8391 - accuracy: 0.4375\n",
            "Epoch 133/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8882 - accuracy: 0.3854\n",
            "Epoch 134/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8211 - accuracy: 0.4479\n",
            "Epoch 135/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.9015 - accuracy: 0.3958\n",
            "Epoch 136/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8688 - accuracy: 0.4271\n",
            "Epoch 137/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.0023 - accuracy: 0.3854\n",
            "Epoch 138/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.0132 - accuracy: 0.4167\n",
            "Epoch 139/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.1264 - accuracy: 0.3750\n",
            "Epoch 140/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.1317 - accuracy: 0.2917\n",
            "Epoch 141/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.1103 - accuracy: 0.3542\n",
            "Epoch 142/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.9663 - accuracy: 0.3750\n",
            "Epoch 143/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8677 - accuracy: 0.4062\n",
            "Epoch 144/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8817 - accuracy: 0.4375\n",
            "Epoch 145/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8324 - accuracy: 0.4375\n",
            "Epoch 146/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.7818 - accuracy: 0.4792\n",
            "Epoch 147/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.7954 - accuracy: 0.4271\n",
            "Epoch 148/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.7188 - accuracy: 0.5208\n",
            "Epoch 149/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.7233 - accuracy: 0.5104\n",
            "Epoch 150/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6999 - accuracy: 0.4688\n",
            "Epoch 151/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.7216 - accuracy: 0.4792\n",
            "Epoch 152/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6798 - accuracy: 0.4792\n",
            "Epoch 153/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.7824 - accuracy: 0.3958\n",
            "Epoch 154/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6920 - accuracy: 0.5208\n",
            "Epoch 155/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6821 - accuracy: 0.4896\n",
            "Epoch 156/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6413 - accuracy: 0.4896\n",
            "Epoch 157/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6799 - accuracy: 0.4375\n",
            "Epoch 158/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6845 - accuracy: 0.4688\n",
            "Epoch 159/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5764 - accuracy: 0.5417\n",
            "Epoch 160/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6101 - accuracy: 0.4896\n",
            "Epoch 161/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5735 - accuracy: 0.5521\n",
            "Epoch 162/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6124 - accuracy: 0.4896\n",
            "Epoch 163/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5674 - accuracy: 0.5312\n",
            "Epoch 164/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5940 - accuracy: 0.4896\n",
            "Epoch 165/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5362 - accuracy: 0.5104\n",
            "Epoch 166/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6639 - accuracy: 0.4792\n",
            "Epoch 167/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6264 - accuracy: 0.4688\n",
            "Epoch 168/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6506 - accuracy: 0.5000\n",
            "Epoch 169/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6055 - accuracy: 0.4792\n",
            "Epoch 170/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6693 - accuracy: 0.4792\n",
            "Epoch 171/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5508 - accuracy: 0.4792\n",
            "Epoch 172/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6504 - accuracy: 0.4792\n",
            "Epoch 173/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5657 - accuracy: 0.4688\n",
            "Epoch 174/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5538 - accuracy: 0.5000\n",
            "Epoch 175/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5762 - accuracy: 0.4896\n",
            "Epoch 176/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5072 - accuracy: 0.5208\n",
            "Epoch 177/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5496 - accuracy: 0.5208\n",
            "Epoch 178/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5767 - accuracy: 0.4896\n",
            "Epoch 179/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4496 - accuracy: 0.5417\n",
            "Epoch 180/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4754 - accuracy: 0.5417\n",
            "Epoch 181/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4977 - accuracy: 0.5208\n",
            "Epoch 182/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5853 - accuracy: 0.5000\n",
            "Epoch 183/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5889 - accuracy: 0.4792\n",
            "Epoch 184/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5544 - accuracy: 0.5104\n",
            "Epoch 185/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5037 - accuracy: 0.5312\n",
            "Epoch 186/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5546 - accuracy: 0.4688\n",
            "Epoch 187/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5922 - accuracy: 0.4688\n",
            "Epoch 188/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.7532 - accuracy: 0.4479\n",
            "Epoch 189/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.7483 - accuracy: 0.5000\n",
            "Epoch 190/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6666 - accuracy: 0.5000\n",
            "Epoch 191/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5478 - accuracy: 0.5312\n",
            "Epoch 192/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5186 - accuracy: 0.5521\n",
            "Epoch 193/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5217 - accuracy: 0.4896\n",
            "Epoch 194/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5132 - accuracy: 0.4792\n",
            "Epoch 195/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4802 - accuracy: 0.5417\n",
            "Epoch 196/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4916 - accuracy: 0.4896\n",
            "Epoch 197/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3876 - accuracy: 0.5833\n",
            "Epoch 198/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4358 - accuracy: 0.5208\n",
            "Epoch 199/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4067 - accuracy: 0.5417\n",
            "Epoch 200/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3784 - accuracy: 0.5208\n",
            "Epoch 201/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3700 - accuracy: 0.5208\n",
            "Epoch 202/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3448 - accuracy: 0.5729\n",
            "Epoch 203/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3469 - accuracy: 0.5833\n",
            "Epoch 204/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3375 - accuracy: 0.5938\n",
            "Epoch 205/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3183 - accuracy: 0.5625\n",
            "Epoch 206/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2865 - accuracy: 0.6146\n",
            "Epoch 207/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3054 - accuracy: 0.5833\n",
            "Epoch 208/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3381 - accuracy: 0.5938\n",
            "Epoch 209/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3562 - accuracy: 0.5625\n",
            "Epoch 210/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3273 - accuracy: 0.5833\n",
            "Epoch 211/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3127 - accuracy: 0.6042\n",
            "Epoch 212/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2559 - accuracy: 0.6458\n",
            "Epoch 213/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3857 - accuracy: 0.5417\n",
            "Epoch 214/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2629 - accuracy: 0.6354\n",
            "Epoch 215/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2576 - accuracy: 0.6042\n",
            "Epoch 216/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2918 - accuracy: 0.5938\n",
            "Epoch 217/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2371 - accuracy: 0.6667\n",
            "Epoch 218/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2929 - accuracy: 0.5729\n",
            "Epoch 219/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4032 - accuracy: 0.5104\n",
            "Epoch 220/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3313 - accuracy: 0.6250\n",
            "Epoch 221/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3348 - accuracy: 0.6250\n",
            "Epoch 222/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3196 - accuracy: 0.6042\n",
            "Epoch 223/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2826 - accuracy: 0.6146\n",
            "Epoch 224/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3026 - accuracy: 0.5938\n",
            "Epoch 225/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3733 - accuracy: 0.5729\n",
            "Epoch 226/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.7487 - accuracy: 0.4583\n",
            "Epoch 227/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8743 - accuracy: 0.4583\n",
            "Epoch 228/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5688 - accuracy: 0.5208\n",
            "Epoch 229/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4203 - accuracy: 0.5417\n",
            "Epoch 230/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4150 - accuracy: 0.5729\n",
            "Epoch 231/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2960 - accuracy: 0.6042\n",
            "Epoch 232/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3587 - accuracy: 0.5312\n",
            "Epoch 233/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2413 - accuracy: 0.6354\n",
            "Epoch 234/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2109 - accuracy: 0.6354\n",
            "Epoch 235/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1920 - accuracy: 0.6562\n",
            "Epoch 236/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1972 - accuracy: 0.6562\n",
            "Epoch 237/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1848 - accuracy: 0.6250\n",
            "Epoch 238/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1664 - accuracy: 0.6562\n",
            "Epoch 239/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1978 - accuracy: 0.6250\n",
            "Epoch 240/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1400 - accuracy: 0.6562\n",
            "Epoch 241/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1947 - accuracy: 0.6250\n",
            "Epoch 242/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1135 - accuracy: 0.6667\n",
            "Epoch 243/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1351 - accuracy: 0.6250\n",
            "Epoch 244/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0748 - accuracy: 0.7188\n",
            "Epoch 245/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0311 - accuracy: 0.7083\n",
            "Epoch 246/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0538 - accuracy: 0.6771\n",
            "Epoch 247/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1130 - accuracy: 0.6667\n",
            "Epoch 248/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1592 - accuracy: 0.6146\n",
            "Epoch 249/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0994 - accuracy: 0.6979\n",
            "Epoch 250/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3547 - accuracy: 0.5521\n",
            "Epoch 251/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3865 - accuracy: 0.5417\n",
            "Epoch 252/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5830 - accuracy: 0.5312\n",
            "Epoch 253/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4688 - accuracy: 0.5625\n",
            "Epoch 254/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3733 - accuracy: 0.6146\n",
            "Epoch 255/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.5705 - accuracy: 0.5729\n",
            "Epoch 256/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4235 - accuracy: 0.6146\n",
            "Epoch 257/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3301 - accuracy: 0.6042\n",
            "Epoch 258/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2468 - accuracy: 0.5833\n",
            "Epoch 259/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2013 - accuracy: 0.6146\n",
            "Epoch 260/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1708 - accuracy: 0.6458\n",
            "Epoch 261/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1748 - accuracy: 0.6354\n",
            "Epoch 262/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1262 - accuracy: 0.6042\n",
            "Epoch 263/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0934 - accuracy: 0.6250\n",
            "Epoch 264/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1659 - accuracy: 0.6562\n",
            "Epoch 265/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0693 - accuracy: 0.6667\n",
            "Epoch 266/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1262 - accuracy: 0.6042\n",
            "Epoch 267/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1019 - accuracy: 0.6250\n",
            "Epoch 268/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1335 - accuracy: 0.6042\n",
            "Epoch 269/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0342 - accuracy: 0.6875\n",
            "Epoch 270/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0213 - accuracy: 0.6667\n",
            "Epoch 271/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9549 - accuracy: 0.7396\n",
            "Epoch 272/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9674 - accuracy: 0.7396\n",
            "Epoch 273/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8963 - accuracy: 0.7292\n",
            "Epoch 274/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8700 - accuracy: 0.7292\n",
            "Epoch 275/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9383 - accuracy: 0.6667\n",
            "Epoch 276/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9900 - accuracy: 0.6771\n",
            "Epoch 277/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9002 - accuracy: 0.7188\n",
            "Epoch 278/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8734 - accuracy: 0.7396\n",
            "Epoch 279/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0092 - accuracy: 0.6667\n",
            "Epoch 280/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0343 - accuracy: 0.6771\n",
            "Epoch 281/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0590 - accuracy: 0.6354\n",
            "Epoch 282/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0523 - accuracy: 0.6458\n",
            "Epoch 283/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9519 - accuracy: 0.6771\n",
            "Epoch 284/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9087 - accuracy: 0.6979\n",
            "Epoch 285/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9540 - accuracy: 0.6771\n",
            "Epoch 286/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8926 - accuracy: 0.7396\n",
            "Epoch 287/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7941 - accuracy: 0.7604\n",
            "Epoch 288/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8572 - accuracy: 0.6979\n",
            "Epoch 289/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8748 - accuracy: 0.7083\n",
            "Epoch 290/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8525 - accuracy: 0.7083\n",
            "Epoch 291/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8607 - accuracy: 0.7083\n",
            "Epoch 292/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9088 - accuracy: 0.7083\n",
            "Epoch 293/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8362 - accuracy: 0.7188\n",
            "Epoch 294/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8327 - accuracy: 0.7500\n",
            "Epoch 295/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7463 - accuracy: 0.8125\n",
            "Epoch 296/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9231 - accuracy: 0.6875\n",
            "Epoch 297/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9874 - accuracy: 0.6458\n",
            "Epoch 298/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0023 - accuracy: 0.6458\n",
            "Epoch 299/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0713 - accuracy: 0.6042\n",
            "Epoch 300/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0914 - accuracy: 0.6458\n",
            "Epoch 301/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8525 - accuracy: 0.7083\n",
            "Epoch 302/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0839 - accuracy: 0.6771\n",
            "Epoch 303/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9950 - accuracy: 0.6771\n",
            "Epoch 304/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1154 - accuracy: 0.6354\n",
            "Epoch 305/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9061 - accuracy: 0.6979\n",
            "Epoch 306/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8772 - accuracy: 0.7083\n",
            "Epoch 307/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8580 - accuracy: 0.7188\n",
            "Epoch 308/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7631 - accuracy: 0.7188\n",
            "Epoch 309/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7358 - accuracy: 0.7188\n",
            "Epoch 310/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8142 - accuracy: 0.7292\n",
            "Epoch 311/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8212 - accuracy: 0.7812\n",
            "Epoch 312/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7647 - accuracy: 0.7500\n",
            "Epoch 313/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8354 - accuracy: 0.7292\n",
            "Epoch 314/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8676 - accuracy: 0.7500\n",
            "Epoch 315/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4591 - accuracy: 0.5938\n",
            "Epoch 316/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4389 - accuracy: 0.5938\n",
            "Epoch 317/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8358 - accuracy: 0.5104\n",
            "Epoch 318/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 3.0339 - accuracy: 0.3438\n",
            "Epoch 319/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 2.4003 - accuracy: 0.3958\n",
            "Epoch 320/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8158 - accuracy: 0.5417\n",
            "Epoch 321/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.8508 - accuracy: 0.5312\n",
            "Epoch 322/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.7780 - accuracy: 0.4688\n",
            "Epoch 323/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.6185 - accuracy: 0.5104\n",
            "Epoch 324/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4506 - accuracy: 0.5938\n",
            "Epoch 325/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3851 - accuracy: 0.5729\n",
            "Epoch 326/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3069 - accuracy: 0.5833\n",
            "Epoch 327/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2489 - accuracy: 0.5521\n",
            "Epoch 328/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2573 - accuracy: 0.5938\n",
            "Epoch 329/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.4024 - accuracy: 0.5417\n",
            "Epoch 330/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3782 - accuracy: 0.5625\n",
            "Epoch 331/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2865 - accuracy: 0.6042\n",
            "Epoch 332/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1416 - accuracy: 0.6354\n",
            "Epoch 333/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2045 - accuracy: 0.6667\n",
            "Epoch 334/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1066 - accuracy: 0.6458\n",
            "Epoch 335/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0504 - accuracy: 0.6562\n",
            "Epoch 336/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0640 - accuracy: 0.6562\n",
            "Epoch 337/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8596 - accuracy: 0.7604\n",
            "Epoch 338/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8990 - accuracy: 0.7188\n",
            "Epoch 339/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9057 - accuracy: 0.6979\n",
            "Epoch 340/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8477 - accuracy: 0.7500\n",
            "Epoch 341/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8968 - accuracy: 0.7188\n",
            "Epoch 342/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8125 - accuracy: 0.7500\n",
            "Epoch 343/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7871 - accuracy: 0.7500\n",
            "Epoch 344/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7461 - accuracy: 0.7083\n",
            "Epoch 345/10000\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.7520 - accuracy: 0.7708\n",
            "Epoch 346/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7179 - accuracy: 0.7812\n",
            "Epoch 347/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7027 - accuracy: 0.7812\n",
            "Epoch 348/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6882 - accuracy: 0.7604\n",
            "Epoch 349/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7271 - accuracy: 0.7604\n",
            "Epoch 350/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6939 - accuracy: 0.7708\n",
            "Epoch 351/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6871 - accuracy: 0.7917\n",
            "Epoch 352/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6769 - accuracy: 0.8021\n",
            "Epoch 353/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6644 - accuracy: 0.7812\n",
            "Epoch 354/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6328 - accuracy: 0.8229\n",
            "Epoch 355/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6263 - accuracy: 0.7917\n",
            "Epoch 356/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6017 - accuracy: 0.8021\n",
            "Epoch 357/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6456 - accuracy: 0.7500\n",
            "Epoch 358/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6129 - accuracy: 0.8229\n",
            "Epoch 359/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6421 - accuracy: 0.8125\n",
            "Epoch 360/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9502 - accuracy: 0.7292\n",
            "Epoch 361/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.8072 - accuracy: 0.7604\n",
            "Epoch 362/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7545 - accuracy: 0.7604\n",
            "Epoch 363/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6942 - accuracy: 0.7604\n",
            "Epoch 364/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6839 - accuracy: 0.7604\n",
            "Epoch 365/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7111 - accuracy: 0.7292\n",
            "Epoch 366/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6579 - accuracy: 0.7708\n",
            "Epoch 367/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6101 - accuracy: 0.7708\n",
            "Epoch 368/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5934 - accuracy: 0.8125\n",
            "Epoch 369/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6456 - accuracy: 0.7500\n",
            "Epoch 370/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5562 - accuracy: 0.8333\n",
            "Epoch 371/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6191 - accuracy: 0.7917\n",
            "Epoch 372/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6251 - accuracy: 0.7604\n",
            "Epoch 373/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5658 - accuracy: 0.8125\n",
            "Epoch 374/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5615 - accuracy: 0.8125\n",
            "Epoch 375/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5512 - accuracy: 0.8229\n",
            "Epoch 376/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5333 - accuracy: 0.8333\n",
            "Epoch 377/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5592 - accuracy: 0.7812\n",
            "Epoch 378/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5300 - accuracy: 0.8229\n",
            "Epoch 379/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4854 - accuracy: 0.8542\n",
            "Epoch 380/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5081 - accuracy: 0.8021\n",
            "Epoch 381/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5097 - accuracy: 0.8229\n",
            "Epoch 382/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4823 - accuracy: 0.8438\n",
            "Epoch 383/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4896 - accuracy: 0.8333\n",
            "Epoch 384/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4803 - accuracy: 0.8229\n",
            "Epoch 385/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4775 - accuracy: 0.8438\n",
            "Epoch 386/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4690 - accuracy: 0.8229\n",
            "Epoch 387/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4506 - accuracy: 0.8542\n",
            "Epoch 388/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4692 - accuracy: 0.8333\n",
            "Epoch 389/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4720 - accuracy: 0.8438\n",
            "Epoch 390/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4619 - accuracy: 0.8438\n",
            "Epoch 391/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4683 - accuracy: 0.8438\n",
            "Epoch 392/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4263 - accuracy: 0.8333\n",
            "Epoch 393/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4582 - accuracy: 0.8229\n",
            "Epoch 394/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4255 - accuracy: 0.8646\n",
            "Epoch 395/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4611 - accuracy: 0.8125\n",
            "Epoch 396/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4269 - accuracy: 0.8438\n",
            "Epoch 397/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4034 - accuracy: 0.8750\n",
            "Epoch 398/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4215 - accuracy: 0.8438\n",
            "Epoch 399/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4607 - accuracy: 0.8229\n",
            "Epoch 400/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4895 - accuracy: 0.7812\n",
            "Epoch 401/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0227 - accuracy: 0.6979\n",
            "Epoch 402/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1559 - accuracy: 0.6458\n",
            "Epoch 403/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9715 - accuracy: 0.6979\n",
            "Epoch 404/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9526 - accuracy: 0.6667\n",
            "Epoch 405/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1249 - accuracy: 0.5938\n",
            "Epoch 406/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3536 - accuracy: 0.5625\n",
            "Epoch 407/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9791 - accuracy: 0.6458\n",
            "Epoch 408/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.1948 - accuracy: 0.5833\n",
            "Epoch 409/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.0872 - accuracy: 0.6042\n",
            "Epoch 410/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.2562 - accuracy: 0.6667\n",
            "Epoch 411/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 1.3033 - accuracy: 0.5938\n",
            "Epoch 412/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9287 - accuracy: 0.6875\n",
            "Epoch 413/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9258 - accuracy: 0.6979\n",
            "Epoch 414/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7382 - accuracy: 0.7917\n",
            "Epoch 415/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.9203 - accuracy: 0.6875\n",
            "Epoch 416/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7285 - accuracy: 0.7604\n",
            "Epoch 417/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.7496 - accuracy: 0.7083\n",
            "Epoch 418/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6420 - accuracy: 0.7812\n",
            "Epoch 419/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.6898 - accuracy: 0.7604\n",
            "Epoch 420/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5906 - accuracy: 0.8125\n",
            "Epoch 421/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5412 - accuracy: 0.8229\n",
            "Epoch 422/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5289 - accuracy: 0.8438\n",
            "Epoch 423/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4936 - accuracy: 0.8229\n",
            "Epoch 424/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4985 - accuracy: 0.8333\n",
            "Epoch 425/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4318 - accuracy: 0.8646\n",
            "Epoch 426/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4230 - accuracy: 0.8958\n",
            "Epoch 427/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4222 - accuracy: 0.8750\n",
            "Epoch 428/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4380 - accuracy: 0.8229\n",
            "Epoch 429/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4376 - accuracy: 0.8438\n",
            "Epoch 430/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4124 - accuracy: 0.8750\n",
            "Epoch 431/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4226 - accuracy: 0.8646\n",
            "Epoch 432/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4422 - accuracy: 0.8750\n",
            "Epoch 433/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4005 - accuracy: 0.8750\n",
            "Epoch 434/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4009 - accuracy: 0.8542\n",
            "Epoch 435/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3727 - accuracy: 0.8646\n",
            "Epoch 436/10000\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.3688 - accuracy: 0.8958\n",
            "Epoch 437/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3548 - accuracy: 0.9062\n",
            "Epoch 438/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3358 - accuracy: 0.8958\n",
            "Epoch 439/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3348 - accuracy: 0.9167\n",
            "Epoch 440/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3476 - accuracy: 0.8958\n",
            "Epoch 441/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3814 - accuracy: 0.8750\n",
            "Epoch 442/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3664 - accuracy: 0.8854\n",
            "Epoch 443/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3450 - accuracy: 0.9271\n",
            "Epoch 444/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3166 - accuracy: 0.9375\n",
            "Epoch 445/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3750 - accuracy: 0.8854\n",
            "Epoch 446/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3588 - accuracy: 0.9062\n",
            "Epoch 447/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4141 - accuracy: 0.8542\n",
            "Epoch 448/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4152 - accuracy: 0.8646\n",
            "Epoch 449/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4219 - accuracy: 0.8854\n",
            "Epoch 450/10000\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.4028 - accuracy: 0.8750\n",
            "Epoch 451/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3870 - accuracy: 0.8646\n",
            "Epoch 452/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3766 - accuracy: 0.8958\n",
            "Epoch 453/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4061 - accuracy: 0.8646\n",
            "Epoch 454/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3613 - accuracy: 0.8854\n",
            "Epoch 455/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4253 - accuracy: 0.8542\n",
            "Epoch 456/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5182 - accuracy: 0.8333\n",
            "Epoch 457/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4573 - accuracy: 0.8750\n",
            "Epoch 458/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4496 - accuracy: 0.8542\n",
            "Epoch 459/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4141 - accuracy: 0.8542\n",
            "Epoch 460/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3768 - accuracy: 0.8854\n",
            "Epoch 461/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4889 - accuracy: 0.8333\n",
            "Epoch 462/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3711 - accuracy: 0.8958\n",
            "Epoch 463/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3373 - accuracy: 0.9062\n",
            "Epoch 464/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3474 - accuracy: 0.8958\n",
            "Epoch 465/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3116 - accuracy: 0.9375\n",
            "Epoch 466/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3938 - accuracy: 0.8646\n",
            "Epoch 467/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3546 - accuracy: 0.8542\n",
            "Epoch 468/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2986 - accuracy: 0.9271\n",
            "Epoch 469/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3001 - accuracy: 0.9167\n",
            "Epoch 470/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2855 - accuracy: 0.9167\n",
            "Epoch 471/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2699 - accuracy: 0.9479\n",
            "Epoch 472/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2782 - accuracy: 0.9375\n",
            "Epoch 473/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2741 - accuracy: 0.9375\n",
            "Epoch 474/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2837 - accuracy: 0.9271\n",
            "Epoch 475/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2724 - accuracy: 0.9062\n",
            "Epoch 476/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2852 - accuracy: 0.9167\n",
            "Epoch 477/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2581 - accuracy: 0.9479\n",
            "Epoch 478/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2913 - accuracy: 0.8958\n",
            "Epoch 479/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2632 - accuracy: 0.9271\n",
            "Epoch 480/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2616 - accuracy: 0.9479\n",
            "Epoch 481/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2545 - accuracy: 0.9271\n",
            "Epoch 482/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2156 - accuracy: 0.9688\n",
            "Epoch 483/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2471 - accuracy: 0.9271\n",
            "Epoch 484/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2675 - accuracy: 0.9271\n",
            "Epoch 485/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2889 - accuracy: 0.9062\n",
            "Epoch 486/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2920 - accuracy: 0.8958\n",
            "Epoch 487/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2532 - accuracy: 0.9479\n",
            "Epoch 488/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2663 - accuracy: 0.9271\n",
            "Epoch 489/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2503 - accuracy: 0.9375\n",
            "Epoch 490/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2473 - accuracy: 0.9167\n",
            "Epoch 491/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2308 - accuracy: 0.9375\n",
            "Epoch 492/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2482 - accuracy: 0.9375\n",
            "Epoch 493/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2275 - accuracy: 0.9375\n",
            "Epoch 494/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2213 - accuracy: 0.9479\n",
            "Epoch 495/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2211 - accuracy: 0.9375\n",
            "Epoch 496/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2539 - accuracy: 0.9375\n",
            "Epoch 497/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2195 - accuracy: 0.9479\n",
            "Epoch 498/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2869 - accuracy: 0.9167\n",
            "Epoch 499/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2271 - accuracy: 0.9375\n",
            "Epoch 500/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2084 - accuracy: 0.9479\n",
            "Epoch 501/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2437 - accuracy: 0.9062\n",
            "Epoch 502/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2745 - accuracy: 0.9375\n",
            "Epoch 503/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2781 - accuracy: 0.8854\n",
            "Epoch 504/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2476 - accuracy: 0.9167\n",
            "Epoch 505/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2078 - accuracy: 0.9375\n",
            "Epoch 506/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2066 - accuracy: 0.9583\n",
            "Epoch 507/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2338 - accuracy: 0.9375\n",
            "Epoch 508/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2511 - accuracy: 0.9167\n",
            "Epoch 509/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2851 - accuracy: 0.8958\n",
            "Epoch 510/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3289 - accuracy: 0.8854\n",
            "Epoch 511/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3183 - accuracy: 0.8542\n",
            "Epoch 512/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2609 - accuracy: 0.9167\n",
            "Epoch 513/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2560 - accuracy: 0.9167\n",
            "Epoch 514/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2159 - accuracy: 0.9375\n",
            "Epoch 515/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1868 - accuracy: 0.9479\n",
            "Epoch 516/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2000 - accuracy: 0.9479\n",
            "Epoch 517/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2224 - accuracy: 0.9479\n",
            "Epoch 518/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2288 - accuracy: 0.9167\n",
            "Epoch 519/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2038 - accuracy: 0.9375\n",
            "Epoch 520/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2411 - accuracy: 0.9167\n",
            "Epoch 521/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2030 - accuracy: 0.9479\n",
            "Epoch 522/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2065 - accuracy: 0.9479\n",
            "Epoch 523/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2333 - accuracy: 0.9375\n",
            "Epoch 524/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2297 - accuracy: 0.9167\n",
            "Epoch 525/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2098 - accuracy: 0.9583\n",
            "Epoch 526/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2086 - accuracy: 0.9583\n",
            "Epoch 527/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2364 - accuracy: 0.9375\n",
            "Epoch 528/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2098 - accuracy: 0.9271\n",
            "Epoch 529/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2431 - accuracy: 0.9062\n",
            "Epoch 530/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2443 - accuracy: 0.8854\n",
            "Epoch 531/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2372 - accuracy: 0.9375\n",
            "Epoch 532/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2605 - accuracy: 0.9375\n",
            "Epoch 533/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2015 - accuracy: 0.9479\n",
            "Epoch 534/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2472 - accuracy: 0.9062\n",
            "Epoch 535/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2478 - accuracy: 0.9062\n",
            "Epoch 536/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2183 - accuracy: 0.9375\n",
            "Epoch 537/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1765 - accuracy: 0.9479\n",
            "Epoch 538/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2972 - accuracy: 0.9062\n",
            "Epoch 539/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3804 - accuracy: 0.8750\n",
            "Epoch 540/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2820 - accuracy: 0.8958\n",
            "Epoch 541/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3137 - accuracy: 0.8854\n",
            "Epoch 542/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2256 - accuracy: 0.9479\n",
            "Epoch 543/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2539 - accuracy: 0.8958\n",
            "Epoch 544/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2979 - accuracy: 0.9062\n",
            "Epoch 545/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3281 - accuracy: 0.8854\n",
            "Epoch 546/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5561 - accuracy: 0.8438\n",
            "Epoch 547/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4290 - accuracy: 0.8438\n",
            "Epoch 548/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4429 - accuracy: 0.8438\n",
            "Epoch 549/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5262 - accuracy: 0.7812\n",
            "Epoch 550/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5526 - accuracy: 0.8021\n",
            "Epoch 551/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4565 - accuracy: 0.7812\n",
            "Epoch 552/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3806 - accuracy: 0.8438\n",
            "Epoch 553/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3293 - accuracy: 0.9167\n",
            "Epoch 554/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3690 - accuracy: 0.9062\n",
            "Epoch 555/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3573 - accuracy: 0.8854\n",
            "Epoch 556/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3233 - accuracy: 0.8646\n",
            "Epoch 557/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3363 - accuracy: 0.9062\n",
            "Epoch 558/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2849 - accuracy: 0.8750\n",
            "Epoch 559/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3256 - accuracy: 0.8958\n",
            "Epoch 560/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2306 - accuracy: 0.9479\n",
            "Epoch 561/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3189 - accuracy: 0.8750\n",
            "Epoch 562/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2654 - accuracy: 0.9167\n",
            "Epoch 563/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2057 - accuracy: 0.9271\n",
            "Epoch 564/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2133 - accuracy: 0.9271\n",
            "Epoch 565/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2038 - accuracy: 0.9375\n",
            "Epoch 566/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2241 - accuracy: 0.9271\n",
            "Epoch 567/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2614 - accuracy: 0.8958\n",
            "Epoch 568/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2158 - accuracy: 0.9167\n",
            "Epoch 569/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3274 - accuracy: 0.8750\n",
            "Epoch 570/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3030 - accuracy: 0.8854\n",
            "Epoch 571/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3551 - accuracy: 0.8646\n",
            "Epoch 572/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3856 - accuracy: 0.8542\n",
            "Epoch 573/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2604 - accuracy: 0.9167\n",
            "Epoch 574/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3340 - accuracy: 0.8750\n",
            "Epoch 575/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3877 - accuracy: 0.8438\n",
            "Epoch 576/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5205 - accuracy: 0.8125\n",
            "Epoch 577/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4152 - accuracy: 0.8438\n",
            "Epoch 578/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.5296 - accuracy: 0.7917\n",
            "Epoch 579/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4793 - accuracy: 0.8229\n",
            "Epoch 580/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4529 - accuracy: 0.8229\n",
            "Epoch 581/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3647 - accuracy: 0.8750\n",
            "Epoch 582/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3293 - accuracy: 0.8646\n",
            "Epoch 583/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2510 - accuracy: 0.9271\n",
            "Epoch 584/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3398 - accuracy: 0.8750\n",
            "Epoch 585/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.4158 - accuracy: 0.8438\n",
            "Epoch 586/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2858 - accuracy: 0.8750\n",
            "Epoch 587/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2513 - accuracy: 0.9167\n",
            "Epoch 588/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2771 - accuracy: 0.8750\n",
            "Epoch 589/10000\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.3215 - accuracy: 0.8646\n",
            "Epoch 590/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2495 - accuracy: 0.9062\n",
            "Epoch 591/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.3063 - accuracy: 0.8750\n",
            "Epoch 592/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2180 - accuracy: 0.9375\n",
            "Epoch 593/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2723 - accuracy: 0.8958\n",
            "Epoch 594/10000\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.2158 - accuracy: 0.9271\n",
            "Epoch 595/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.2346 - accuracy: 0.9479\n",
            "Epoch 596/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1904 - accuracy: 0.9375\n",
            "Epoch 597/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1876 - accuracy: 0.9479\n",
            "Epoch 598/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1825 - accuracy: 0.9479\n",
            "Epoch 599/10000\n",
            "96/96 [==============================] - 1s 7ms/step - loss: 0.1734 - accuracy: 0.9375\n",
            "Epoch 600/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1774 - accuracy: 0.9375\n",
            "Epoch 601/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1745 - accuracy: 0.9479\n",
            "Epoch 602/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1480 - accuracy: 0.9479\n",
            "Epoch 603/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1517 - accuracy: 0.9479\n",
            "Epoch 604/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1515 - accuracy: 0.9583\n",
            "Epoch 605/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1514 - accuracy: 0.9375\n",
            "Epoch 606/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1370 - accuracy: 0.9583\n",
            "Epoch 607/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1433 - accuracy: 0.9688\n",
            "Epoch 608/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1311 - accuracy: 0.9583\n",
            "Epoch 609/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1461 - accuracy: 0.9271\n",
            "Epoch 610/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1461 - accuracy: 0.9375\n",
            "Epoch 611/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1356 - accuracy: 0.9479\n",
            "Epoch 612/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1366 - accuracy: 0.9583\n",
            "Epoch 613/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1512 - accuracy: 0.9375\n",
            "Epoch 614/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1789 - accuracy: 0.9167\n",
            "Epoch 615/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1427 - accuracy: 0.9583\n",
            "Epoch 616/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1478 - accuracy: 0.9375\n",
            "Epoch 617/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1241 - accuracy: 0.9479\n",
            "Epoch 618/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1403 - accuracy: 0.9479\n",
            "Epoch 619/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1372 - accuracy: 0.9583\n",
            "Epoch 620/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1468 - accuracy: 0.9271\n",
            "Epoch 621/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1497 - accuracy: 0.9375\n",
            "Epoch 622/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1629 - accuracy: 0.9271\n",
            "Epoch 623/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1308 - accuracy: 0.9375\n",
            "Epoch 624/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1190 - accuracy: 0.9375\n",
            "Epoch 625/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1470 - accuracy: 0.9375\n",
            "Epoch 626/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1230 - accuracy: 0.9583\n",
            "Epoch 627/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1214 - accuracy: 0.9479\n",
            "Epoch 628/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1339 - accuracy: 0.9583\n",
            "Epoch 629/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1424 - accuracy: 0.9479\n",
            "Epoch 630/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1045 - accuracy: 0.9688\n",
            "Epoch 631/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1197 - accuracy: 0.9688\n",
            "Epoch 632/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1419 - accuracy: 0.9375\n",
            "Epoch 633/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1450 - accuracy: 0.9479\n",
            "Epoch 634/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1095 - accuracy: 0.9792\n",
            "Epoch 635/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1301 - accuracy: 0.9375\n",
            "Epoch 636/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1433 - accuracy: 0.9375\n",
            "Epoch 637/10000\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.1233 - accuracy: 0.9479\n",
            "Epoch 638/10000\n",
            "64/96 [===================>..........] - ETA: 0s - loss: 0.1408 - accuracy: 0.9219"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-e74584cffbc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                       verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuwQsuGkULWI",
        "colab_type": "text"
      },
      "source": [
        "3. **Venue and Time**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzFEySuuZPWc",
        "colab_type": "text"
      },
      "source": [
        "https://datascience.stackexchange.com/questions/53609/how-to-determine-input-shape-in-keras\n",
        "\n",
        "https://mmuratarat.github.io/2019-06-12/embeddings-with-numeric-variables-Keras#:~:text=In%20order%20to%20combine%20the,do%20for%20any%20regular%20network.\n",
        "\n",
        "https://www.tensorflow.org/guide/keras/masking_and_padding\n",
        "\n",
        "https://towardsdatascience.com/text-classifier-with-multiple-outputs-and-multiple-losses-in-keras-4b7a527eb858\n",
        "\n",
        "https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class\n",
        "\n",
        "https://www.kaggle.com/rajmehra03/a-detailed-explanation-of-keras-embedding-layer\n",
        "\n",
        "https://medium.com/@satnalikamayank12/on-learning-embeddings-for-categorical-data-using-keras-165ff2773fc9\n",
        "\n",
        "https://keras.io/guides/working_with_rnns/\n",
        "\n",
        "https://keras.io/guides/making_new_layers_and_models_via_subclassing/\n",
        "\n",
        "https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526\n",
        "\n",
        "https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work\n",
        "\n",
        "https://stackabuse.com/python-for-nlp-word-embeddings-for-deep-learning-in-keras/"
      ]
    }
  ]
}